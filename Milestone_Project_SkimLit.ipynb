{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRR3AxyAevo0nKj+/UxaYn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MelihKlc/Deep-Learning/blob/main/Milestone_Project_SkimLit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The purpose of this notebook is to build an NLP model to make reading medical abstracts easier."
      ],
      "metadata": {
        "id": "AUHdZq9wiBPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get data\n",
        "\n",
        "Since we will be replicating the paper above (PubMed 200k RCT) , lets download the dataset they used.\n",
        "\n",
        "We can do so from the authors GitHub: https://github.com/Franck-Dernoncourt/pubmed-rct"
      ],
      "metadata": {
        "id": "HRu6KJq9uMLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct  # Githubdan data cekerken git clone kullanıyoruz\n",
        "\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQpgQmAfu-ln",
        "outputId": "54df74a2-57fb-41f4-a67a-b78277f8a946"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 5), reused 5 (delta 5), pack-reused 25\u001b[K\n",
            "Receiving objects: 100% (33/33), 177.08 MiB | 15.08 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Updating files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20K dataset koymalarının sebebi önce kücük datasette calısıp sonrasında upscale etmek. (%10 of original dataset)\n",
        "# Check the files are in the PubMed_20k_ dataset\n",
        "# Dev.txt aslında validation set için konulan başka bir isim\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\n",
        "!ls pubmed-rct/PubMed_20k_RCT/   # Burda sayılar yerine @ konulmus sekilde geliyo datasetimiz. Aslında preprocess edilmis oluyo bir kısmı."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikUSsoCbvChR",
        "outputId": "72ccfafb-26ed-4802-e533-50bc029dcbb3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n",
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start our experiments using the 20K dataset with number replaced by \"@\" sign\n",
        "\n",
        "data_dir = \"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "8GXRBkotwc1q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all of the filenames in the target directory.\n",
        "import os\n",
        "\n",
        "filenames = [ data_dir + filename for filename in os.listdir(data_dir) ]\n",
        "filenames\n",
        "\n",
        "#for döngüsünden sonra gelen filename, her bir döngü iterasyonunda listenin içindeki dosya ve dizin adlarını temsil eden bir değişkendir. Yani her döngü adımında filename değişkeni, listenin içindeki sıradaki dosya veya dizin adını alır.\n",
        "\n",
        "#Örneğin, eğer os.listdir(data_dir) çağrısıyla data_dir dizininde bulunan dosya ve dizin adları şunlar ise: ['dosya1.txt', 'dosya2.txt', 'alt_dizin']\n",
        "\n",
        "#for filename in os.listdir(data_dir) ifadesi döngüye başladığında filename şu değerleri alacaktır:\n",
        "\n",
        "#İterasyon 1: filename = 'dosya1.txt'\n",
        "#İterasyon 2: filename = 'dosya2.txt'\n",
        "#İterasyon 3: filename = 'alt_dizin'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWq9Y5KFy73z",
        "outputId": "42652590-330f-4a58-b1ea-9c8096089b1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess data\n",
        "\n",
        "Now we have got some text data , it is time to become one with it.\n",
        "\n",
        "And one of the best ways to become one with the data is to..\n",
        "\n",
        "> Visualize\n",
        "\n",
        "So with that in mind , lets write a function to read in all of the lines of a target text file"
      ],
      "metadata": {
        "id": "pCggJBx9zJNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads filename (a text filename) and returns the lines of text as a list\n",
        "\n",
        "  Args:\n",
        "    filename: a string containing the target filepath.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings with one string per line from the target filename.\n",
        "  \"\"\"\n",
        "  # r means read and f means file. Open this file(filename) and save it as f\n",
        "  with open(filename , \"r\") as f:\n",
        "    return f.readlines()  # This reads the remaining lines from the file object and returns them as a list.\n"
      ],
      "metadata": {
        "id": "BYD-tylq3JTJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets read in the training lines\n",
        "\n",
        "train_lines = get_lines(data_dir + \"train.txt\" )\n",
        "train_lines[ : 27 ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY3mI6ZX4-Yc",
        "outputId": "2af91401-7d66-4855-8a2a-abf96acebd7a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
              " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
              " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
              " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
              " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
              " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n',\n",
              " 'CONCLUSIONS\\tResults further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .\\n',\n",
              " '\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets think about how we want out data to look..\n",
        "\n",
        "How i think our data would be best represented..\n",
        "\n",
        "We will represent our data with dictionary\n",
        "\n",
        "Emotional eatingle baslayan yeri kullanıyoruz.\n",
        "\n",
        "'  [ {  ' line_number ' : 0  ,\n",
        "' target ' : ' BACKGROUND ' ,\n",
        "' text ' : \"BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n\" ,\n",
        "' total_lines ' : 11  (sentence in our special abstract) }]  '\n",
        "\n",
        "Bizim datamızda order önemli çünkü conclusion cümlesinin başta olması saçma olur bu yüzden ordera dikkat edeceğiz.\n",
        "\n",
        "Bunu bitirdiğimizde liste içinde 11 dictionarymiz olması gerek.\n",
        "\n",
        "Niye bunu kullanıyoruz? Çünkü pythonda kendi data structure ımızı oluşturmak çok önemli şu an datamızda bir structure yok bu yüzden biz bunu list of dictionaries structure ına çevireceğiz.\n",
        "\n"
      ],
      "metadata": {
        "id": "8q8kcAmC5THw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets write a function which turns each of our datasets into the above format so we can continue to prepare"
      ],
      "metadata": {
        "id": "GF7kFhYP-YY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Returns a list of dictionaries of abstarct line data.\n",
        "\n",
        "  Takes in filename , reads in contents and sorts through each line ,\n",
        "  extracting things like the target label , the text of the sentence ,\n",
        "  how many sentences are in the current abstract and what sentence number\n",
        "  the target line is.\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract. abstractlar \\n ile ayrıldıgı icin biz de burda abstractları ayırıyoruz.\n",
        "  abstract_samples = [] # Create an empty list of abstracts\n",
        "\n",
        "  # Loop through each line in the target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"):  # Check to see if the line is an ID line. Bu methodla ### ile başlayan line gelirse yi test ediyoruz.\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\"   # Reset the abstract string if the line is an ID line. Yani id line geldiginde abstractımızı resetleyip basta yaptıgımız isleme dönüyoruz.\n",
        "    elif line.isspace():  # Check to see if line is a new line. Artık buraya geldiğimizde abstractları ayırdık. Simdi de abstract içindeki cümleleri ayırmamız gerekiyor. Bu yüzden isspace kullanıyoruz bu da new line gördüğünde devreye giriyor yani \\n gördüğünde.\n",
        "      abstract_line_split = abstract_lines.splitlines()  # Split abstract into seperate lines. splitlines fonksiyonu ile \\n yani new line gördüğünde artık onu line olarak ayarlıyor ve aşağıya geçtiğinde farklı bir line a geçmiş oluyoruz.\n",
        "\n",
        "         # Iterate through each line in a single abstract and count them at the same time\n",
        "      for abstract_line_number , abstract_line in enumerate(abstract_line_split):\n",
        "          line_data = {}  # Create an empty dictionary for each line. Her line için yukarıda bir pattern yazmıştık onu oluşturuyoruz.\n",
        "          target_text_split = abstract_line.split(\"\\t\") # Split target label from text\n",
        "          line_data[\"target\"] = target_text_split[0] # Get target labels. target_text_split ile textimizi labelından ayırdık. Şimdi line_data adında bir data olusturduk yukarıda dictionary olarak ve buna target adında bir feature ekledik bu labelları tutacak içinde. target_text_split[0] 0. index dediğimiz zaten labellar oluyo biz 2 indexe ayırdık target ve text olarak.\n",
        "          line_data[\"text\"] = target_text_split[1].lower()  # Textteki tüm harfleri kücük harfe ceviriyoruz lower methodu ile.\n",
        "          line_data[\"line_number\"] = abstract_line_number # What number line does the line appear in the abstract.\n",
        "          line_data[\"total_lines\"] = len(abstract_line_split) - 1  # -1 , indexler 0 dan basladıgı icin. How many total lines are there in the target abstract?\n",
        "          abstract_samples.append(line_data)  # add line data to abstract sample list. Burda artık line_data ile gerekli dictionary mizi olusturduk simdi list of dictionary kullanacagımız icin en basta olusturdugumuz empty listeye dictionarymizi ekliyoruz.\n",
        "    else:\n",
        "      abstract_lines += line  # If the above conditions arent satisfied , the line contains a labelled sentence . If it is not an id line (doesnt begin with ###) and if it also is not an empty string, the else statement is saying all of these lines between the ### and between the new line (\\n) are part of the same abstract\n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "ifEujPig_ZXa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data from file and preprocess it. (%%time ne kadar surdugunu ogrenmek icin)\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir +\"train.txt\")\n",
        "train_samples[ : 20]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Gjcv7LRvyn",
        "outputId": "9e244638-8c77-4755-c4d4-d8cccc251f67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 587 ms, sys: 85.1 ms, total: 672 ms\n",
            "Wall time: 1.12 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 10},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 10},\n",
              " {'target': 'OBJECTIVE',\n",
              "  'text': 'the aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 10},\n",
              " {'target': 'OBJECTIVE',\n",
              "  'text': 'it was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 10},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'participants ( n = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 10},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'attentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 10},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'self-reported emotional eating was assessed with the dutch eating behavior questionnaire ( debq ) and ad libitum food intake was tested by a disguised food offer .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 10},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'hierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "test_samples[ : 30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPVVqR06SCfx",
        "outputId": "0dfac829-3512-4249-871e-591b75332125"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'BACKGROUND',\n",
              "  'text': 'this study analyzed liver function abnormalities in heart failure patients admitted with severe acute decompensated heart failure ( adhf ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'a post hoc analysis was conducted with the use of data from the evaluation study of congestive heart failure and pulmonary artery catheterization effectiveness ( escape ) .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'liver function tests ( lfts ) were measured at @ time points from baseline , at discharge , and up to @ months follow-up .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'survival analyses were used to assess the association between admission model of end-stage liver disease excluding international normalized ratio ( meld-xi ) scores and patient outcome.there was a high prevalence of abnormal baseline ( admission ) lfts ( albumin @ % , aspartate transaminase @ % , alanine transaminase @ % , and total bilirubin @ % ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': \"the percentage of patients with abnormal lfts decreased significantly from baseline to @-months ' follow-up .\",\n",
              "  'line_number': 4,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'when mean hemodynamic profiles were compared in patients with abnormal versus normal lfts , elevated total bilirubin was associated with a significantly lower cardiac index ( @ vs @ ; p < @ ) and higher central venous pressure ( @ vs @ ; p = @ ) .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'multivariable analyses revealed that patients with elevated meld-xi scores ( @ ) had a @-fold ( hazard ratio@ @ , @ % confidence interval @-@ @ ) increased risk of death , rehospitalization , or transplantation after adjusting for baseline lfts , age , sex , race , body mass index , diabetes , and systolic blood pressure .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 8},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'abnormal lfts are common in the adhf population and are a dynamic marker of an impaired hemodynamic state .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 8},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'elevated meld-xi scores are associated with poor outcomes among patients admitted with adhf .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 8},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'minimally invasive endovascular aneurysm repair ( evar ) could be a surgical technique that improves outcome of patients with ruptured abdominal aortic aneurysm ( raaa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 12},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'the aim of this study was to analyse the cost-effectiveness and cost-utility of evar compared with standard open repair ( or ) in the treatment of raaa , with costs per @-day and @-month survivor as outcome parameters .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 12},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'resource use was determined from the amsterdam acute aneurysm ( ajax ) trial , a multicentre randomized trial comparing evar with or in patients with raaa .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 12},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'the analysis was performed from a provider perspective .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 12},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'all costs were calculated as if all patients had been treated in the same hospital ( onze lieve vrouwe gasthuis , teaching hospital ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 12},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'a total of @ patients were randomized .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 12},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the @-day mortality rate was @ per cent after evar and @ per cent for or : absolute risk reduction ( arr ) @ ( @ per cent confidence interval ( c.i. ) -@ to @ ) per cent .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 12},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'at @months , the total mortality rate for evar was @ per cent , compared with @ per cent among those assigned to or : arr @ ( -@ to @ ) per cent .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 12},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean cost difference between evar and or was @ ( @ per cent c.i. -@ to @,@ ) at @days and @,@ ( -@ to @,@ ) at @months .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 12},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the incremental cost-effectiveness ratio per prevented death was @,@ at @days and @,@ at @months .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 12},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was no significant difference in quality of life between evar and or .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 12},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'nor was evar superior regarding cost-utility .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 12},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'evar may be more effective for raaa , but its increased costs mean that it is unaffordable based on current standards of societal willingness-to-pay for health gains .',\n",
              "  'line_number': 12,\n",
              "  'total_lines': 12},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'evidence suggests that individuals with social anxiety demonstrate vigilance to social threat , whilst the peptide hormone oxytocin is widely accepted as supporting affiliative behaviour in humans .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 8},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'this study investigated whether oxytocin can affect attentional bias in social anxiety .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 8},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'in a double-blind , randomized , placebo-controlled , within-group study design , @ healthy and @ highly socially anxious ( hsa ) male volunteers ( within the hsa group , @ were diagnosed with generalized social anxiety disorder ) were administered @ iu of oxytocin or placebo to investigate attentional processing in social anxiety .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 8},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'attentional bias was assessed using the dot-probe paradigm with angry , fearful , happy and neutral face stimuli .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'in the baseline placebo condition , the hsa group showed greater attentional bias for emotional faces than healthy individuals .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'oxytocin reduced the difference between hsa and non-socially anxious individuals in attentional bias for emotional faces .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'moreover , it appeared to normalize attentional bias in hsa individuals to levels seen in the healthy population in the baseline condition .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 8},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the biological mechanisms by which oxytocin may be exerting these effects are discussed .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 8}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now that our data is the format of a list of dictionaries , how about we turn into a DataFrame to further vision"
      ],
      "metadata": {
        "id": "UPzHXFDdSiwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd   # Bizim datalarımızı dictionary formata getirme sebeplerimizin birisi de dictlerin pandas ile DataFrame şekline kolay çevrilebilmesi.\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "train_df.head(14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "06zDbubCVgtc",
        "outputId": "b74b6fb5-5c9d-4010-d117-e43ce71dad88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73614203-43eb-4f53-b097-8cc89c88ad48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73614203-43eb-4f53-b097-8cc89c88ad48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73614203-43eb-4f53-b097-8cc89c88ad48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73614203-43eb-4f53-b097-8cc89c88ad48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-728dbc1e-c6dc-4be8-a86a-fa1f1306a2aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-728dbc1e-c6dc-4be8-a86a-fa1f1306a2aa')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-728dbc1e-c6dc-4be8-a86a-fa1f1306a2aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBsFlyOPVyXj",
        "outputId": "804db138-6387-49b3-f15d-fa1b815bea9c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check the length of different lines\n",
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "tw3u_MzeXMbI",
        "outputId": "40b837ad-6204-4040-cafc-577d4cf1e54f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get list of sentences"
      ],
      "metadata": {
        "id": "x5eku_YgY25G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert abstract text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()"
      ],
      "metadata": {
        "id": "8HKuMzXOZP0i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the 10 lines of training sentences\n",
        "train_sentences[ : 10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cJzG9z7ZgVT",
        "outputId": "339a1790-c369-4e56-ddde-4883da6079e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make numeric labels (ML models require numeric labels)"
      ],
      "metadata": {
        "id": "st5VIsXCah1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First we will encode with one hot encoder and then we will use label encoder"
      ],
      "metadata": {
        "id": "KR9OSHZ9gTJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse = False)  # We want non-sparse matrix\n",
        "\n",
        "train_labels_encoded = encoder.fit_transform(train_df[\"target\"].to_numpy().reshape( -1 , 1 )) # Reshape yapmamız gerekiyor cünkü 2d array bekleniyor input olarak\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgU9tZP_dAl4",
        "outputId": "a49c98f6-404f-46fa-84aa-76ac92b7f73f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels_encoded = encoder.transform(val_df[\"target\"].to_numpy().reshape( -1  , 1))\n",
        "test_labels_encoded = encoder.transform(test_df[\"target\"].to_numpy().reshape( -1  , 1))\n",
        "# We wont use fit again because we already fitted in train_labels_encoded our encoder object , so fitting val and test labels are unnecessary"
      ],
      "metadata": {
        "id": "DEtAi_GmeOeb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label encode labels"
      ],
      "metadata": {
        "id": "u1cgqovnfVhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder_2 = LabelEncoder()\n",
        "\n",
        "train_labels_encoded_labelencoder = encoder_2.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded_labelencoder = encoder_2.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded_labelencoder = encoder_2.transform(test_df[\"target\"].to_numpy())"
      ],
      "metadata": {
        "id": "8Qq6LFkdgcq0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels_encoded_labelencoder[ : 10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9cbTWxVhAKx",
        "outputId": "bec2b471-7625-4e75-db06-6283ecc3bc44"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 4, 4, 4, 4, 4, 4, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(encoder_2.classes_)\n",
        "class_names = encoder_2.classes_\n",
        "num_classes , class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE7kj41jhMnN",
        "outputId": "dd2ad9fa-23b2-412b-a4c9-fabf7a278e00"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting a series of modelling experiments\n",
        "\n",
        "As usual , we are going to be trying out a bunch of different models and seeing which one works best.\n",
        "\n",
        "And as always , we are going to start with a baseline (TF-IDF multinomial naive bayes)"
      ],
      "metadata": {
        "id": "DjCSdo8FigMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 0 : Getting a baseline"
      ],
      "metadata": {
        "id": "WF58EFc1opL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "\n",
        "model_0 = Pipeline( [\n",
        "\n",
        "                   (\"tfidf\" , TfidfVectorizer()) ,\n",
        "                   (\"clf\" , MultinomialNB())\n",
        "]\n",
        ")\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(\n",
        "    X =  train_sentences ,\n",
        " y =   train_labels_encoded_labelencoder\n",
        "\n",
        ")\n",
        "# TfidfVectorizer terim frekansı ters belge frekansı (TF-IDF) değerlerini hesaplamak için kullanılır. Bu yöntem, bir belge içerisindeki bir terimin önemini, hem belge içerisindeki sıklığına hem de tüm belgelerdeki görülme sıklığına dayalı olarak belirler. Bu sayede metinlerin içerdikleri kelimelerin anlamlılığını belirlemek için kullanılır.\n",
        "# MultinomialNB, çok sınıflı Bayes sınıflandırıcılarından biridir ve metin sınıflandırma gibi problemlerde kullanılır. Naive Bayes algoritması, Bayes teoremi temel alınarak çalışır ve bir metni belirli sınıflara tahmin etmek için metindeki özelliklerin olasılıklarını kullanır. Bu durumda, sınıflandırıcı, veri setindeki sınıfları tahmin etmek için metin özelliklerini (TF-IDF değerleri) kullanacaktır."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "4IoUWKdNosl3",
        "outputId": "45753192-769d-4e20-d062-e754fa90069d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate baseline model on validation set\n",
        "model_0.score(\n",
        "    X = val_sentences ,\n",
        "    y = val_labels_encoded_labelencoder\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpPJyjN0p4gk",
        "outputId": "e6d32817-8706-4b86-f1d2-18e39de873be"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using our baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JERTAwfrkAZ",
        "outputId": "9f7480e9-0bf9-451d-e662-deaea152012e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We will compare predictions across different metrics (accuracy , precision , recall , f1-score)\n",
        "\n"
      ],
      "metadata": {
        "id": "12N1Lv7dr8Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "qhMa5BWntAdP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = calculate_results(\n",
        "    y_true = val_labels_encoded_labelencoder ,\n",
        "    y_pred = baseline_preds\n",
        "\n",
        ")\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44jCF4CwuYJn",
        "outputId": "46ab8d2d-4a39-4a85-cab9-55ccec2d2f98"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: Conv1D with token embeddings"
      ],
      "metadata": {
        "id": "rfqwHaUCufye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a text vectorizer layer\n",
        "\n",
        "We want to make a layer which maps our texts from words to number"
      ],
      "metadata": {
        "id": "twLDiuzc5cRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How long is each sentence on average?\n",
        "import numpy as np\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL-iXn_J1RoG",
        "outputId": "0a786f35-8a0f-4827-acae-6cbef14ed99d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=20);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "oohqz-171aZw",
        "outputId": "6eb7243c-5c4c-4b5a-da34-22eee1a8b4e3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average number of tokens in the training texts\n",
        "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92QdHQJ0vMjy",
        "outputId": "9abc3dec-da1f-4169-b0a7-832f1b8b168b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How long of a sentence lenght covers 95% of examples?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len  # output length kaç seçersek bizim datamızın %95 ini kapsar?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bLYOwWC1eRj",
        "outputId": "05b300d2-2656-423a-c610-535a80cf635e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many word are in our vocab? (taken from table 2 in our dataset paper , we have 68000 words)\n",
        "max_tokens = 68000"
      ],
      "metadata": {
        "id": "jsRdYGX_51fh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will create our textvectorizer function for convertinf text into numbers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "#ngram substringleri birleştiriyor. Mesela elimizde 'Imagine getting flattened by Kurt Zouma' cümlesi var. ngram = 2 dersek , \"Image getting\" , \"flattened by\" , \"Kurt Zouma\"  gibi ikişer ikişer substringleri birleştiriyor.\n",
        "\n",
        "# Default values of TextVectorization\n",
        "text_vectorizer = TextVectorization(max_tokens = max_tokens , # How many words in the vocabulary ( automatically add <00V>)\n",
        "                                                       output_sequence_length = 55 , # Desired lenght of vectorized output length of vectorized sequences\n",
        "                                    )"
      ],
      "metadata": {
        "id": "RCu67l48vDZx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "M4Z9ae-yv4Dv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out text vectorizer on random sentences\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\n Length of text : {len(target_sentence.split())}\\n\")\n",
        "print(f\"Text vectorized form of the text : \\n{text_vectorizer([target_sentence])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHf2YCFW7WiK",
        "outputId": "e02a32d3-1c59-4f07-cc54-042b9d67c6df"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "the procedure was classified as `` usual '' or `` difficult '' by the endoscopist at the conclusion of each case based on the need for adjunctive maneuvers to facilitate endoscope advancement .\n",
            "\n",
            " Length of text : 33\n",
            "\n",
            "Text vectorized form of the text : \n",
            "[[    2   407    10  2102    25   370    16  1760    22     2 10374    15\n",
            "      2  3039     4   122   825   261    18     2   483    11  2216  9138\n",
            "      6  2138  7085  8768     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words in our training vocab?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in our vocab : {len(rct_20k_text_vocab)}\")\n",
        "print(f\"Most common words in the vocab : { rct_20k_text_vocab[ :  5 ] }\")\n",
        "print(f\"Least common words in the vocab : { rct_20k_text_vocab[ -5 : ] }\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm-zo1f08vzK",
        "outputId": "0a3e1a4f-f321-475d-f9f8-de6aa7fbc110"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in our vocab : 64841\n",
            "Most common words in the vocab : ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocab : ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2KAlJ0y8v4A",
        "outputId": "6964fa3f-b923-49e9-ccba-0d009029321f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization',\n",
              " 'trainable': True,\n",
              " 'dtype': 'string',\n",
              " 'batch_input_shape': (None,),\n",
              " 'max_tokens': 68000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create an embedding layer"
      ],
      "metadata": {
        "id": "xC_PJP4u-FoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding( input_dim = len(rct_20k_text_vocab) ,  # set input shape\n",
        "                              output_dim = 128 , # Output shape. Every token in the format of 128 long vector\n",
        "                              mask_zero = True  # Input length 55 dedigimiz icin uzun cümlelerin sonunda 0 lar kalacak . Tensorflow to do more efficient computing when there is lots of zeros.\n",
        "                              )"
      ],
      "metadata": {
        "id": "RFNho50YwEOp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show example embedding\n",
        "# Cümleyi embed etmeden önce kesinlikle numerical form lazım bize o yüzden text vectorizationdan geçirmeden embedding yapamıyoruz.\n",
        "print(f\"Sentence before vectorization: \\n {target_sentence}\")\n",
        "vectorized_sentence = text_vectorizer ([target_sentence])\n",
        "print(f\"\\nVectorized form of our sentence (before embedding) : \\n {vectorized_sentence}\")\n",
        "embedded_sentence = embedding(vectorized_sentence)\n",
        "print(f\"\\nEmbedded form of our sentence : \\n {embedded_sentence}\")\n",
        "print(f\"\\nShape of embedded form of sentence \\n : {embedded_sentence.shape} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WjQf7x6_2h4",
        "outputId": "564e1848-1557-4bc0-d6df-90addc34fa14"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization: \n",
            " the procedure was classified as `` usual '' or `` difficult '' by the endoscopist at the conclusion of each case based on the need for adjunctive maneuvers to facilitate endoscope advancement .\n",
            "\n",
            "Vectorized form of our sentence (before embedding) : \n",
            " [[    2   407    10  2102    25   370    16  1760    22     2 10374    15\n",
            "      2  3039     4   122   825   261    18     2   483    11  2216  9138\n",
            "      6  2138  7085  8768     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n",
            "\n",
            "Embedded form of our sentence : \n",
            " [[[ 0.00227692  0.02313609  0.02885688 ...  0.00542902  0.00287042\n",
            "    0.02692653]\n",
            "  [-0.00841216  0.00174212 -0.03521187 ... -0.01883209 -0.04277772\n",
            "   -0.03651248]\n",
            "  [-0.01056628 -0.04605243 -0.0018052  ... -0.01954138  0.03284463\n",
            "   -0.00866001]\n",
            "  ...\n",
            "  [ 0.00788181 -0.02490911  0.00115781 ...  0.01156297  0.04051268\n",
            "    0.02252573]\n",
            "  [ 0.00788181 -0.02490911  0.00115781 ...  0.01156297  0.04051268\n",
            "    0.02252573]\n",
            "  [ 0.00788181 -0.02490911  0.00115781 ...  0.01156297  0.04051268\n",
            "    0.02252573]]]\n",
            "\n",
            "Shape of embedded form of sentence \n",
            " : (1, 55, 128) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating datasets (making sure our data loads as fast as possible)\n",
        "\n",
        "We are going to setup our data to run as fast as possible with tensorflow tf.data API , many of the steps here are discussed at length in these two resources:\n",
        "\n",
        "https://www.tensorflow.org/guide/data_performance\n",
        "\n",
        "https://www.tensorflow.org/guide/data"
      ],
      "metadata": {
        "id": "8o6ko96pFWAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences , train_labels_encoded))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences , test_labels_encoded))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences , val_labels_encoded))\n",
        "\n",
        "# It combines them into tensorflow slice dataset"
      ],
      "metadata": {
        "id": "J6Xu4GEZGkvg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched datasets\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset\n",
        "\n",
        "#Shuffle etmiyoruz cünkü bu datamızda önceden bahsettiğimiz üzere order önemli."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5wfcBKXIyPj",
        "outputId": "8303215b-09b5-4000-e433-66d06dd10d75"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-rFXqGbMlk6",
        "outputId": "05d02581-359b-4b19-8d5d-bcc21f1d2762"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model_1\n",
        "\n",
        "inputs = layers.Input(shape = (1,) , dtype  = tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(64 , kernel_size = 5 , activation = \"relu\" , padding = \"same\")(x)\n",
        "x = layers.GlobalAveragePooling1D()(x) # Condense the output of our feature vector from conv layer\n",
        "outputs = layers.Dense( num_classes , activation = \"softmax\")(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs , outputs)\n",
        "\n",
        "# Compile a model\n",
        "\n",
        "model_1.compile(loss = [\"categorical_crossentropy\"] ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "# Fit the model\n",
        "hist_1 = model_1.fit(\n",
        "    train_dataset ,\n",
        "    epochs = 5 ,  # Eğer daha hızlı process istiyorsak burda steps_per_epoch = int( len(0.1 * len(train_dataset))) yapabiliriz ama böyle yaptıgımızda modelimiz train datamızın sadece %10 u ile train oluyor.\n",
        "    validation_data = val_dataset\n",
        ")\n",
        "# Direkt train_dataset ile feed ediyoruz çünkü bizim train_dataset imiz train sentenceları ve onların labellarını içeren bir tuple."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BqFjb6pwOYE",
        "outputId": "16685a06-0892-4961-9c9a-62a1c5d8f6a8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5627/5627 [==============================] - 93s 15ms/step - loss: 0.6148 - accuracy: 0.7760 - val_loss: 0.5349 - val_accuracy: 0.8103\n",
            "Epoch 2/5\n",
            "5627/5627 [==============================] - 37s 7ms/step - loss: 0.4519 - accuracy: 0.8418 - val_loss: 0.5325 - val_accuracy: 0.8117\n",
            "Epoch 3/5\n",
            "5627/5627 [==============================] - 39s 7ms/step - loss: 0.3708 - accuracy: 0.8731 - val_loss: 0.5669 - val_accuracy: 0.8063\n",
            "Epoch 4/5\n",
            "5627/5627 [==============================] - 36s 6ms/step - loss: 0.3057 - accuracy: 0.8983 - val_loss: 0.6274 - val_accuracy: 0.8008\n",
            "Epoch 5/5\n",
            "5627/5627 [==============================] - 37s 6ms/step - loss: 0.2513 - accuracy: 0.9187 - val_loss: 0.7067 - val_accuracy: 0.7941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our model\n",
        "model_1_evaluation = model_1.evaluate(val_dataset)\n",
        "model_1_evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ewt-Hw0PZfK",
        "outputId": "abbfeeea-d4a5-4e7d-ce40-1ba6a40a6bc9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 3s 3ms/step - loss: 0.7067 - accuracy: 0.7941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7066957950592041, 0.7941215634346008]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with our model\n",
        "model_1_preds = model_1.predict(val_dataset)\n",
        "model_1_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIaMVtVIZysl",
        "outputId": "526a3a12-bdd9-4ab6-f32b-34025de86b58"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 3s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.2060717e-01, 1.0366353e-03, 4.4754294e-01, 2.1341959e-02,\n",
              "        9.4713354e-03],\n",
              "       [5.2201200e-01, 5.9496168e-02, 1.8560833e-03, 4.1167668e-01,\n",
              "        4.9590943e-03],\n",
              "       [6.7684501e-02, 1.6994791e-03, 2.9619194e-03, 9.2757982e-01,\n",
              "        7.4340460e-05],\n",
              "       ...,\n",
              "       [3.6087493e-09, 1.9948291e-07, 2.1274647e-04, 1.3075484e-09,\n",
              "        9.9978703e-01],\n",
              "       [1.1535938e-01, 3.4216785e-01, 3.1982461e-01, 2.5265234e-02,\n",
              "        1.9738296e-01],\n",
              "       [3.0332000e-04, 9.9915648e-01, 4.6659249e-04, 2.1853780e-06,\n",
              "        7.1379654e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_g3PjvBaKPx",
        "outputId": "723bb86b-46b0-402e-b1e6-79f6e6059e13"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30212, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert preds to classes\n",
        "model_1_pred = tf.argmax(model_1_preds , axis = 1)\n"
      ],
      "metadata": {
        "id": "R5KAAXHsaUJI"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L_foDKla-Dr",
        "outputId": "4474b325-aaf5-4b0b-8f09-0142976730fd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(\n",
        "    y_true = val_labels_encoded_labelencoder ,\n",
        "    y_pred = model_1_pred\n",
        ")\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f2jxHd7bOC5",
        "outputId": "4c121332-f158-445a-8c7d-3421843772ed"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.4121541109493,\n",
              " 'precision': 0.7910591376179037,\n",
              " 'recall': 0.794121541109493,\n",
              " 'f1': 0.7914216786187722}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2 : Feature extraction with pretrained token embeddings\n",
        "\n",
        "We can use glove embedding also but we will use universal sentence encoder (pre-trained word embeddings from tensorflow hub)."
      ],
      "metadata": {
        "id": "WoeWj6qAcnd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "# embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")  Bu kısım örnekleri hub a atıp görmek için"
      ],
      "metadata": {
        "id": "w-JK3snqhwJ8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Keras layer using USE pre-trained layer from tensorflow hub\n",
        "import tensorflow as tf\n",
        "\n",
        "sentence_encoder_layer = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/google/universal-sentence-encoder/4\" ,\n",
        "    trainable = False ,\n",
        "    name = \"USE\"\n",
        ")"
      ],
      "metadata": {
        "id": "GEVa9Lafh02O"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the pre-trained embedding on a random sentence\n",
        "\n",
        "random_train_sentence = random.choice(test_sentences)\n",
        "random_embedded_sentence  = sentence_encoder_layer([random_train_sentence])\n",
        "print(f\"Random sentence : \\n {random_train_sentence}\")\n",
        "print(f\"\\nEmbed form of our sentence: \\n {random_embedded_sentence} \")\n",
        "print(f\"\\nLength of embedded sentence : \\n {len(random_embedded_sentence[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mi4eaehiiHX",
        "outputId": "6697640d-4382-4a30-b93c-527def6b3810"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sentence : \n",
            " randomisation was done by a minimisation algorithm stratified by figo stage , residual disease , interval between surgery and chemotherapy , and gynecologic cancer intergroup group .\n",
            "\n",
            "Embed form of our sentence: \n",
            " [[-0.06503702  0.00882439  0.03621592 -0.01291342 -0.02688814 -0.08095063\n",
            "   0.02514381 -0.04141701  0.05657679  0.05582137  0.08000645 -0.06752125\n",
            "  -0.04086111  0.06243248  0.04084297 -0.05559887 -0.08151209 -0.01094112\n",
            "  -0.02716626 -0.01883569 -0.02490789  0.0644007  -0.01207968  0.01764577\n",
            "   0.06787116  0.06224651  0.05408912 -0.00461699 -0.03732037  0.06298658\n",
            "   0.05123181  0.08144541 -0.00122782 -0.07710256 -0.06134517  0.00081208\n",
            "   0.0051245  -0.0573304  -0.04243295 -0.06144259 -0.03076115 -0.04503918\n",
            "   0.00180319  0.01537078  0.00022629  0.04306788  0.01714981  0.02880569\n",
            "  -0.04419525  0.03640237 -0.04365776 -0.00355611 -0.05062658 -0.07106584\n",
            "   0.00691259  0.01663456 -0.03713736  0.06725527  0.06753295  0.0274053\n",
            "  -0.01915903  0.01714561 -0.00707778  0.05842157  0.06010455 -0.02464899\n",
            "   0.06885604  0.02619263  0.05663641  0.04160903 -0.02079196 -0.05365622\n",
            "   0.0508473   0.02117127 -0.04647094  0.04798242 -0.0008738   0.07711574\n",
            "  -0.03078087 -0.00165216  0.06591442  0.05367494  0.05584412 -0.0042276\n",
            "  -0.06225425  0.04911942 -0.04956183 -0.01672624 -0.041498   -0.07229302\n",
            "  -0.07802568  0.03910037 -0.02131578  0.00398627  0.07397104 -0.0450712\n",
            "   0.03393698  0.01241995  0.03005287 -0.05604177  0.01699227  0.02884841\n",
            "   0.06862512  0.06166074  0.033917   -0.05790963  0.05053254 -0.00702805\n",
            "  -0.03694016 -0.01129118 -0.07287384 -0.02935941  0.04280435  0.01627246\n",
            "   0.06345545  0.00983929  0.00794142  0.02920057  0.04221989 -0.00028569\n",
            "   0.04713039 -0.02007804  0.02883213 -0.02536169  0.0680349   0.04371376\n",
            "  -0.06028347  0.0400999  -0.0190032  -0.03718407  0.05077901  0.0814511\n",
            "   0.01794631  0.00134167  0.04849957 -0.03598152  0.02386111  0.05860566\n",
            "  -0.0194981  -0.00600435 -0.05346082  0.06946491  0.02013853 -0.02865362\n",
            "   0.0476207  -0.00490044  0.04934921 -0.04641717 -0.01944919 -0.00819339\n",
            "   0.05866615 -0.01271624 -0.06342113 -0.06359744  0.06582487  0.01028117\n",
            "  -0.0358461   0.04755098 -0.05374762 -0.03862967 -0.0715444   0.04978328\n",
            "  -0.03224545  0.01981962  0.05326417 -0.06585246 -0.05403921  0.04245481\n",
            "   0.04644372 -0.06106029 -0.06188065 -0.07670841 -0.04860813  0.05741903\n",
            "   0.00340747 -0.06267126 -0.06369101  0.04038773  0.05592186  0.05643081\n",
            "   0.01336432  0.0087764   0.05773766  0.03165572  0.0091589   0.01570616\n",
            "   0.00898349  0.02464227 -0.02436397 -0.02568532  0.03050348 -0.04031853\n",
            "   0.01293139  0.03671918  0.01693759 -0.01838747 -0.03426223  0.05455128\n",
            "  -0.01327817  0.03220397 -0.01088061 -0.00075385 -0.00790316  0.04518629\n",
            "   0.02761392 -0.01157492  0.07326769  0.02415086 -0.02236377  0.05705677\n",
            "  -0.05961062  0.04872565  0.03869925  0.01927699 -0.04519343 -0.02620539\n",
            "   0.0607996   0.04357201  0.02861309 -0.022005   -0.01543478 -0.05462011\n",
            "   0.06897342 -0.07074372  0.06950565  0.00967177  0.04232337  0.03102919\n",
            "  -0.02605908  0.06537314  0.04457688  0.04715732 -0.06665476 -0.0491339\n",
            "   0.06637789 -0.00598296 -0.01257304  0.00482045 -0.06479841  0.03242026\n",
            "  -0.0459152  -0.00024532 -0.0685844  -0.03733537 -0.04751818 -0.01597141\n",
            "  -0.04304779  0.03096546 -0.03605763 -0.07965274 -0.00298361 -0.0470812\n",
            "  -0.0124595  -0.02294589 -0.04081969  0.06819525 -0.03286469  0.04557309\n",
            "   0.01536278 -0.03355927  0.01434199 -0.01153116 -0.04235284  0.07229089\n",
            "  -0.04993331 -0.0366021   0.04716792  0.0485153   0.04126283 -0.00015945\n",
            "  -0.04250854  0.0293465   0.05518753 -0.01315943 -0.04957995 -0.04499853\n",
            "   0.01533395  0.0194317   0.03442835  0.01115049  0.05537535  0.027577\n",
            "  -0.01559472 -0.04013419  0.06609841 -0.0315263  -0.03182236  0.05666942\n",
            "   0.06817537  0.01103185  0.05617593 -0.05941364 -0.06472122 -0.01523662\n",
            "  -0.0598317  -0.01793352  0.02117858  0.04308731  0.03118387  0.03806835\n",
            "   0.05313587  0.05681206  0.03835509 -0.06665214 -0.07585578  0.07267766\n",
            "  -0.04896838 -0.06685327  0.00431118  0.06343321  0.02939045  0.02426588\n",
            "   0.01813029 -0.03101658  0.03923899 -0.0551505   0.00493156  0.0471703\n",
            "  -0.03481795  0.045095    0.03609349  0.01607946  0.02317658 -0.06227728\n",
            "  -0.06625552  0.08067986 -0.08092379  0.05495791 -0.0651265   0.02812615\n",
            "   0.00166897 -0.07397059 -0.02097143  0.06785976  0.03698655  0.04878248\n",
            "  -0.02825542  0.00260219  0.03543127  0.04522638  0.02800252 -0.02817148\n",
            "   0.05346341 -0.00897992 -0.0486605  -0.01767999  0.02069557 -0.01448784\n",
            "   0.02007783  0.04925173 -0.01391941  0.0018938   0.06032855 -0.01325191\n",
            "   0.07363045  0.04123224 -0.059354   -0.0630704   0.0064825  -0.0597943\n",
            "   0.0272542  -0.02018143 -0.0743471  -0.06842292  0.03675523  0.05120348\n",
            "   0.04002425 -0.00824312  0.00609061 -0.03221241 -0.03431939  0.07002658\n",
            "   0.07143245  0.01804124  0.07369415 -0.01363247 -0.00386282 -0.0058833\n",
            "   0.01383822 -0.05674151 -0.00939855  0.00150645 -0.02883896 -0.01363321\n",
            "  -0.0567073   0.05549593 -0.07571854 -0.06650794  0.01530418 -0.05687899\n",
            "   0.00448104  0.05881367  0.0104796  -0.0056684  -0.06059564  0.06643591\n",
            "   0.07759495 -0.01978647  0.01392522 -0.07179224  0.07524032  0.0474597\n",
            "  -0.05255873  0.01948833 -0.03239177 -0.01326229  0.03093102  0.04147926\n",
            "   0.05200377 -0.01757961 -0.0130134   0.0680275   0.05697793 -0.01538903\n",
            "  -0.05996465 -0.06372439  0.04446833 -0.05518839 -0.02206612 -0.03044391\n",
            "   0.04439846 -0.03042668 -0.01546713 -0.06524439  0.00787035 -0.0423427\n",
            "   0.06031718 -0.03682379 -0.02334317 -0.04096935 -0.05583911 -0.05561844\n",
            "  -0.01831353  0.04864801  0.06260689 -0.03830918 -0.00067485  0.03438883\n",
            "  -0.05499459  0.02049968 -0.01501891  0.007671    0.01783368  0.02842832\n",
            "   0.0049313   0.04912034  0.00682606  0.00271366 -0.027351   -0.0307779\n",
            "   0.01660097  0.01224577 -0.04155964 -0.00603182 -0.02352906 -0.05418005\n",
            "  -0.07506564  0.06539641 -0.0170338   0.05028331 -0.00748461  0.04577621\n",
            "   0.01825489  0.02218426 -0.00531026  0.04543733 -0.03769226 -0.05184881\n",
            "   0.04782514 -0.05504985  0.07803957  0.06223227 -0.01961266  0.0680891\n",
            "   0.02015051 -0.03161263  0.02803529  0.07108957 -0.04671321  0.03504841\n",
            "   0.02827871  0.04171757  0.03690924  0.02445211  0.03632823 -0.03938198\n",
            "  -0.02023896 -0.07727666 -0.01587432  0.03480219 -0.05179826  0.0690917\n",
            "  -0.00607706 -0.00732425  0.05389569 -0.05817195  0.00987784 -0.04900206\n",
            "   0.06446304  0.03174211 -0.02998599 -0.03340634  0.02072212 -0.04814125\n",
            "   0.05308089 -0.08165958  0.04276686  0.056452    0.02496929 -0.03711965\n",
            "  -0.07200599 -0.06475192]] \n",
            "\n",
            "Length of embedded sentence : \n",
            " 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model with keras API\n",
        "\n",
        "inputs = layers.Input( shape = [] , dtype = tf.string)\n",
        "x = sentence_encoder_layer(inputs)\n",
        "x = layers.Dense( 128 , activation = \"relu\")(x)\n",
        "outputs = layers.Dense( num_classes , activation = \"softmax\")(x)\n",
        "\n",
        "model_2 = tf.keras.Model( inputs , outputs )\n",
        "\n",
        "# Compile a model\n",
        "model_2.compile(loss = [\"categorical_crossentropy\"] ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "# Fit the model\n",
        "hist_2 = model_2.fit(\n",
        "    train_dataset ,\n",
        "    epochs = 3 ,  # Eğer daha hızlı process istiyorsak burda steps_per_epoch = int( len(0.1 * len(train_dataset))) yapabiliriz ama böyle yaptıgımızda modelimiz train datamızın sadece %10 u ile train oluyor.\n",
        "    validation_data = val_dataset\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW9G3uSdlMdK",
        "outputId": "4dea6b40-b4df-41ef-ad53-686194294a59"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "5627/5627 [==============================] - 80s 14ms/step - loss: 0.7280 - accuracy: 0.7213 - val_loss: 0.6546 - val_accuracy: 0.7506\n",
            "Epoch 2/3\n",
            "5627/5627 [==============================] - 76s 13ms/step - loss: 0.6334 - accuracy: 0.7596 - val_loss: 0.6187 - val_accuracy: 0.7653\n",
            "Epoch 3/3\n",
            "5627/5627 [==============================] - 74s 13ms/step - loss: 0.5991 - accuracy: 0.7739 - val_loss: 0.6047 - val_accuracy: 0.7712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMSXdZ61xmQf",
        "outputId": "449cbad8-cccb-4ee9-dfda-01a44af15370"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 21s 22ms/step - loss: 0.6047 - accuracy: 0.7712\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6047007441520691, 0.7712167501449585]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(val_dataset)\n",
        "model_2_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpcwVh7PxoFq",
        "outputId": "54325650-2793-4be9-a2ed-a95ea8e84e41"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 14s 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.8449662e-01, 2.9371664e-01, 9.3615054e-05, 1.1943516e-01,\n",
              "        2.2579804e-03],\n",
              "       [3.6432031e-01, 5.1467067e-01, 8.8574417e-04, 1.1948601e-01,\n",
              "        6.3729804e-04],\n",
              "       [5.6958061e-01, 2.4035919e-02, 1.9774001e-02, 3.7085393e-01,\n",
              "        1.5755536e-02],\n",
              "       ...,\n",
              "       [4.5660313e-04, 3.1012890e-04, 9.1273263e-03, 2.2698627e-04,\n",
              "        9.8987889e-01],\n",
              "       [1.0602547e-02, 7.1821824e-02, 7.6391444e-02, 2.6820132e-03,\n",
              "        8.3850217e-01],\n",
              "       [1.0294240e-02, 9.8722225e-01, 2.2527925e-03, 9.0268622e-06,\n",
              "        2.2176895e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the prediction probabilities found with feature extraction model to labels\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9td7SbOAxuS_",
        "outputId": "10b0bd3d-5b3a-423a-920b-51e68d050bc6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 0, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = calculate_results(y_true=val_labels_encoded_labelencoder,\n",
        "                                   y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRyi-gqAxxlY",
        "outputId": "6a9a3e34-2069-4780-b63b-90086bf6fe50"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.12167350721568,\n",
              " 'precision': 0.7692598015961705,\n",
              " 'recall': 0.7712167350721567,\n",
              " 'f1': 0.7671807073675014}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}