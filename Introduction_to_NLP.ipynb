{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRaF6zv/sc4qZGjM2nfw25",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MelihKlc/Deep-Learning/blob/main/Introduction_to_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to NLP with TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences or text)\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)"
      ],
      "metadata": {
        "id": "ZvR8mis3T1NF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token dediğimiz şey ya bir word ya da character oluyor. Bizim seçimimize göre"
      ],
      "metadata": {
        "id": "b8Pm1RjSdFCV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZDpxXx5A_kL",
        "outputId": "31e0b2ae-1657-4202-9478-976e5ad82e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-18 14:22:43--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-18 14:22:43 (59.2 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback , plot_loss_curves , compare_historys , unzip_data , walk_through_dir , calculate_results"
      ],
      "metadata": {
        "id": "xCejjNfzSTlJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the text data\n",
        "\n",
        "The dataset we are going to use it NLP dataset for text samples tweets labelled as disaster or not disaster"
      ],
      "metadata": {
        "id": "BIEadC1JTde3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGuVddupW7y6",
        "outputId": "985a0857-235b-4aa6-ecec-5ac9579c787d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-18 14:22:46--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.119.128, 108.177.121.128, 142.250.1.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.119.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip.1’\n",
            "\n",
            "\r          nlp_getti   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-08-18 14:22:47 (115 MB/s) - ‘nlp_getting_started.zip.1’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "id": "Dt_Hb9aVXBpI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Become one with the data"
      ],
      "metadata": {
        "id": "1CXRD5ekXLeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing our text dataset\n",
        "\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eIAbKE5MbRu4",
        "outputId": "141b3008-ec46-4eca-9506-9648f57df3c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c75d42bf-e95f-41f8-b37d-715040195c72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c75d42bf-e95f-41f8-b37d-715040195c72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c75d42bf-e95f-41f8-b37d-715040195c72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c75d42bf-e95f-41f8-b37d-715040195c72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6bc7d711-0d2d-41cd-ad20-4d9494cc35b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6bc7d711-0d2d-41cd-ad20-4d9494cc35b2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6bc7d711-0d2d-41cd-ad20-4d9494cc35b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If target label has 1 , it means that our sentence is about disasters\n",
        "\n",
        "train_df[\"text\"][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BmxsyZAAbjho",
        "outputId": "cfd3796c-cee6-41f5-a6d2-be1a6778f8cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Forest fire near La Ronge Sask. Canada'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training data because of we dont want to be overfitting\n",
        "\n",
        "train_df_shuffled = train_df.sample(frac = 1 , random_state = 42) # Frac = 1 dememizin sebebi bütün datamızı shuffle etmek istiyoruz.\n"
      ],
      "metadata": {
        "id": "peBiGpVFdUoY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the our test_dataset look like?\n",
        "\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "c1k0HwrydA8V",
        "outputId": "8787b535-a5ac-479a-bf48-82c989f4cbc2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e749d1a-a9a7-4e4c-8a2d-f63926544eee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e749d1a-a9a7-4e4c-8a2d-f63926544eee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e749d1a-a9a7-4e4c-8a2d-f63926544eee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e749d1a-a9a7-4e4c-8a2d-f63926544eee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ee086cd-d8d7-403a-9d8d-e1ec4ec41e47\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ee086cd-d8d7-403a-9d8d-e1ec4ec41e47')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ee086cd-d8d7-403a-9d8d-e1ec4ec41e47 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ituWtfoOd6IF",
        "outputId": "5f11db7d-3562-46a1-ed59-5d1033908e17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many total samples?\n",
        "\n",
        "len(train_df) , len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_mAXEjKeotz",
        "outputId": "669b517c-da81-4a8b-af5c-2e9667f40f08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets visualize some random training examples.\n",
        "import random\n",
        "random_index = random.randint( 0 , len(train_df) - 5)  # Create random indexes not higher than the total number of samples\n",
        "\n",
        "for row in train_df[[\"text\" , \"target\"]][random_index : random_index + 5].itertuples():  # Bu satırda, train_df veri çerçevesinde rastgele seçilen 5 satırı (veya kalan kadar satır varsa) içeren bir alt veri çerçevesini seçiyoruz. Sadece \"text\" ve \"target\" sütunlarını seçiyoruz. itertuples() işlevi, seçilen satırları birer birer dönmek için kullanılır.\n",
        "  _ , text , target = row\n",
        "  print(f\"Target : {target} \" , \"(real_disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n {text}\")\n",
        "  print(\"---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCQxOzetf3qo",
        "outputId": "01392cc4-b647-4c0f-f459-e5e4d400ec8f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target : 0  (not real disaster)\n",
            "Text:\n",
            " I can't listen to Darude Sandstorm without expecting airhorns now\n",
            "---\n",
            "\n",
            "Target : 0  (not real disaster)\n",
            "Text:\n",
            " Now playing: Darude - Sandstorm - radio edit http://t.co/DUdAIrBBPo http://t.co/padosfyXnM\n",
            "---\n",
            "\n",
            "Target : 1  (real_disaster)\n",
            "Text:\n",
            " Watch This Airport Get Swallowed Up By A Sandstorm In Under A Minute http://t.co/bgM4cSrbVd\n",
            "---\n",
            "\n",
            "Target : 0  (not real disaster)\n",
            "Text:\n",
            " I slammed my phone to the ground and then screamed ahahahga\n",
            "---\n",
            "\n",
            "Target : 0  (not real disaster)\n",
            "Text:\n",
            " @InfiniteGrace7 I just screamed to the world how much I love My Little Pony ??\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data into training and validation sets"
      ],
      "metadata": {
        "id": "NYyM_c2vmbwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences , val_sentences , train_labels , val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy() ,train_df_shuffled[\"target\"].to_numpy() , test_size=0.1 , random_state = 42)"
      ],
      "metadata": {
        "id": "bLiead7ynr2C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences) , len(val_sentences) , len(train_labels) , len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coxzmsW3oZ_O",
        "outputId": "ead40628-1c62-4c87-9c1a-fda7eb1867f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 762, 6851, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Check the first 10 samples\n",
        "\n",
        " train_sentences[ : 10] , train_labels[ : 10]  # Train sentence içindeki cümleler train_labels taki outputlarla eşleşiyor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_sGU2OFox9E",
        "outputId": "f54c4f28-7563-480c-ba15-5bf5ae970865"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object),\n",
              " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting text into numbers\n",
        "\n",
        "When dealing with a text problem , one of the first things you will have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this namely:\n",
        "* Tokenization - Direct mapping of token (a token could be a word or a character) to number.\n",
        "* Embedding - Create a matrix of feature vector for each token (the size of the feature vector can be and this embedding can be learn)"
      ],
      "metadata": {
        "id": "puq9UADUsMiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text vectorization (tokenization , Converting text into numbers)"
      ],
      "metadata": {
        "id": "-Kb5K5HJx5ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "#ngram substringleri birleştiriyor. Mesela elimizde 'Imagine getting flattened by Kurt Zouma' cümlesi var. ngram = 2 dersek , \"Image getting\" , \"flattened by\" , \"Kurt Zouma\"  gibi ikişer ikişer substringleri birleştiriyor.\n",
        "\n",
        "# Default values of TextVectorization\n",
        "text_vectorizer = TextVectorization(max_tokens = 10000 , # How many words in the vocabulary ( automatically add <00V>)\n",
        "                                                        standardize = \"lower_and_strip_punctuation\" ,  # Bütün harfleri küçük yapıp noktalama işaretlerini siliyor çünkü bunlar disaster olup olmadıgını anlamamıza yardım eden şeyler değil.\n",
        "                                                        split = \"whitespace\"  , # Tokenlar arasında boşluk bırakmak için.\n",
        "                                                        ngrams = None , # Create a groups of n-word\n",
        "                                                        output_mode = \"int\" , # How to map tokens to number\n",
        "                                                        output_sequence_length = None , # How long do you want your sequences to be. (None atadıgımızda en uzun tokeni alıp bütün tokenlere o lengthi veriyor. Kısa olan sentences ların sonu 0 larla dolduruluyor.)\n",
        "                                                        pad_to_max_tokens = True\n",
        "                                    )"
      ],
      "metadata": {
        "id": "Cxtb395wx_hk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[0].split()  # Split bu işe yarıyor."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlYkq6mh7x7v",
        "outputId": "24d9277a-da2e-401e-fadc-d1d9fbb02978"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "# We could just pad them to the longest , but to keep our data small , we will just find the average lenght and then make sure every tweet gets turned into numbers but those list of numbers is the same size as the average throughout every sample.\n",
        "\n",
        "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErtEgSI522eS",
        "outputId": "461e8653-bbcc-4705-80c4-a93109a646b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization variables.\n",
        "\n",
        "max_vocab_length = 10000 # Max number of words to have in our vocabulary\n",
        "max_length = 15 # Max length our sequences will be (e.g. How many words from a Tweet does model see?). Mesela tweet 30 kelime uzunlugunda ama biz bunu 15 atadıgımız icin modelimiz ilk 15 kelimesini görecek\n",
        "\n",
        "# Uptading our textvectorizer\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length ,  # Bizim bütün tweetlerimizden 10000 tane alacak bu 10000 most common lardan oluşacak\n",
        "                                    output_mode = \"int\" ,\n",
        "                                    output_sequence_length = max_length\n",
        "                                    )\n"
      ],
      "metadata": {
        "id": "lrsM1zLI7ul9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5Ltg-bK_vK8",
        "outputId": "091bb396-235c-4bc5-e066-1a0bb29e75f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       ...,\n",
              "       'Near them on the sand half sunk a shattered visage lies... http://t.co/0kCCG1BT06',\n",
              "       \"kesabaran membuahkan hasil indah pada saat tepat! life isn't about waiting for the storm to pass it's about learning to dance in the rain.\",\n",
              "       \"@ScottDPierce @billharris_tv @HarrisGle @Beezersun I'm forfeiting this years fantasy football pool out of fear I may win n get my ass kicked\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "\n",
        "text_vectorizer.adapt(train_sentences)  # CNN deki fit işlemi gibi artık bütün train sentenceslarımıza text_vectorizerde ne yapılmasını istediysek uygulanacak."
      ],
      "metadata": {
        "id": "ghmETMAUAP2J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We are trying to do here is map the word data that we have to numerical form"
      ],
      "metadata": {
        "id": "MTAP8ZoNB8Qv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "\n",
        "text_vectorizer([sample_sentence])   # Text vectorizer ı biz liste şeklinde oluşturdugumuz icin girdigimiz örnekleri [ ] içinde yazıyoruz.\n",
        "# Burda shape in 0. indexi sequence i veriyor. 1 tam cümle girdiğimiz için sequence 1.\n",
        "# Shape in 1. indexi de length veriyor. Max olarak 15 dediğimiz için buna adapt oluyo bizim sample ımız."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7RJ4k3QCb09",
        "outputId": "adb8ef6a-52cf-4a22-d4db-255b4e2d08e3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from our train_sentences data\n",
        "\n",
        "import random\n",
        "random_sentences = random.choice(train_sentences)\n",
        "\n",
        "print(f\"Original sentence : \\n {random_sentences} \\n\\n  Vectorized form of our random sentence: \\n\")\n",
        "text_vectorizer([random_sentences])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "445VsnFkCwfu",
        "outputId": "0db3d8c0-96f1-4583-8ddc-8b31e8bd433c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence : \n",
            " @SergioPiaggio 'IÛªd worked so hard to get to that level that I wasnÛªt going to let the injury define me. I was going to define it.Û Cool \n",
            "\n",
            "  Vectorized form of our random sentence: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[8643, 5331, 1733,   28,  892,    5,   52,    5,   16,  813,   16,\n",
              "           8, 6913,  104,    5]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()  # Get all of the unique words in our training data\n",
        "top_5_words = words_in_vocab[ : 5 ] # Get the most common words in our data\n",
        "bottom_5_words = words_in_vocab[ -5 :  ] # Get the least common words\n",
        "\n",
        "print(f\"Number of words in vocab : {len(words_in_vocab)} \\n\")\n",
        "print(f\"Most common words : {top_5_words} \\n\")\n",
        "print(f\"Least common words  : {bottom_5_words} \\n\")"
      ],
      "metadata": {
        "id": "d9b3ZBmZEOD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2133e1f4-f8ae-4c46-f305-4020398477d0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab : 10000 \n",
            "\n",
            "Most common words : ['', '[UNK]', 'the', 'a', 'in'] \n",
            "\n",
            "Least common words  : ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding we are going to use TensorFlow embedding layer.\n",
        "\n",
        "The parameters we care most about for our embedding layers\n",
        "\n",
        "* 'input_dim' : the size of our vocabulary\n",
        "* 'output_dim' : the size of the output embedding vector , for example , a value of 100 would mean each token gets represented by a vector 100 long.\n",
        "* 'input_length' : lenght of the sequences being passed to the embedding layer."
      ],
      "metadata": {
        "id": "rpG4T0zpFx86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Note** : Neural networks 8 e bölünebilen sayılarla çok iyi çalışıyor"
      ],
      "metadata": {
        "id": "5cYwAyvhg9uY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding( input_dim = max_vocab_length ,  # set input shape\n",
        "                             output_dim = 128 , # Output shape. Every token in the format of 128 long vector\n",
        "                              input_length = max_length  # How long is each input\n",
        "                              )"
      ],
      "metadata": {
        "id": "ycuzyABpijy3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from our training data\n",
        "\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text : \\n {random_sentence}\\n\")\n",
        "print(\"Embedded form\")\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))  # Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRVhucTKj8Fi",
        "outputId": "b075c49d-ef46-4c27-d47c-dd600ba8470d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text : \n",
            " Demolition Means Progress: Flint Michigan and the Fate of the American Metropolis Highsmith https://t.co/ZvoBMDxHGP\n",
            "\n",
            "Embedded form\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.02536899,  0.04975064,  0.04531486, ...,  0.04033859,\n",
              "          0.02942633,  0.01726137],\n",
              "        [-0.00965609,  0.03112185,  0.01632122, ..., -0.01998364,\n",
              "         -0.00841166,  0.03210044],\n",
              "        [-0.01363263, -0.04059486,  0.00960726, ...,  0.0269217 ,\n",
              "         -0.01254296,  0.04731056],\n",
              "        ...,\n",
              "        [-0.01412129, -0.02558997,  0.03156263, ..., -0.02259362,\n",
              "          0.03602357, -0.01284522],\n",
              "        [-0.01412129, -0.02558997,  0.03156263, ..., -0.02259362,\n",
              "          0.03602357, -0.01284522],\n",
              "        [-0.00050489, -0.03629545,  0.03552065, ...,  0.00640681,\n",
              "         -0.04900563,  0.04188022]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "\n",
        "sample_embed[0][0] , sample_embed[0][0].shape , sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrOmrtw3kr_s",
        "outputId": "7b5ceec5-5fe1-436f-8c28-a8aef8c875d6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-2.5368989e-02,  4.9750637e-02,  4.5314860e-02,  5.1313639e-03,\n",
              "         3.6592294e-02,  1.0269992e-03,  3.7733022e-02,  3.0495692e-02,\n",
              "        -1.0252379e-02,  2.0583678e-02, -3.1429686e-02, -4.2386364e-02,\n",
              "         1.1711717e-03,  2.5520828e-02, -3.0533804e-02, -4.6086907e-03,\n",
              "         2.4970416e-02,  3.9121162e-02, -1.4882050e-02, -3.4789313e-02,\n",
              "        -4.6104420e-02,  2.8650835e-04,  1.4943842e-02,  4.7540776e-03,\n",
              "         2.1904718e-02,  1.2770090e-02,  4.4552866e-02, -4.8190467e-03,\n",
              "        -4.6311796e-02, -2.8489470e-02,  3.6288425e-04, -3.0012727e-03,\n",
              "         4.9475227e-02, -2.3742605e-02, -5.2202493e-05, -3.7650466e-02,\n",
              "         3.2933664e-02,  2.3520473e-02,  2.4384093e-02, -1.7920494e-02,\n",
              "         4.8910905e-02,  8.0694556e-03, -7.3417649e-03,  2.0037506e-02,\n",
              "         1.0574758e-02, -4.7010422e-02,  2.6305329e-02,  4.3807913e-02,\n",
              "         2.5681440e-02, -4.9889721e-02,  3.6801483e-02, -4.8700668e-02,\n",
              "         6.8055615e-03, -2.3325801e-02, -2.2750307e-02,  3.0465212e-02,\n",
              "         3.0548278e-02, -3.9830804e-02, -2.3626601e-02,  1.3093177e-02,\n",
              "         1.6358707e-02, -4.6927121e-02, -4.6546437e-02,  3.5582934e-02,\n",
              "         8.9337714e-03,  2.6528124e-02,  1.5978348e-02, -3.0374043e-03,\n",
              "         3.2490555e-02, -7.2672218e-04, -2.7375221e-03, -2.8328896e-03,\n",
              "        -1.1902858e-02,  9.9163279e-03, -4.4152644e-02, -9.5018968e-03,\n",
              "        -1.3183594e-02,  4.3355934e-03, -1.9252313e-02, -2.6424205e-02,\n",
              "        -1.8165328e-02, -6.5235384e-03, -3.5926353e-02,  4.7261130e-02,\n",
              "         1.1974167e-02,  1.8562410e-02, -1.8049240e-02,  1.1444319e-02,\n",
              "         3.2297485e-03, -1.5732072e-02,  2.8575335e-02,  2.5167856e-02,\n",
              "         1.5182011e-03, -9.7645894e-03, -2.4107194e-02,  4.5914043e-02,\n",
              "         1.5927020e-02,  3.6196578e-02,  3.5258774e-02, -1.0373723e-02,\n",
              "        -3.9816581e-02, -4.8929859e-02, -4.4647276e-02,  1.3709333e-02,\n",
              "        -4.5513500e-02,  3.9816927e-02, -4.6577718e-02, -1.1152793e-02,\n",
              "         4.5127753e-02,  1.2939010e-02,  3.3129189e-02, -1.0005511e-02,\n",
              "         4.1301623e-03, -2.5808103e-03,  4.1971359e-02,  1.0982156e-02,\n",
              "         4.5645822e-02, -2.3480281e-03,  2.0743236e-03,  1.2065791e-02,\n",
              "         2.7317192e-02,  2.5201488e-02, -2.1958161e-02,  4.4916902e-02,\n",
              "        -7.7698380e-04,  4.0338587e-02,  2.9426325e-02,  1.7261375e-02],\n",
              "       dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " <tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[-0.02536899,  0.04975064,  0.04531486, ...,  0.04033859,\n",
              "           0.02942633,  0.01726137],\n",
              "         [-0.00965609,  0.03112185,  0.01632122, ..., -0.01998364,\n",
              "          -0.00841166,  0.03210044],\n",
              "         [-0.01363263, -0.04059486,  0.00960726, ...,  0.0269217 ,\n",
              "          -0.01254296,  0.04731056],\n",
              "         ...,\n",
              "         [-0.01412129, -0.02558997,  0.03156263, ..., -0.02259362,\n",
              "           0.03602357, -0.01284522],\n",
              "         [-0.01412129, -0.02558997,  0.03156263, ..., -0.02259362,\n",
              "           0.03602357, -0.01284522],\n",
              "         [-0.00050489, -0.03629545,  0.03552065, ...,  0.00640681,\n",
              "          -0.04900563,  0.04188022]]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling a text dataset (running a series of experimentation)\n",
        "\n",
        "Now we have got a way to turn our text sequences into numbers , it is time to start building a series of modelling experiments.\n",
        "\n",
        "We will start with a baseline and move on from there\n",
        "\n",
        "* Model 0 : Naive Bayes (baseline)\n",
        "* Model 1 : Feed-forward neural network\n",
        "* Model 2 : LSTM model (RNN)\n",
        "* Model 3 : GRU model (RNN)\n",
        "* Model 4 : Bidirectional LSTM (RNN)\n",
        "* Model 5 : 1D Convolutional neural network (CNN)\n",
        "* Model 6 : TensorFlow Hub pre-trained Feature extractor (using transfer learning for NLP)\n",
        "* Model 7 : Same as model 6 but with %10 of training data\n",
        "\n",
        "How are we going to approach all of this ?\n",
        "\n",
        "Use standart steps in modelling with tensorflow\n",
        "\n",
        "* Create a model\n",
        "* Compile o model\n",
        "* Fit the model\n",
        "* Evaluate the model"
      ],
      "metadata": {
        "id": "JVEyYcflme3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0 : Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments , it is important to create a baseline model so you have got a benchmark for future experiments to build upon\n",
        "\n",
        "To create our baseline, We will use sklearn Multinomial naive bayes using the TF-IDF formula to convert our words to numbers.\n",
        "\n",
        "> **Note:** It is common practice to use non deep learning algorithms as a baseline because of their speed then later using deep learning to see if you can improve upon them"
      ],
      "metadata": {
        "id": "1p_NRd-ZwU8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "\n",
        "model_0 = Pipeline(\n",
        "    [\n",
        "     (\"tfidf\" , TfidfVectorizer())   , # Convert words to numbers using tfidf\n",
        "     (\"clf\" , MultinomialNB() ) # Model to text\n",
        "\n",
        "    ]\n",
        "\n",
        ")\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences , train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "BRBD5msOw3WJ",
        "outputId": "24c80a5b-bca8-4577-dd70-efed4380a6de"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our model\n",
        "baseline_score = model_0.score(val_sentences , val_labels)  # In sklearn we use score instead of evaluate\n",
        "baseline_score\n",
        "# Bu bize accuracy veriyor.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLVHX8tB_e4n",
        "outputId": "0757429b-35ef-4eab-dac8-c4232e191444"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7926509186351706"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[ : 20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuayiquOBdFZ",
        "outputId": "9482f1e0-a116-456f-8922-db516d3cbf8b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels[ : 20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWgjef0nB9lx",
        "outputId": "cf49da32-d680-4fb8-e852-41018e6aca2a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating an evaluation function for our model experiment\n",
        "\n",
        "We could evaluate all of our model's predictions with different metrics every time , however , this will be cumbersome(hantal) and could easliy be fixed with a function\n",
        "\n",
        "Lets create one to compare our model's predictions with the truth labels using following metrices\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ],
      "metadata": {
        "id": "Km8tnsouCDZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate : accuracy , precision , recall , f1-score\n",
        "from sklearn.metrics import accuracy_score , precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true , y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy , precision , recall and f1 score of a binary classification model\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true , y_pred)\n",
        "\n",
        "  # Calculate model precision , recall and f1 score using \"weighted\" average\n",
        "\n",
        "  model_precision , model_recall , model_f1 , _ = precision_recall_fscore_support(y_true , y_pred , average = \"weighted\")\n",
        "  model_results = {\n",
        "      \"accuracy\": model_accuracy ,\n",
        "      \"precision\": model_precision ,\n",
        "      \"recall\": model_recall ,\n",
        "      \"f1-score\": model_f1\n",
        "  }\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "FXRAxCnSI9x6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model results\n",
        "\n",
        "baseline_results = calculate_results(y_true = val_labels ,\n",
        "                                     y_pred = baseline_preds\n",
        "                                     )\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUIDlpVTLc5X",
        "outputId": "da1c0193-b04d-435d-c480-ebb055bc9886"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7926509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 : A simple dense model"
      ],
      "metadata": {
        "id": "__OqmlrKLnZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save Tensorboard logs\n",
        "save_dir = \"model_logs\""
      ],
      "metadata": {
        "id": "bTr9HwMlOL36"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a model with Functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape = (1,) , dtype = tf.string)  # shape = (1 , ) çünkü it is going to see one sequence at a time\n",
        "x = text_vectorizer(inputs)  # Turn the input text into numbers\n",
        "x = embedding(x) # Create an embedding of the numberized inputs.\n",
        "x = layers.GlobalAveragePooling1D()(x) # Lower the dimensionality of the embedding. Eğer pooling layer eklemezsek her token için ayrı ayrı predict yapıyor. Pooling layer tek bir uzun vectore çeviriyor.\n",
        "outputs = layers.Dense( 1 , activation = \"sigmoid\")(x)  # Create an output layer , We have binary outputs so we use 1 hidden unit and activation will be sigmoid\n",
        "\n",
        "model_1 = tf.keras.Model(inputs , outputs , name = \"model_1_dense\")"
      ],
      "metadata": {
        "id": "fMvxm7T5Oaaz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RopoUs4_VrsH",
        "outputId": "8f91b92a-7c08-4d35-ef12-1f3de8e865af"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile a model\n",
        "model_1.compile(loss = [\"binary_crossentropy\"] ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "# Fit the model\n",
        "\n",
        "hist_1 = model_1.fit(x = train_sentences ,\n",
        "                     y = train_labels ,\n",
        "                     epochs = 5 ,\n",
        "                     validation_data = (val_sentences , val_labels)  ,\n",
        "                     callbacks = [create_tensorboard_callback(dir_name = save_dir , experiment_name = \"model_1_dense\")])   # validation datayı tuple formatta yazmamız gerekiyor."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvcSBEKzW8wI",
        "outputId": "7eab6ad0-6a5c-4d0b-8a3d-07e01d205dcb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20230818-142250\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 20ms/step - loss: 0.6105 - accuracy: 0.6916 - val_loss: 0.5376 - val_accuracy: 0.7520\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.4402 - accuracy: 0.8180 - val_loss: 0.4795 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3462 - accuracy: 0.8634 - val_loss: 0.4575 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.2839 - accuracy: 0.8920 - val_loss: 0.4609 - val_accuracy: 0.7927\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.2364 - accuracy: 0.9121 - val_loss: 0.4861 - val_accuracy: 0.7940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences , val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edri7CRRZVe_",
        "outputId": "46ad9026-7dce-4385-be25-719a816ab55a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.7940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4860583245754242, 0.7939632534980774]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_preds = model_1.predict(val_sentences)\n",
        "model_1_preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJkgOJHAZ9VK",
        "outputId": "d847c960-afbf-4eab-fe2e-35f334bc0a00"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at a single prediction\n",
        "model_1_preds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-JB7ps3aXcG",
        "outputId": "4e55c605-f318-4fc4-b41d-de44f17afa6a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.28718972], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " val_labels  # Şu an val labels ile predlerimizi karşılaştıramıyoruz çünkü biz apple to apple gibi aynı şeyleri karşılaştırmamız gerek. Zaten binary classificationdan bildigimiz üzere şu an predictlerimiz probabilities şeklinde yani 0 la 1 arasında değerler alıyor. 0.5 in üstündeki değerleri 1 olarak alıcaz altındaki değerleri ise 0 olarak alıcaz. Bu şekilde pred değerlerimizle ground truth değerleri karşılaştırabiliriz.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrvZ7wZHdXtF",
        "outputId": "0a21c8d0-dbda-4990-cb37-ecb539b2d6be"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "\n",
        "model_1_pred = tf.squeeze(tf.round(model_1_preds))\n",
        "model_1_pred[ : 10] , model_1_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0EmKlMdvaN",
        "outputId": "dc113fda-7555-4d18-b151-e93545703233"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>,\n",
              " TensorShape([762]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our model_1 results\n",
        "\n",
        "model_1_results = calculate_results(y_true = val_labels ,\n",
        "                                    y_pred = model_1_pred\n",
        "                                    )\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SYrQi2He5bF",
        "outputId": "d0e71a40-77c0-4942-bf51-3160ccfa8135"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7939632545931758,\n",
              " 'precision': 0.8025297569280951,\n",
              " 'recall': 0.7939632545931758,\n",
              " 'f1-score': 0.7900777653888648}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKMFCVxYf5s5",
        "outputId": "d18fe194-e05d-4a5d-aab7-722929420a3d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7926509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1-score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looks like our baseline is outperforming our first deep learning model"
      ],
      "metadata": {
        "id": "d38h4wXDis4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding layer en başta random değerler alıyor. Sonrasında her epochta internal weights ini uptade for each token.  "
      ],
      "metadata": {
        "id": "DT8NQZQejjC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing learned embeddings"
      ],
      "metadata": {
        "id": "bCpcpWwbj0sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giuGttxWkMzB",
        "outputId": "3a202dc8-6c24-4c8d-ef4b-d3526babe96b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# These are the numerical representation of each token in our training data\n",
        "# Getlayer kullanırken summary içindeki ismi kullanıyoruz.\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI6NvAYPkW51",
        "outputId": "a5f59bf4-4cef-4e5a-b8b6-f43a2cdd3e48"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Eter7SRluaa",
        "outputId": "558e2fff-fa12-4e85-a0fe-fcdb732057e7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we have got the embedding matrix our model has learned to represent our tokens , lets visualize this\n",
        "\n",
        "Handy tool form tensoflow : Tensorflow Projector\n",
        "\n",
        "https://www.tensorflow.org/text/guide/word_embeddings"
      ],
      "metadata": {
        "id": "-mJmsOp6l2ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embedding files\n",
        "import io\n",
        "\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "UJHomhFam9xM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To upload to projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "32nOcyxZo2OF",
        "outputId": "e87048f6-aa08-4bac-a786-fd55ecf1043e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aecf1a3d-33b1-4c5d-a796-512eecdfcb64\", \"vectors.tsv\", 15376833)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6b64942b-9fa3-4221-ad7e-b5480e9a9ce1\", \"metadata.tsv\", 80388)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequence data\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input.\n",
        "\n",
        "https://www.youtube.com/watch?v=SEnXr6v2ifU\n"
      ],
      "metadata": {
        "id": "_GHAIBs4p20k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: LSTM\n",
        "\n",
        "LSTM = Long Short Term Memory\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "'''\n",
        "Input(text) -> Tokenize -> Embedding -> Layers (RNN's / dense) -> Output(label probability)\n",
        "'''"
      ],
      "metadata": {
        "id": "wbsgg7Fpx5pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an LSTM model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape = (1 ,)  , dtype = tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#print(x.shape)\n",
        "#x = layers.LSTM(64 , return_sequences = True)(x)  # When you are stacking RNN cells together , you need to set return_sequences = True. Yani eğer birden fazla lstm layer kullanacaksak son lstm layer hariç true atamamız lazım.\n",
        "#print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.Dense(64 , activation = \"relu\")(x)\n",
        "outputs = layers.Dense(1 , activation = \"sigmoid\")(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs , outputs)\n"
      ],
      "metadata": {
        "id": "Wp7LIw3y0p34"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSqJdm8_2NlE",
        "outputId": "3802ea0c-9b7f-4c40-a5ec-c1684b76990e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile a model\n",
        "\n",
        "model_2.compile(loss = [\"binary_crossentropy\"] ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = [\"accuracy\"]\n",
        "\n",
        "                )\n",
        "\n",
        "hist_2 = model_2.fit(x = train_sentences ,\n",
        "                     y = train_labels ,\n",
        "                     epochs = 5 ,\n",
        "                     validation_data = (val_sentences , val_labels)  ,\n",
        "                     callbacks = [create_tensorboard_callback(dir_name = save_dir , experiment_name = \"model_2_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLj0L8Zh5aLr",
        "outputId": "eec0a977-4958-4f2a-e568-f94f92d1be8a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_dense/20230818-142317\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 22ms/step - loss: 0.2246 - accuracy: 0.9177 - val_loss: 0.6029 - val_accuracy: 0.7861\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.1537 - accuracy: 0.9429 - val_loss: 0.5861 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.1242 - accuracy: 0.9531 - val_loss: 0.6949 - val_accuracy: 0.7848\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 7s 32ms/step - loss: 0.1036 - accuracy: 0.9613 - val_loss: 0.7845 - val_accuracy: 0.7795\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0826 - accuracy: 0.9673 - val_loss: 0.9734 - val_accuracy: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(val_sentences , val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5H4LHvb5WDa",
        "outputId": "e72e7746-37bd-4810-88de-96aeb88de772"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.9734 - accuracy: 0.7756\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9734324216842651, 0.7755905389785767]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_preds = model_2.predict(val_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsHszMgr6Q1o",
        "outputId": "506a8bb4-4aed-4dc9-fd00-ac6e417a3f4f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_pred = tf.squeeze(tf.round(model_2_preds))\n",
        "model_2_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sufnkW8t6d3F",
        "outputId": "234eb66d-a2ab-4d26-81e4-9752574ffb92"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = calculate_results(y_true = val_labels ,\n",
        "                                    y_pred = model_2_pred\n",
        "                                    )\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uui4oF-96xeX",
        "outputId": "097af60a-cbf3-45d9-c85a-b851f769ecfb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7755905511811023,\n",
              " 'precision': 0.7790436087799748,\n",
              " 'recall': 0.7755905511811023,\n",
              " 'f1-score': 0.7728084240126466}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3 : GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell(layers) has similar features to an LSTM cell but has less parameters"
      ],
      "metadata": {
        "id": "vBN2tAjb7F0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build an RNN using the GRU cell\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape = (1,) , dtype = tf.string)\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "\n",
        "x = embedding(x)\n",
        "\n",
        "x = layers.GRU(64)(x)\n",
        "\n",
        "# x = layers.LSTM( 64 , return_sequences= True)(x)\n",
        "\n",
        "# x = layers.GRU(64)(x)  böyle de yapabiliriz göstermek icin sadece comment line a aldım.\n",
        "\n",
        "# x = layers.Dense( 64 , activation = \"relu\")(x)\n",
        "\n",
        "# x = layers.GlobalAveragePooling1D()(x)  return sequences true yaparsak global average pooling layer eklememiz gerek ama yapmazsak gerek yok.\n",
        "\n",
        "outputs = layers.Dense(1 , activation = \"sigmoid\" , name = \"output_layer\")(x)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs , outputs)\n"
      ],
      "metadata": {
        "id": "qM7zrYGg9FB-"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojMiMyWsCZoE",
        "outputId": "09da854c-32b7-4c56-b011-9afbe49ac3c3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 64)                37248     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile a model\n",
        "\n",
        "model_3.compile(loss = [\"binary_crossentropy\"] ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n"
      ],
      "metadata": {
        "id": "DMcGLqyOCbz-"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "hist_3 = model_3.fit(x = train_sentences ,\n",
        "                     y = train_labels ,\n",
        "                     epochs = 5 ,\n",
        "                     validation_data = (val_sentences , val_labels)  ,\n",
        "                     callbacks = [create_tensorboard_callback(dir_name = save_dir , experiment_name = \"model_3_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAdqG0byDp3i",
        "outputId": "a8731d74-bdda-4a96-fd0c-9bd0dc5f79d3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_dense/20230818-143159\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 21ms/step - loss: 0.1600 - accuracy: 0.9356 - val_loss: 0.6836 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.0840 - accuracy: 0.9724 - val_loss: 0.8863 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0720 - accuracy: 0.9721 - val_loss: 0.9030 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0587 - accuracy: 0.9747 - val_loss: 1.0831 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0560 - accuracy: 0.9756 - val_loss: 1.1891 - val_accuracy: 0.7677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(val_sentences , val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKShX8wkD2mw",
        "outputId": "f3cac84a-a8bc-46d7-cb82-a9c2134c389e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 9ms/step - loss: 1.1891 - accuracy: 0.7677\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.189102053642273, 0.7677165269851685]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_preds_probs = model_3.predict(val_sentences)\n",
        "model_3_preds_probs , model_3_preds_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhaXwpRwEgUA",
        "outputId": "e614e560-488a-4a04-f12b-e07c8ffe432a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[9.33567237e-04],\n",
              "        [7.86224008e-01],\n",
              "        [9.99835014e-01],\n",
              "        [1.52615368e-01],\n",
              "        [7.31422479e-05],\n",
              "        [9.99648929e-01],\n",
              "        [1.51633501e-01],\n",
              "        [9.99940634e-01],\n",
              "        [9.99859989e-01],\n",
              "        [8.72723520e-01],\n",
              "        [1.40119970e-04],\n",
              "        [7.53337026e-01],\n",
              "        [1.40699587e-04],\n",
              "        [1.96753323e-01],\n",
              "        [6.71073503e-05],\n",
              "        [1.88254868e-03],\n",
              "        [1.32227331e-04],\n",
              "        [1.13866619e-04],\n",
              "        [1.53231816e-02],\n",
              "        [9.99298871e-01],\n",
              "        [9.99843597e-01],\n",
              "        [4.11053989e-05],\n",
              "        [9.99459267e-01],\n",
              "        [9.93008609e-04],\n",
              "        [9.99783933e-01],\n",
              "        [9.99913633e-01],\n",
              "        [3.84999439e-04],\n",
              "        [6.95713679e-04],\n",
              "        [2.43780334e-04],\n",
              "        [2.73990899e-01],\n",
              "        [9.84578609e-01],\n",
              "        [8.62300803e-04],\n",
              "        [1.90395792e-03],\n",
              "        [8.19994253e-04],\n",
              "        [4.83461648e-01],\n",
              "        [2.38137498e-01],\n",
              "        [9.99788165e-01],\n",
              "        [3.17075402e-01],\n",
              "        [1.28924688e-02],\n",
              "        [9.99925733e-01],\n",
              "        [4.29809928e-01],\n",
              "        [6.72474562e-05],\n",
              "        [5.77148050e-02],\n",
              "        [1.17362346e-04],\n",
              "        [9.96462107e-01],\n",
              "        [9.99720097e-01],\n",
              "        [9.86173809e-01],\n",
              "        [9.69443023e-01],\n",
              "        [2.21614074e-03],\n",
              "        [4.04077739e-01],\n",
              "        [4.25285165e-04],\n",
              "        [4.19483989e-01],\n",
              "        [1.46754656e-03],\n",
              "        [3.74906580e-04],\n",
              "        [7.07644939e-01],\n",
              "        [1.31911468e-02],\n",
              "        [7.71908730e-04],\n",
              "        [9.99847114e-01],\n",
              "        [2.36277236e-04],\n",
              "        [3.19062412e-04],\n",
              "        [8.00734684e-02],\n",
              "        [9.99814630e-01],\n",
              "        [9.81989920e-01],\n",
              "        [8.28095153e-03],\n",
              "        [9.99923706e-01],\n",
              "        [9.99937177e-01],\n",
              "        [9.54192579e-01],\n",
              "        [1.74257886e-02],\n",
              "        [9.91906285e-01],\n",
              "        [1.45909307e-03],\n",
              "        [2.02466249e-02],\n",
              "        [3.38956155e-02],\n",
              "        [9.99930441e-01],\n",
              "        [6.44153857e-04],\n",
              "        [6.07685983e-01],\n",
              "        [9.90882456e-01],\n",
              "        [1.65900007e-01],\n",
              "        [9.99514520e-01],\n",
              "        [2.79033303e-01],\n",
              "        [3.46303396e-02],\n",
              "        [3.60959268e-04],\n",
              "        [1.45575330e-01],\n",
              "        [9.99903262e-01],\n",
              "        [2.32280305e-04],\n",
              "        [1.76124202e-04],\n",
              "        [5.94129611e-04],\n",
              "        [1.92811785e-04],\n",
              "        [1.56481110e-04],\n",
              "        [5.48514538e-04],\n",
              "        [9.99769092e-01],\n",
              "        [9.99767363e-01],\n",
              "        [9.35390854e-05],\n",
              "        [9.93810534e-01],\n",
              "        [1.12870548e-04],\n",
              "        [9.99858618e-01],\n",
              "        [8.13422084e-01],\n",
              "        [7.45839238e-01],\n",
              "        [9.99824047e-01],\n",
              "        [9.99426544e-01],\n",
              "        [9.98182476e-01],\n",
              "        [9.99966860e-01],\n",
              "        [9.03773995e-04],\n",
              "        [7.58036404e-05],\n",
              "        [9.16862011e-01],\n",
              "        [9.99504864e-01],\n",
              "        [6.07030606e-03],\n",
              "        [9.93615091e-01],\n",
              "        [9.96680319e-01],\n",
              "        [2.61954701e-04],\n",
              "        [9.98353899e-01],\n",
              "        [9.78808284e-01],\n",
              "        [3.52327566e-04],\n",
              "        [1.58000216e-02],\n",
              "        [7.86339398e-04],\n",
              "        [2.13484760e-04],\n",
              "        [1.41530000e-02],\n",
              "        [7.58506656e-01],\n",
              "        [9.73914623e-01],\n",
              "        [4.93922969e-03],\n",
              "        [1.24229278e-04],\n",
              "        [9.99936044e-01],\n",
              "        [8.01366768e-05],\n",
              "        [4.65394623e-05],\n",
              "        [8.33420515e-01],\n",
              "        [2.18277355e-03],\n",
              "        [3.41325649e-04],\n",
              "        [9.99829054e-01],\n",
              "        [6.27438785e-05],\n",
              "        [7.48882128e-04],\n",
              "        [9.96820748e-01],\n",
              "        [4.28417523e-04],\n",
              "        [9.99936044e-01],\n",
              "        [9.99953628e-01],\n",
              "        [9.99913633e-01],\n",
              "        [9.99648213e-01],\n",
              "        [1.49807820e-04],\n",
              "        [9.99816656e-01],\n",
              "        [4.54581603e-02],\n",
              "        [2.73089297e-03],\n",
              "        [3.26512352e-04],\n",
              "        [9.99926090e-01],\n",
              "        [7.92784989e-01],\n",
              "        [1.96753323e-01],\n",
              "        [9.99289870e-01],\n",
              "        [1.65488124e-01],\n",
              "        [3.97799740e-04],\n",
              "        [9.24846972e-05],\n",
              "        [5.64093243e-05],\n",
              "        [3.05663906e-02],\n",
              "        [9.99747813e-01],\n",
              "        [3.04256595e-04],\n",
              "        [3.03127207e-02],\n",
              "        [2.33359262e-03],\n",
              "        [1.58555165e-04],\n",
              "        [1.05788182e-04],\n",
              "        [9.99430776e-01],\n",
              "        [8.30132067e-01],\n",
              "        [1.67090935e-03],\n",
              "        [9.98891294e-01],\n",
              "        [1.49417654e-04],\n",
              "        [9.99597073e-01],\n",
              "        [6.75558520e-04],\n",
              "        [4.83280560e-03],\n",
              "        [9.96294856e-01],\n",
              "        [1.38787672e-01],\n",
              "        [5.17032167e-05],\n",
              "        [9.99877989e-01],\n",
              "        [2.10212339e-02],\n",
              "        [9.99787390e-01],\n",
              "        [6.86576664e-01],\n",
              "        [9.99815702e-01],\n",
              "        [9.91850972e-01],\n",
              "        [9.99369442e-01],\n",
              "        [1.92973661e-04],\n",
              "        [9.99966383e-01],\n",
              "        [2.04292548e-04],\n",
              "        [7.20962067e-04],\n",
              "        [2.42535840e-03],\n",
              "        [7.85157859e-01],\n",
              "        [9.99848604e-01],\n",
              "        [5.55148348e-04],\n",
              "        [6.84040964e-01],\n",
              "        [9.99203444e-01],\n",
              "        [9.99873221e-01],\n",
              "        [9.99880433e-01],\n",
              "        [1.78128903e-04],\n",
              "        [3.08041606e-04],\n",
              "        [9.99969244e-01],\n",
              "        [6.86611820e-05],\n",
              "        [5.64369257e-05],\n",
              "        [4.02167626e-03],\n",
              "        [9.94715691e-01],\n",
              "        [2.15773878e-04],\n",
              "        [1.57106653e-04],\n",
              "        [1.20443896e-04],\n",
              "        [4.52589768e-04],\n",
              "        [2.10601138e-04],\n",
              "        [4.33797482e-03],\n",
              "        [9.99571085e-01],\n",
              "        [3.67967878e-04],\n",
              "        [1.15152411e-02],\n",
              "        [9.99845803e-01],\n",
              "        [9.99618053e-01],\n",
              "        [7.81714276e-04],\n",
              "        [2.68534059e-04],\n",
              "        [9.99820650e-01],\n",
              "        [9.99610305e-01],\n",
              "        [9.99652982e-01],\n",
              "        [9.86024499e-01],\n",
              "        [9.89263594e-01],\n",
              "        [1.55979651e-03],\n",
              "        [9.99809265e-01],\n",
              "        [1.17817042e-04],\n",
              "        [1.98911352e-04],\n",
              "        [9.20623497e-05],\n",
              "        [9.39718084e-05],\n",
              "        [9.99857187e-01],\n",
              "        [8.86892796e-01],\n",
              "        [9.97183144e-01],\n",
              "        [4.12117600e-01],\n",
              "        [3.31027359e-01],\n",
              "        [1.13139465e-03],\n",
              "        [8.19281151e-04],\n",
              "        [6.54592877e-03],\n",
              "        [9.99804139e-01],\n",
              "        [6.06259517e-02],\n",
              "        [2.45736074e-03],\n",
              "        [9.99958336e-01],\n",
              "        [9.97329354e-01],\n",
              "        [6.81477904e-01],\n",
              "        [1.15016483e-04],\n",
              "        [1.98234152e-03],\n",
              "        [9.96956885e-01],\n",
              "        [2.96694100e-01],\n",
              "        [5.22389650e-01],\n",
              "        [1.55852046e-02],\n",
              "        [4.39168606e-03],\n",
              "        [1.71894077e-02],\n",
              "        [4.02615522e-04],\n",
              "        [1.97959089e-04],\n",
              "        [9.91126597e-01],\n",
              "        [2.44954857e-03],\n",
              "        [9.99855876e-01],\n",
              "        [9.99757230e-01],\n",
              "        [5.59048785e-04],\n",
              "        [7.95449450e-05],\n",
              "        [9.99726295e-01],\n",
              "        [1.57679489e-04],\n",
              "        [1.30813278e-03],\n",
              "        [1.69848278e-01],\n",
              "        [1.82978678e-04],\n",
              "        [9.98806953e-01],\n",
              "        [4.69689148e-05],\n",
              "        [1.58233824e-03],\n",
              "        [9.99725401e-01],\n",
              "        [1.38853014e-01],\n",
              "        [9.99616027e-01],\n",
              "        [9.99943376e-01],\n",
              "        [5.04201353e-02],\n",
              "        [1.27445266e-04],\n",
              "        [1.99281983e-03],\n",
              "        [1.24708647e-04],\n",
              "        [3.01451819e-05],\n",
              "        [9.99671698e-01],\n",
              "        [9.99877810e-01],\n",
              "        [2.57918425e-02],\n",
              "        [9.99624193e-01],\n",
              "        [1.85810015e-04],\n",
              "        [7.94359483e-04],\n",
              "        [1.21400801e-04],\n",
              "        [3.81101883e-04],\n",
              "        [9.55314536e-05],\n",
              "        [9.99723196e-01],\n",
              "        [1.03475607e-03],\n",
              "        [7.54351568e-05],\n",
              "        [9.99762475e-01],\n",
              "        [6.34821045e-05],\n",
              "        [1.38067539e-04],\n",
              "        [9.99701500e-01],\n",
              "        [1.83308366e-04],\n",
              "        [6.36056205e-03],\n",
              "        [6.96473289e-05],\n",
              "        [9.99753773e-01],\n",
              "        [7.96508312e-01],\n",
              "        [5.90081453e-01],\n",
              "        [6.18915586e-03],\n",
              "        [9.95953798e-01],\n",
              "        [3.20462883e-03],\n",
              "        [9.99366641e-01],\n",
              "        [1.55754504e-03],\n",
              "        [9.98794675e-01],\n",
              "        [9.82144535e-01],\n",
              "        [9.50628638e-01],\n",
              "        [5.15344692e-03],\n",
              "        [5.72949473e-04],\n",
              "        [2.76896983e-01],\n",
              "        [1.30723231e-03],\n",
              "        [2.48598796e-03],\n",
              "        [2.35036088e-04],\n",
              "        [1.98932234e-02],\n",
              "        [3.36084886e-05],\n",
              "        [2.00857801e-04],\n",
              "        [2.05887705e-02],\n",
              "        [9.99889851e-01],\n",
              "        [2.40480033e-04],\n",
              "        [1.82363745e-02],\n",
              "        [1.02157975e-02],\n",
              "        [2.39888772e-01],\n",
              "        [2.53601894e-02],\n",
              "        [2.49555218e-04],\n",
              "        [1.23011356e-04],\n",
              "        [9.99310017e-01],\n",
              "        [2.45660573e-01],\n",
              "        [4.29353714e-01],\n",
              "        [9.99962866e-01],\n",
              "        [1.46943639e-04],\n",
              "        [9.29941356e-01],\n",
              "        [1.31709769e-01],\n",
              "        [3.75304022e-03],\n",
              "        [1.66619644e-01],\n",
              "        [2.07177669e-04],\n",
              "        [1.08884936e-02],\n",
              "        [9.99221742e-01],\n",
              "        [1.54771432e-01],\n",
              "        [9.99817967e-01],\n",
              "        [2.53472298e-01],\n",
              "        [1.35582566e-04],\n",
              "        [9.99838471e-01],\n",
              "        [2.65208073e-04],\n",
              "        [9.99860704e-01],\n",
              "        [3.72742332e-04],\n",
              "        [3.01921536e-04],\n",
              "        [9.99842167e-01],\n",
              "        [1.21871955e-04],\n",
              "        [1.60868076e-04],\n",
              "        [9.99692976e-01],\n",
              "        [1.40052260e-04],\n",
              "        [4.68913605e-03],\n",
              "        [7.88621426e-01],\n",
              "        [9.97766972e-01],\n",
              "        [1.19407137e-04],\n",
              "        [6.07463648e-04],\n",
              "        [9.99745786e-01],\n",
              "        [9.99906898e-01],\n",
              "        [9.98183966e-01],\n",
              "        [3.82945277e-02],\n",
              "        [9.72078979e-01],\n",
              "        [9.98028040e-01],\n",
              "        [5.81028289e-04],\n",
              "        [2.31519254e-04],\n",
              "        [2.60016173e-02],\n",
              "        [7.83825200e-03],\n",
              "        [9.39476158e-05],\n",
              "        [2.69772299e-03],\n",
              "        [3.73880640e-02],\n",
              "        [1.15308700e-04],\n",
              "        [9.99745429e-01],\n",
              "        [9.99913633e-01],\n",
              "        [9.99916017e-01],\n",
              "        [2.31826736e-04],\n",
              "        [2.72857398e-01],\n",
              "        [1.97654106e-02],\n",
              "        [4.41320688e-02],\n",
              "        [9.97757792e-01],\n",
              "        [4.04040694e-01],\n",
              "        [6.52059534e-05],\n",
              "        [4.77346039e-04],\n",
              "        [2.29217185e-04],\n",
              "        [9.97560501e-01],\n",
              "        [1.31299326e-04],\n",
              "        [8.73987505e-04],\n",
              "        [3.62246617e-04],\n",
              "        [2.60405825e-04],\n",
              "        [9.73081216e-02],\n",
              "        [9.24707472e-01],\n",
              "        [1.09760210e-01],\n",
              "        [2.37795990e-04],\n",
              "        [5.87165996e-04],\n",
              "        [7.03208934e-05],\n",
              "        [9.99894857e-01],\n",
              "        [9.99556541e-01],\n",
              "        [6.25486255e-01],\n",
              "        [9.01520789e-01],\n",
              "        [9.32311523e-05],\n",
              "        [9.10846710e-01],\n",
              "        [9.99887347e-01],\n",
              "        [9.08373833e-01],\n",
              "        [9.36531723e-02],\n",
              "        [9.99571323e-01],\n",
              "        [3.44070583e-03],\n",
              "        [9.99903023e-01],\n",
              "        [2.98506464e-03],\n",
              "        [4.78570728e-04],\n",
              "        [1.40206590e-01],\n",
              "        [3.74249741e-02],\n",
              "        [9.99768913e-01],\n",
              "        [7.04463348e-02],\n",
              "        [3.51453054e-05],\n",
              "        [1.16045529e-04],\n",
              "        [4.04040694e-01],\n",
              "        [9.99976754e-01],\n",
              "        [4.06269137e-05],\n",
              "        [4.94592637e-01],\n",
              "        [9.99933422e-01],\n",
              "        [4.51209926e-05],\n",
              "        [9.99936044e-01],\n",
              "        [3.19813407e-04],\n",
              "        [2.73997756e-03],\n",
              "        [8.46684197e-05],\n",
              "        [9.99472499e-01],\n",
              "        [9.91293609e-01],\n",
              "        [4.09009750e-04],\n",
              "        [1.03279155e-04],\n",
              "        [9.84976053e-01],\n",
              "        [9.99852836e-01],\n",
              "        [6.64425373e-01],\n",
              "        [1.64656274e-04],\n",
              "        [5.31646982e-03],\n",
              "        [3.06449860e-01],\n",
              "        [1.82431642e-04],\n",
              "        [9.99922454e-01],\n",
              "        [3.00718814e-01],\n",
              "        [9.99925852e-01],\n",
              "        [9.99621034e-01],\n",
              "        [2.63586128e-03],\n",
              "        [7.13037848e-01],\n",
              "        [3.59573110e-04],\n",
              "        [9.99602377e-01],\n",
              "        [8.62680256e-01],\n",
              "        [7.43235707e-01],\n",
              "        [5.70345845e-04],\n",
              "        [7.74915842e-03],\n",
              "        [3.62356659e-04],\n",
              "        [6.83156250e-05],\n",
              "        [1.89319290e-02],\n",
              "        [2.78014876e-03],\n",
              "        [9.94661093e-01],\n",
              "        [2.11836467e-03],\n",
              "        [9.99937057e-01],\n",
              "        [9.99908328e-01],\n",
              "        [2.70273449e-04],\n",
              "        [7.86224008e-01],\n",
              "        [2.09940923e-03],\n",
              "        [2.75359955e-04],\n",
              "        [4.07459021e-01],\n",
              "        [9.94907916e-01],\n",
              "        [1.10842870e-03],\n",
              "        [2.82713715e-02],\n",
              "        [6.76246782e-05],\n",
              "        [7.07883434e-03],\n",
              "        [2.61827990e-05],\n",
              "        [9.99800324e-01],\n",
              "        [9.97759283e-01],\n",
              "        [9.99849141e-01],\n",
              "        [9.57295835e-01],\n",
              "        [8.66343737e-01],\n",
              "        [6.82219979e-04],\n",
              "        [6.68086504e-05],\n",
              "        [4.06514019e-01],\n",
              "        [9.99240279e-01],\n",
              "        [9.99871552e-01],\n",
              "        [1.17481708e-04],\n",
              "        [3.47646116e-03],\n",
              "        [2.65220209e-04],\n",
              "        [9.99884784e-01],\n",
              "        [9.99869287e-01],\n",
              "        [1.23487567e-04],\n",
              "        [2.84356009e-02],\n",
              "        [9.99947488e-01],\n",
              "        [3.87363345e-03],\n",
              "        [4.09681275e-02],\n",
              "        [9.97807741e-01],\n",
              "        [4.50461404e-04],\n",
              "        [2.38002380e-04],\n",
              "        [9.97243941e-01],\n",
              "        [4.21847284e-01],\n",
              "        [1.19656481e-01],\n",
              "        [9.99943733e-01],\n",
              "        [1.31644585e-04],\n",
              "        [3.95279494e-04],\n",
              "        [3.52091483e-05],\n",
              "        [1.12782436e-04],\n",
              "        [1.13342838e-04],\n",
              "        [9.99785006e-01],\n",
              "        [1.72536165e-04],\n",
              "        [7.16272056e-01],\n",
              "        [9.59441185e-01],\n",
              "        [1.05700977e-01],\n",
              "        [7.48851942e-03],\n",
              "        [4.20569595e-05],\n",
              "        [3.60972685e-04],\n",
              "        [9.99933064e-01],\n",
              "        [9.99806046e-01],\n",
              "        [6.01948355e-04],\n",
              "        [2.03560092e-04],\n",
              "        [1.51410961e-04],\n",
              "        [1.87782382e-04],\n",
              "        [9.99355912e-01],\n",
              "        [9.67401502e-05],\n",
              "        [9.98500347e-01],\n",
              "        [9.80346084e-01],\n",
              "        [2.35221252e-01],\n",
              "        [9.06060755e-01],\n",
              "        [4.20622900e-03],\n",
              "        [1.22036999e-02],\n",
              "        [4.46459599e-04],\n",
              "        [2.29258575e-02],\n",
              "        [8.42894375e-01],\n",
              "        [4.94018584e-01],\n",
              "        [2.21809015e-01],\n",
              "        [1.39030904e-04],\n",
              "        [5.37356646e-05],\n",
              "        [2.74100603e-04],\n",
              "        [1.08456472e-03],\n",
              "        [2.28681490e-02],\n",
              "        [1.64475337e-01],\n",
              "        [9.99897957e-01],\n",
              "        [9.99629974e-01],\n",
              "        [8.13422084e-01],\n",
              "        [9.99912083e-01],\n",
              "        [2.13934220e-02],\n",
              "        [4.24618600e-04],\n",
              "        [9.99353170e-01],\n",
              "        [8.24947655e-03],\n",
              "        [7.13662419e-04],\n",
              "        [2.16748953e-01],\n",
              "        [9.60077584e-01],\n",
              "        [6.75937918e-05],\n",
              "        [6.95141554e-01],\n",
              "        [9.03428197e-01],\n",
              "        [9.99368250e-01],\n",
              "        [9.99707580e-01],\n",
              "        [3.48567875e-04],\n",
              "        [5.87110370e-02],\n",
              "        [9.96592522e-01],\n",
              "        [5.36466796e-05],\n",
              "        [4.17377390e-02],\n",
              "        [9.21663269e-02],\n",
              "        [9.97812748e-01],\n",
              "        [9.75084245e-01],\n",
              "        [5.71127573e-04],\n",
              "        [2.46355194e-04],\n",
              "        [9.66239989e-01],\n",
              "        [5.18992369e-04],\n",
              "        [1.00371381e-03],\n",
              "        [8.95627745e-05],\n",
              "        [5.20649195e-01],\n",
              "        [9.99906301e-01],\n",
              "        [9.97780383e-01],\n",
              "        [5.87042829e-04],\n",
              "        [9.99879003e-01],\n",
              "        [9.99877512e-01],\n",
              "        [7.09917731e-05],\n",
              "        [9.99796271e-01],\n",
              "        [2.74674855e-02],\n",
              "        [9.50519204e-01],\n",
              "        [1.96642324e-01],\n",
              "        [7.31637236e-04],\n",
              "        [2.15219086e-04],\n",
              "        [1.59182295e-04],\n",
              "        [3.76596639e-04],\n",
              "        [9.37335717e-05],\n",
              "        [1.84604436e-01],\n",
              "        [1.81305560e-03],\n",
              "        [9.99836564e-01],\n",
              "        [2.81991059e-04],\n",
              "        [9.86225128e-01],\n",
              "        [1.61527634e-01],\n",
              "        [1.58351642e-04],\n",
              "        [1.06961081e-04],\n",
              "        [9.99924958e-01],\n",
              "        [8.48634518e-04],\n",
              "        [9.99791741e-01],\n",
              "        [3.51308584e-01],\n",
              "        [3.72896611e-04],\n",
              "        [1.12701677e-01],\n",
              "        [1.01405103e-03],\n",
              "        [1.31597921e-01],\n",
              "        [9.99877512e-01],\n",
              "        [9.47235749e-05],\n",
              "        [1.61892604e-04],\n",
              "        [1.61866676e-02],\n",
              "        [9.99883354e-01],\n",
              "        [4.35464131e-03],\n",
              "        [2.15608728e-04],\n",
              "        [9.93943572e-01],\n",
              "        [8.58898420e-05],\n",
              "        [1.73495166e-04],\n",
              "        [2.65915209e-04],\n",
              "        [2.96123683e-01],\n",
              "        [6.90880115e-04],\n",
              "        [3.38614672e-01],\n",
              "        [2.22719043e-01],\n",
              "        [5.98422659e-04],\n",
              "        [1.00131969e-04],\n",
              "        [1.17712930e-01],\n",
              "        [3.74330994e-05],\n",
              "        [9.99298930e-01],\n",
              "        [9.74066138e-01],\n",
              "        [6.44747615e-02],\n",
              "        [1.11618494e-04],\n",
              "        [5.02184441e-04],\n",
              "        [9.99851227e-01],\n",
              "        [9.77240622e-01],\n",
              "        [9.99960542e-01],\n",
              "        [4.14261594e-04],\n",
              "        [9.93977368e-01],\n",
              "        [2.85627932e-04],\n",
              "        [9.81343985e-01],\n",
              "        [9.10659552e-01],\n",
              "        [1.29120584e-04],\n",
              "        [9.99744713e-01],\n",
              "        [2.92322738e-03],\n",
              "        [9.88579810e-01],\n",
              "        [9.99940157e-01],\n",
              "        [2.31585442e-03],\n",
              "        [9.52344781e-05],\n",
              "        [4.80596751e-01],\n",
              "        [1.29612556e-04],\n",
              "        [5.91603294e-03],\n",
              "        [9.99820650e-01],\n",
              "        [3.93332690e-01],\n",
              "        [9.99432325e-01],\n",
              "        [1.05411880e-01],\n",
              "        [9.99768853e-01],\n",
              "        [9.84285414e-01],\n",
              "        [4.09061275e-02],\n",
              "        [1.03394435e-04],\n",
              "        [9.94292796e-01],\n",
              "        [9.15267228e-05],\n",
              "        [2.56448686e-01],\n",
              "        [9.99876022e-01],\n",
              "        [9.96336818e-01],\n",
              "        [9.99912798e-01],\n",
              "        [9.99711931e-01],\n",
              "        [9.46919695e-02],\n",
              "        [9.74896491e-01],\n",
              "        [1.03352446e-04],\n",
              "        [4.67397362e-01],\n",
              "        [9.96808290e-01],\n",
              "        [9.99707699e-01],\n",
              "        [1.40569900e-04],\n",
              "        [9.96586144e-01],\n",
              "        [9.99814749e-01],\n",
              "        [3.64478840e-03],\n",
              "        [1.63180055e-03],\n",
              "        [2.21809015e-01],\n",
              "        [3.00928950e-04],\n",
              "        [9.45560157e-01],\n",
              "        [9.97812510e-01],\n",
              "        [9.99845207e-01],\n",
              "        [2.84872163e-04],\n",
              "        [1.18515876e-04],\n",
              "        [1.29047839e-04],\n",
              "        [2.38869384e-01],\n",
              "        [1.29005099e-02],\n",
              "        [6.53026300e-03],\n",
              "        [9.84041154e-01],\n",
              "        [8.20777423e-05],\n",
              "        [1.75137848e-01],\n",
              "        [1.47756306e-03],\n",
              "        [2.91830744e-03],\n",
              "        [9.99643624e-01],\n",
              "        [8.24229210e-04],\n",
              "        [9.53331470e-01],\n",
              "        [7.33882945e-04],\n",
              "        [4.12316222e-05],\n",
              "        [1.62578828e-04],\n",
              "        [9.99919534e-01],\n",
              "        [4.65063930e-01],\n",
              "        [1.19679011e-04],\n",
              "        [1.71772018e-01],\n",
              "        [5.48480339e-02],\n",
              "        [8.23884329e-05],\n",
              "        [9.99709427e-01],\n",
              "        [3.30062700e-04],\n",
              "        [5.82849503e-01],\n",
              "        [1.24989793e-01],\n",
              "        [2.59678869e-04],\n",
              "        [5.32105744e-01],\n",
              "        [2.93036371e-01],\n",
              "        [6.11911935e-04],\n",
              "        [9.96547282e-01],\n",
              "        [7.50096366e-02],\n",
              "        [6.67517722e-01],\n",
              "        [9.99885142e-01],\n",
              "        [4.62630361e-01],\n",
              "        [2.59274006e-01],\n",
              "        [6.75937918e-05],\n",
              "        [3.35555166e-01],\n",
              "        [8.05776042e-04],\n",
              "        [9.99936044e-01],\n",
              "        [3.19296479e-01],\n",
              "        [7.60380412e-04],\n",
              "        [9.99903858e-01],\n",
              "        [3.20940286e-01],\n",
              "        [9.99680400e-01],\n",
              "        [3.20940286e-01],\n",
              "        [9.99898851e-01],\n",
              "        [5.97011276e-05],\n",
              "        [5.25870454e-03],\n",
              "        [9.55965224e-05],\n",
              "        [9.99914050e-01],\n",
              "        [4.16978583e-04],\n",
              "        [3.15669167e-04],\n",
              "        [1.34721573e-04],\n",
              "        [2.28806224e-04],\n",
              "        [1.33466849e-03],\n",
              "        [2.88115698e-04],\n",
              "        [3.70116904e-02],\n",
              "        [1.61310760e-04],\n",
              "        [4.94720181e-04],\n",
              "        [9.97226000e-01],\n",
              "        [1.20910874e-03],\n",
              "        [7.20942672e-03],\n",
              "        [2.10121769e-04],\n",
              "        [7.77023524e-05],\n",
              "        [4.23525982e-02],\n",
              "        [9.83451664e-01],\n",
              "        [1.40025292e-03],\n",
              "        [6.32169610e-03],\n",
              "        [5.34137886e-04],\n",
              "        [9.96673167e-01],\n",
              "        [9.99786377e-01],\n",
              "        [8.33530867e-05],\n",
              "        [1.16520336e-04],\n",
              "        [1.16144074e-04],\n",
              "        [3.05310714e-05],\n",
              "        [9.99876320e-01],\n",
              "        [7.77023524e-05],\n",
              "        [1.27985771e-03],\n",
              "        [9.99428153e-01],\n",
              "        [9.99872446e-01],\n",
              "        [9.99865234e-01],\n",
              "        [9.99963343e-01],\n",
              "        [9.99985576e-01],\n",
              "        [4.56648617e-04],\n",
              "        [3.28784809e-04],\n",
              "        [5.23205437e-02],\n",
              "        [8.82039428e-01],\n",
              "        [9.99894798e-01],\n",
              "        [9.61925864e-01],\n",
              "        [2.86625815e-04],\n",
              "        [9.86509323e-01],\n",
              "        [5.61972558e-01],\n",
              "        [6.48672067e-05],\n",
              "        [1.13353221e-04],\n",
              "        [9.33405757e-03],\n",
              "        [1.61127921e-03],\n",
              "        [7.55226793e-05],\n",
              "        [1.11949234e-03],\n",
              "        [9.59583461e-01],\n",
              "        [9.99944329e-01],\n",
              "        [2.27189114e-04],\n",
              "        [9.99844670e-01],\n",
              "        [2.87139803e-01],\n",
              "        [2.61659943e-03],\n",
              "        [2.25466141e-03],\n",
              "        [3.15784290e-02],\n",
              "        [7.95632958e-01],\n",
              "        [1.43491232e-03],\n",
              "        [9.00286686e-05]], dtype=float32),\n",
              " (762, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_pred_probs = tf.squeeze(tf.round(model_3_preds_probs))\n",
        "model_3_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PncbU2fbEqqj",
        "outputId": "a73eb624-ccde-4b21-ec65-8db8ffdcd6c0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results = calculate_results(y_true = val_labels ,\n",
        "                                    y_pred = model_3_pred_probs\n",
        "                                    )\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdP0wj0mFCZT",
        "outputId": "15354db1-eaec-4f3d-a5c0-d4866b49f4db"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7677165354330708,\n",
              " 'precision': 0.7712255031085189,\n",
              " 'recall': 0.7677165354330708,\n",
              " 'f1-score': 0.7646846187166754}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4 : Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (just like you would read an English sencente) however , a bidirectional RNN goes from right to left as well as left to right."
      ],
      "metadata": {
        "id": "zcVfMAayKopv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model\n",
        "inputs = layers.Input( shape = (1 ,) , dtype = tf.string)\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional( layer = layers.LSTM(64 , return_sequences = True))(x)\n",
        "x = layers.Bidirectional( layer = layers.GRU(64))(x)\n",
        "outputs = layers.Dense( 1 , activation = \"sigmoid\" )(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs , outputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "_sxqrsvSFMwg"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()  # hem left hem righttan baslayıp okudugumuz icin 64 iki katına cıkıyor. Cift taraflı process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7jiYgKAQZFM",
        "outputId": "e36666d9-7faa-4d78-938e-f0946e37deb5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, 15, 128)          98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirecti  (None, 128)              74496     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile a model\n",
        "model_4.compile(loss = [\"binary_crossentropy\"] ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n"
      ],
      "metadata": {
        "id": "ESiw_oCpJnSQ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "hist_4 = model_4.fit(x = train_sentences ,\n",
        "                     y = train_labels ,\n",
        "                     epochs = 5 ,\n",
        "                     validation_data = (val_sentences , val_labels)  ,\n",
        "                     callbacks = [create_tensorboard_callback(dir_name = save_dir , experiment_name = \"model_4_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz80aQULPZGK",
        "outputId": "389784a3-2efd-48b1-c5fc-25b1f24f3be4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_dense/20230818-153804\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 47ms/step - loss: 0.0441 - accuracy: 0.9780 - val_loss: 1.3637 - val_accuracy: 0.7664\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.0367 - accuracy: 0.9816 - val_loss: 1.5140 - val_accuracy: 0.7625\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0314 - accuracy: 0.9837 - val_loss: 1.6644 - val_accuracy: 0.7651\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 9s 41ms/step - loss: 0.0305 - accuracy: 0.9834 - val_loss: 1.5602 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.0314 - accuracy: 0.9841 - val_loss: 1.5137 - val_accuracy: 0.7638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(val_sentences , val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aa3rSdmQ7UL",
        "outputId": "43eb9f15-e7fc-496e-abc7-a4197a156455"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step - loss: 1.4362 - accuracy: 0.7612\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4361608028411865, 0.76115483045578]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_pred = model_4.predict(val_sentences)\n",
        "model_4_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3oMG_IERHBM",
        "outputId": "85dfb5b7-1e2c-45d0-c034-ce8d0d2366bb"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.23207884e-04],\n",
              "       [6.66913211e-01],\n",
              "       [9.99972939e-01],\n",
              "       [2.18059972e-01],\n",
              "       [3.93260452e-05],\n",
              "       [9.99886870e-01],\n",
              "       [4.62646335e-01],\n",
              "       [9.99984443e-01],\n",
              "       [9.99967933e-01],\n",
              "       [9.56643939e-01],\n",
              "       [5.86530914e-05],\n",
              "       [9.06733274e-01],\n",
              "       [6.06115718e-05],\n",
              "       [3.43738496e-01],\n",
              "       [5.27202064e-05],\n",
              "       [4.50437976e-04],\n",
              "       [7.10137829e-05],\n",
              "       [5.94688427e-05],\n",
              "       [3.72070819e-03],\n",
              "       [9.99830544e-01],\n",
              "       [9.98442471e-01],\n",
              "       [4.33132191e-05],\n",
              "       [9.99904156e-01],\n",
              "       [1.72385568e-04],\n",
              "       [9.99909341e-01],\n",
              "       [9.99983668e-01],\n",
              "       [1.55302798e-04],\n",
              "       [4.81643772e-04],\n",
              "       [7.30544853e-05],\n",
              "       [6.89695358e-01],\n",
              "       [9.99340534e-01],\n",
              "       [3.46912304e-04],\n",
              "       [2.05323263e-03],\n",
              "       [3.98569711e-04],\n",
              "       [5.00808582e-02],\n",
              "       [3.65964979e-01],\n",
              "       [9.99947011e-01],\n",
              "       [8.83281156e-02],\n",
              "       [4.25113831e-03],\n",
              "       [9.99971926e-01],\n",
              "       [4.16534960e-01],\n",
              "       [3.82056023e-05],\n",
              "       [2.88166136e-01],\n",
              "       [4.08134692e-05],\n",
              "       [9.98015106e-01],\n",
              "       [9.99957025e-01],\n",
              "       [9.92531002e-01],\n",
              "       [9.14317846e-01],\n",
              "       [5.14051295e-04],\n",
              "       [3.04975063e-01],\n",
              "       [1.34306625e-04],\n",
              "       [4.44286078e-01],\n",
              "       [9.70240799e-04],\n",
              "       [8.35971117e-01],\n",
              "       [8.24056208e-01],\n",
              "       [2.42917426e-03],\n",
              "       [1.15746487e-04],\n",
              "       [9.99956369e-01],\n",
              "       [7.09895394e-05],\n",
              "       [4.65196754e-05],\n",
              "       [4.29228228e-03],\n",
              "       [9.99976754e-01],\n",
              "       [9.95083749e-01],\n",
              "       [1.96044636e-03],\n",
              "       [9.99975979e-01],\n",
              "       [9.99979675e-01],\n",
              "       [9.94954109e-01],\n",
              "       [6.91530406e-02],\n",
              "       [9.97220755e-01],\n",
              "       [1.98851511e-01],\n",
              "       [4.70190455e-04],\n",
              "       [2.93199509e-01],\n",
              "       [9.99969840e-01],\n",
              "       [8.79032305e-04],\n",
              "       [9.98922050e-01],\n",
              "       [9.96564627e-01],\n",
              "       [2.36513373e-03],\n",
              "       [9.99971032e-01],\n",
              "       [1.17103405e-01],\n",
              "       [4.25222376e-03],\n",
              "       [4.24715341e-04],\n",
              "       [7.26890117e-02],\n",
              "       [9.99980152e-01],\n",
              "       [9.58247838e-05],\n",
              "       [8.71217562e-05],\n",
              "       [1.96470399e-04],\n",
              "       [6.07937982e-05],\n",
              "       [7.74885848e-05],\n",
              "       [5.32117730e-04],\n",
              "       [9.99942064e-01],\n",
              "       [9.99972284e-01],\n",
              "       [4.77256399e-05],\n",
              "       [9.99275208e-01],\n",
              "       [5.80909982e-05],\n",
              "       [9.99984443e-01],\n",
              "       [5.54253578e-01],\n",
              "       [9.90077853e-01],\n",
              "       [9.99920547e-01],\n",
              "       [9.99792576e-01],\n",
              "       [9.99516189e-01],\n",
              "       [9.99984086e-01],\n",
              "       [1.39224948e-03],\n",
              "       [2.81490957e-05],\n",
              "       [9.81487393e-01],\n",
              "       [9.99771297e-01],\n",
              "       [7.82432733e-04],\n",
              "       [9.99932289e-01],\n",
              "       [9.99924541e-01],\n",
              "       [5.05546304e-05],\n",
              "       [9.98878658e-01],\n",
              "       [9.93624270e-01],\n",
              "       [1.19643752e-04],\n",
              "       [9.97716606e-01],\n",
              "       [5.60010900e-04],\n",
              "       [1.96367735e-04],\n",
              "       [9.82058584e-04],\n",
              "       [3.59365910e-01],\n",
              "       [9.99374807e-01],\n",
              "       [7.51370797e-04],\n",
              "       [7.57656235e-05],\n",
              "       [9.99982834e-01],\n",
              "       [4.12002919e-05],\n",
              "       [3.92545553e-05],\n",
              "       [5.14992595e-01],\n",
              "       [1.97907723e-03],\n",
              "       [6.81604899e-04],\n",
              "       [9.99929011e-01],\n",
              "       [3.30300754e-05],\n",
              "       [3.84072919e-04],\n",
              "       [9.99467850e-01],\n",
              "       [5.93960052e-04],\n",
              "       [9.99982834e-01],\n",
              "       [9.99981880e-01],\n",
              "       [9.99983668e-01],\n",
              "       [9.99946952e-01],\n",
              "       [7.61274423e-05],\n",
              "       [9.99978542e-01],\n",
              "       [6.93364739e-02],\n",
              "       [6.71951449e-04],\n",
              "       [4.54526424e-04],\n",
              "       [9.99985218e-01],\n",
              "       [8.52317154e-01],\n",
              "       [3.43738496e-01],\n",
              "       [9.99865592e-01],\n",
              "       [2.78650504e-02],\n",
              "       [5.91270858e-04],\n",
              "       [4.17826377e-05],\n",
              "       [3.66589375e-05],\n",
              "       [2.69965432e-03],\n",
              "       [9.99952614e-01],\n",
              "       [4.63502511e-04],\n",
              "       [2.06812955e-02],\n",
              "       [2.51602847e-03],\n",
              "       [6.71948801e-05],\n",
              "       [1.99281349e-04],\n",
              "       [9.99888778e-01],\n",
              "       [9.99606311e-01],\n",
              "       [1.63744786e-03],\n",
              "       [9.99889433e-01],\n",
              "       [5.55375264e-05],\n",
              "       [9.99916434e-01],\n",
              "       [8.39301618e-04],\n",
              "       [3.41286836e-03],\n",
              "       [9.99936700e-01],\n",
              "       [3.00045521e-03],\n",
              "       [4.61201380e-05],\n",
              "       [9.99971271e-01],\n",
              "       [1.64537365e-03],\n",
              "       [9.99979258e-01],\n",
              "       [9.76761281e-01],\n",
              "       [9.99969363e-01],\n",
              "       [9.98221636e-01],\n",
              "       [9.99820292e-01],\n",
              "       [6.88591317e-05],\n",
              "       [9.99987125e-01],\n",
              "       [1.58900846e-04],\n",
              "       [1.08558137e-03],\n",
              "       [4.91931860e-04],\n",
              "       [5.77696525e-02],\n",
              "       [9.99929130e-01],\n",
              "       [7.65311270e-05],\n",
              "       [9.73688483e-01],\n",
              "       [9.99801040e-01],\n",
              "       [9.99971092e-01],\n",
              "       [9.99951184e-01],\n",
              "       [4.52364620e-05],\n",
              "       [2.15640583e-04],\n",
              "       [9.99986231e-01],\n",
              "       [4.21332334e-05],\n",
              "       [3.41066843e-05],\n",
              "       [2.25965586e-03],\n",
              "       [9.98085737e-01],\n",
              "       [8.38764608e-05],\n",
              "       [1.21601246e-04],\n",
              "       [5.40524161e-05],\n",
              "       [1.22038247e-04],\n",
              "       [7.03030528e-05],\n",
              "       [2.04167538e-03],\n",
              "       [9.99898493e-01],\n",
              "       [1.84764140e-04],\n",
              "       [2.05002148e-02],\n",
              "       [9.99968767e-01],\n",
              "       [9.99948025e-01],\n",
              "       [4.06389171e-03],\n",
              "       [1.06310094e-04],\n",
              "       [9.99985933e-01],\n",
              "       [9.99907553e-01],\n",
              "       [9.99931812e-01],\n",
              "       [9.85407829e-01],\n",
              "       [9.99914408e-01],\n",
              "       [8.01911950e-02],\n",
              "       [9.99978602e-01],\n",
              "       [5.56876657e-05],\n",
              "       [2.80565204e-04],\n",
              "       [3.67629873e-05],\n",
              "       [3.09206625e-05],\n",
              "       [9.99802828e-01],\n",
              "       [9.50941741e-01],\n",
              "       [9.99610543e-01],\n",
              "       [5.46720028e-01],\n",
              "       [3.80896777e-01],\n",
              "       [3.36023950e-04],\n",
              "       [8.82252003e-04],\n",
              "       [4.82131145e-04],\n",
              "       [9.99981344e-01],\n",
              "       [8.77158344e-02],\n",
              "       [4.98989422e-04],\n",
              "       [9.99987781e-01],\n",
              "       [9.99414086e-01],\n",
              "       [9.96754169e-01],\n",
              "       [5.20048598e-05],\n",
              "       [3.72356444e-04],\n",
              "       [9.99502838e-01],\n",
              "       [2.26366464e-02],\n",
              "       [2.87313133e-01],\n",
              "       [9.49727371e-04],\n",
              "       [3.18038166e-02],\n",
              "       [1.20433175e-03],\n",
              "       [5.70672972e-04],\n",
              "       [1.87090205e-04],\n",
              "       [9.99453366e-01],\n",
              "       [7.64293130e-04],\n",
              "       [9.99986351e-01],\n",
              "       [9.99915838e-01],\n",
              "       [1.35137409e-04],\n",
              "       [3.49437214e-05],\n",
              "       [9.99926329e-01],\n",
              "       [7.59576214e-05],\n",
              "       [5.16321743e-04],\n",
              "       [1.71318844e-01],\n",
              "       [7.01818208e-05],\n",
              "       [9.99555886e-01],\n",
              "       [3.01000237e-05],\n",
              "       [4.75572975e-04],\n",
              "       [9.99957144e-01],\n",
              "       [8.74678139e-03],\n",
              "       [9.99964774e-01],\n",
              "       [9.99984205e-01],\n",
              "       [3.99989747e-02],\n",
              "       [5.52367273e-05],\n",
              "       [1.30758461e-04],\n",
              "       [4.88992227e-05],\n",
              "       [2.85521455e-05],\n",
              "       [9.99958217e-01],\n",
              "       [9.99971151e-01],\n",
              "       [3.78755182e-02],\n",
              "       [9.99907017e-01],\n",
              "       [9.95420050e-05],\n",
              "       [1.54602213e-03],\n",
              "       [5.42112502e-05],\n",
              "       [2.20121001e-04],\n",
              "       [9.70057299e-05],\n",
              "       [9.99928296e-01],\n",
              "       [3.67438217e-04],\n",
              "       [2.94805541e-05],\n",
              "       [9.99965131e-01],\n",
              "       [9.32018156e-05],\n",
              "       [1.29615393e-04],\n",
              "       [9.99953926e-01],\n",
              "       [8.35604005e-05],\n",
              "       [1.15386874e-03],\n",
              "       [4.64340410e-05],\n",
              "       [9.99974012e-01],\n",
              "       [9.19931471e-01],\n",
              "       [4.66510415e-01],\n",
              "       [3.27603221e-01],\n",
              "       [9.99920607e-01],\n",
              "       [7.76179484e-04],\n",
              "       [9.99803185e-01],\n",
              "       [1.93822548e-01],\n",
              "       [9.98996556e-01],\n",
              "       [9.55350518e-01],\n",
              "       [9.95665491e-01],\n",
              "       [2.08649039e-03],\n",
              "       [3.19382583e-04],\n",
              "       [4.35651317e-02],\n",
              "       [1.44542730e-03],\n",
              "       [4.33452107e-04],\n",
              "       [2.21680224e-04],\n",
              "       [5.54183871e-03],\n",
              "       [3.23914828e-05],\n",
              "       [1.24694634e-04],\n",
              "       [3.19408812e-02],\n",
              "       [9.99975622e-01],\n",
              "       [2.76062085e-04],\n",
              "       [1.17170159e-02],\n",
              "       [6.91895187e-03],\n",
              "       [3.52572761e-02],\n",
              "       [9.65304265e-04],\n",
              "       [8.78741048e-05],\n",
              "       [4.76954774e-05],\n",
              "       [9.99855638e-01],\n",
              "       [1.68910641e-02],\n",
              "       [3.88394147e-01],\n",
              "       [9.99976575e-01],\n",
              "       [7.06897408e-05],\n",
              "       [7.92268634e-01],\n",
              "       [9.93882120e-03],\n",
              "       [1.21735584e-03],\n",
              "       [2.41921507e-02],\n",
              "       [6.12448130e-05],\n",
              "       [2.32933532e-03],\n",
              "       [9.99711215e-01],\n",
              "       [2.21048272e-03],\n",
              "       [9.99977887e-01],\n",
              "       [3.51926744e-01],\n",
              "       [4.93063199e-05],\n",
              "       [9.99980927e-01],\n",
              "       [7.50243053e-05],\n",
              "       [9.99973238e-01],\n",
              "       [1.68905579e-04],\n",
              "       [3.28549184e-04],\n",
              "       [9.99959886e-01],\n",
              "       [8.68463685e-05],\n",
              "       [9.08453585e-05],\n",
              "       [9.99807417e-01],\n",
              "       [3.92642542e-05],\n",
              "       [1.28287531e-04],\n",
              "       [8.35322678e-01],\n",
              "       [9.99754488e-01],\n",
              "       [8.54721729e-05],\n",
              "       [1.18142157e-03],\n",
              "       [9.99978542e-01],\n",
              "       [9.99946117e-01],\n",
              "       [9.99859452e-01],\n",
              "       [6.96203262e-02],\n",
              "       [9.98951435e-01],\n",
              "       [9.99652803e-01],\n",
              "       [7.91698229e-04],\n",
              "       [1.08815009e-04],\n",
              "       [1.87523663e-03],\n",
              "       [2.06546811e-03],\n",
              "       [5.11820945e-05],\n",
              "       [1.86682835e-01],\n",
              "       [5.96935339e-02],\n",
              "       [4.24497048e-05],\n",
              "       [9.99971211e-01],\n",
              "       [9.99983668e-01],\n",
              "       [9.99967515e-01],\n",
              "       [8.09906560e-05],\n",
              "       [3.27011645e-01],\n",
              "       [7.66422786e-03],\n",
              "       [8.22775532e-03],\n",
              "       [9.99104202e-01],\n",
              "       [3.61565679e-01],\n",
              "       [4.59989060e-05],\n",
              "       [2.84788781e-04],\n",
              "       [1.18028220e-04],\n",
              "       [9.99157727e-01],\n",
              "       [6.22593143e-05],\n",
              "       [3.52630013e-04],\n",
              "       [5.74332553e-05],\n",
              "       [1.50447013e-04],\n",
              "       [7.40921870e-02],\n",
              "       [9.93018389e-01],\n",
              "       [6.73337746e-03],\n",
              "       [8.15827152e-05],\n",
              "       [5.98778948e-03],\n",
              "       [5.77588471e-05],\n",
              "       [9.99974787e-01],\n",
              "       [9.99941885e-01],\n",
              "       [8.24048221e-01],\n",
              "       [9.61915851e-01],\n",
              "       [2.94765614e-05],\n",
              "       [9.56295133e-01],\n",
              "       [9.99986112e-01],\n",
              "       [9.80801046e-01],\n",
              "       [4.95046340e-02],\n",
              "       [9.98793602e-01],\n",
              "       [2.67745391e-03],\n",
              "       [9.99966025e-01],\n",
              "       [5.27794799e-03],\n",
              "       [1.99424292e-04],\n",
              "       [5.71703119e-03],\n",
              "       [1.01839623e-03],\n",
              "       [9.99963522e-01],\n",
              "       [4.92741307e-03],\n",
              "       [3.05182621e-05],\n",
              "       [6.00185085e-05],\n",
              "       [3.61565679e-01],\n",
              "       [9.99989212e-01],\n",
              "       [3.33198041e-05],\n",
              "       [4.67285886e-02],\n",
              "       [9.99963224e-01],\n",
              "       [4.40871190e-05],\n",
              "       [9.99982834e-01],\n",
              "       [1.30724919e-04],\n",
              "       [3.28943162e-04],\n",
              "       [8.11450300e-05],\n",
              "       [9.99679148e-01],\n",
              "       [9.99193788e-01],\n",
              "       [2.65278097e-04],\n",
              "       [5.75515696e-05],\n",
              "       [9.99790311e-01],\n",
              "       [9.99953628e-01],\n",
              "       [4.97173399e-01],\n",
              "       [1.29228982e-04],\n",
              "       [3.45998240e-04],\n",
              "       [5.51564097e-01],\n",
              "       [1.80051517e-04],\n",
              "       [9.99979854e-01],\n",
              "       [3.72880101e-02],\n",
              "       [9.99986470e-01],\n",
              "       [9.99924541e-01],\n",
              "       [1.63639814e-03],\n",
              "       [8.70071352e-01],\n",
              "       [8.89329895e-05],\n",
              "       [9.99948025e-01],\n",
              "       [9.91657495e-01],\n",
              "       [9.87597406e-01],\n",
              "       [5.63783629e-04],\n",
              "       [2.78638653e-03],\n",
              "       [2.40392925e-04],\n",
              "       [4.44333091e-05],\n",
              "       [1.68585242e-03],\n",
              "       [1.37590873e-03],\n",
              "       [9.77906227e-01],\n",
              "       [3.40836588e-04],\n",
              "       [9.99978781e-01],\n",
              "       [9.99976993e-01],\n",
              "       [4.21527046e-04],\n",
              "       [6.66913211e-01],\n",
              "       [4.75491775e-04],\n",
              "       [1.25042177e-04],\n",
              "       [2.30906352e-01],\n",
              "       [9.98112679e-01],\n",
              "       [1.93136733e-03],\n",
              "       [9.62528586e-03],\n",
              "       [2.80954009e-05],\n",
              "       [7.58869573e-04],\n",
              "       [3.22353153e-05],\n",
              "       [9.99931693e-01],\n",
              "       [9.99967575e-01],\n",
              "       [9.99982297e-01],\n",
              "       [9.51047957e-01],\n",
              "       [5.31282365e-01],\n",
              "       [1.45327032e-03],\n",
              "       [4.83600779e-05],\n",
              "       [9.99499738e-01],\n",
              "       [9.99816597e-01],\n",
              "       [9.99984860e-01],\n",
              "       [4.38249263e-05],\n",
              "       [1.13374013e-02],\n",
              "       [7.55276415e-05],\n",
              "       [9.99985099e-01],\n",
              "       [9.99971986e-01],\n",
              "       [5.39709763e-05],\n",
              "       [3.38634592e-03],\n",
              "       [9.99982953e-01],\n",
              "       [1.27635663e-03],\n",
              "       [2.71085720e-03],\n",
              "       [9.99972820e-01],\n",
              "       [1.83495475e-04],\n",
              "       [2.05275865e-04],\n",
              "       [9.98360217e-01],\n",
              "       [3.36246997e-01],\n",
              "       [7.34707490e-02],\n",
              "       [9.99979019e-01],\n",
              "       [8.05651434e-05],\n",
              "       [1.59579271e-04],\n",
              "       [3.04721380e-05],\n",
              "       [4.84243174e-05],\n",
              "       [6.71647722e-05],\n",
              "       [9.99959350e-01],\n",
              "       [7.01145327e-05],\n",
              "       [9.16476130e-01],\n",
              "       [9.92600977e-01],\n",
              "       [3.40706389e-03],\n",
              "       [2.18194164e-02],\n",
              "       [3.11386866e-05],\n",
              "       [2.23018593e-04],\n",
              "       [9.99982476e-01],\n",
              "       [9.99980271e-01],\n",
              "       [3.94942937e-04],\n",
              "       [8.90037481e-05],\n",
              "       [7.15487404e-05],\n",
              "       [2.56894942e-04],\n",
              "       [9.99923587e-01],\n",
              "       [6.87477223e-05],\n",
              "       [9.99802351e-01],\n",
              "       [9.92315888e-01],\n",
              "       [9.93095875e-01],\n",
              "       [9.93416011e-01],\n",
              "       [3.51344198e-02],\n",
              "       [8.59062653e-04],\n",
              "       [4.66458179e-04],\n",
              "       [1.52308762e-01],\n",
              "       [5.21775603e-01],\n",
              "       [9.87587571e-02],\n",
              "       [1.12717748e-02],\n",
              "       [1.47149185e-04],\n",
              "       [3.11664953e-05],\n",
              "       [3.31778981e-04],\n",
              "       [3.21659888e-03],\n",
              "       [9.92525101e-01],\n",
              "       [2.28633702e-01],\n",
              "       [9.99965847e-01],\n",
              "       [9.99898791e-01],\n",
              "       [5.54253638e-01],\n",
              "       [9.99735594e-01],\n",
              "       [1.70126813e-03],\n",
              "       [2.29986661e-04],\n",
              "       [9.99753177e-01],\n",
              "       [2.48892000e-04],\n",
              "       [2.65564799e-04],\n",
              "       [2.86104172e-01],\n",
              "       [9.98114705e-01],\n",
              "       [2.92988789e-05],\n",
              "       [9.27595794e-01],\n",
              "       [8.13214004e-01],\n",
              "       [9.99900103e-01],\n",
              "       [9.99913931e-01],\n",
              "       [3.93231865e-03],\n",
              "       [2.79135955e-03],\n",
              "       [9.68411684e-01],\n",
              "       [6.56907723e-05],\n",
              "       [6.99309912e-03],\n",
              "       [9.21193838e-01],\n",
              "       [9.94644761e-01],\n",
              "       [9.80286896e-01],\n",
              "       [1.16757787e-04],\n",
              "       [1.96898705e-04],\n",
              "       [9.93262112e-01],\n",
              "       [2.83580943e-04],\n",
              "       [2.94906204e-04],\n",
              "       [7.84159784e-05],\n",
              "       [3.67124915e-01],\n",
              "       [9.99982059e-01],\n",
              "       [9.98890817e-01],\n",
              "       [1.76825677e-03],\n",
              "       [9.99970138e-01],\n",
              "       [9.99975622e-01],\n",
              "       [4.89854719e-05],\n",
              "       [9.99975860e-01],\n",
              "       [2.31760205e-03],\n",
              "       [9.98803735e-01],\n",
              "       [1.31041044e-02],\n",
              "       [8.01551505e-04],\n",
              "       [2.89224292e-04],\n",
              "       [8.58885323e-05],\n",
              "       [1.67048915e-04],\n",
              "       [6.32709416e-05],\n",
              "       [9.84159946e-01],\n",
              "       [9.87604653e-05],\n",
              "       [9.99981642e-01],\n",
              "       [6.65250118e-04],\n",
              "       [9.99744594e-01],\n",
              "       [9.44764495e-01],\n",
              "       [1.90243707e-03],\n",
              "       [6.85574123e-05],\n",
              "       [9.99978244e-01],\n",
              "       [1.30370885e-04],\n",
              "       [9.99965012e-01],\n",
              "       [3.06267798e-01],\n",
              "       [4.22954006e-04],\n",
              "       [8.42922274e-03],\n",
              "       [7.03454425e-04],\n",
              "       [4.30967566e-03],\n",
              "       [9.99975622e-01],\n",
              "       [3.22176129e-05],\n",
              "       [5.93193145e-05],\n",
              "       [2.91302847e-03],\n",
              "       [9.99984741e-01],\n",
              "       [1.67613872e-03],\n",
              "       [7.10335589e-05],\n",
              "       [9.99835372e-01],\n",
              "       [5.55382139e-05],\n",
              "       [9.55809301e-05],\n",
              "       [4.37107927e-04],\n",
              "       [2.06517279e-02],\n",
              "       [3.23688524e-04],\n",
              "       [4.01319951e-01],\n",
              "       [6.57716319e-02],\n",
              "       [2.98124971e-03],\n",
              "       [5.91656499e-05],\n",
              "       [4.26399186e-02],\n",
              "       [3.98764205e-05],\n",
              "       [9.99901056e-01],\n",
              "       [9.99765277e-01],\n",
              "       [1.03340605e-02],\n",
              "       [4.12092522e-05],\n",
              "       [7.83885014e-04],\n",
              "       [9.99970913e-01],\n",
              "       [9.65549290e-01],\n",
              "       [9.99948323e-01],\n",
              "       [3.46287125e-04],\n",
              "       [9.98194873e-01],\n",
              "       [4.25571692e-04],\n",
              "       [9.97578621e-01],\n",
              "       [9.78639066e-01],\n",
              "       [4.02895530e-05],\n",
              "       [9.99963224e-01],\n",
              "       [8.81004496e-04],\n",
              "       [9.99642432e-01],\n",
              "       [9.99977469e-01],\n",
              "       [7.96165667e-04],\n",
              "       [7.35036738e-05],\n",
              "       [9.87662673e-01],\n",
              "       [5.01968352e-05],\n",
              "       [7.75605500e-01],\n",
              "       [9.99985933e-01],\n",
              "       [3.58902842e-01],\n",
              "       [9.95905697e-01],\n",
              "       [5.23351990e-02],\n",
              "       [9.99966085e-01],\n",
              "       [9.96889114e-01],\n",
              "       [1.94403506e-03],\n",
              "       [5.17661720e-05],\n",
              "       [9.86273885e-01],\n",
              "       [5.71010060e-05],\n",
              "       [2.95515001e-01],\n",
              "       [9.99964118e-01],\n",
              "       [9.99694049e-01],\n",
              "       [9.99980628e-01],\n",
              "       [9.99854326e-01],\n",
              "       [6.86109364e-01],\n",
              "       [9.97062206e-01],\n",
              "       [6.17997066e-05],\n",
              "       [9.44185197e-01],\n",
              "       [9.88685250e-01],\n",
              "       [9.99896824e-01],\n",
              "       [9.98795440e-05],\n",
              "       [9.98634577e-01],\n",
              "       [9.99935806e-01],\n",
              "       [8.71982146e-03],\n",
              "       [3.76139488e-03],\n",
              "       [1.12717748e-02],\n",
              "       [4.36630857e-04],\n",
              "       [9.49692309e-01],\n",
              "       [9.99392807e-01],\n",
              "       [9.99986827e-01],\n",
              "       [5.88323572e-04],\n",
              "       [4.31554690e-05],\n",
              "       [4.65732010e-05],\n",
              "       [1.84190348e-01],\n",
              "       [7.79193128e-04],\n",
              "       [2.26920974e-02],\n",
              "       [9.97740448e-01],\n",
              "       [4.58720024e-05],\n",
              "       [3.50931853e-01],\n",
              "       [3.37141246e-04],\n",
              "       [1.10554148e-03],\n",
              "       [9.99880433e-01],\n",
              "       [2.30314516e-04],\n",
              "       [9.91436183e-01],\n",
              "       [1.47782615e-03],\n",
              "       [2.49376062e-05],\n",
              "       [1.36501141e-04],\n",
              "       [9.99985397e-01],\n",
              "       [9.94336784e-01],\n",
              "       [4.34595131e-05],\n",
              "       [2.01014150e-02],\n",
              "       [1.79878920e-01],\n",
              "       [3.19979808e-05],\n",
              "       [9.99954939e-01],\n",
              "       [9.22485560e-05],\n",
              "       [9.81593609e-01],\n",
              "       [4.58705187e-01],\n",
              "       [6.39244754e-05],\n",
              "       [2.44304776e-01],\n",
              "       [9.93709117e-02],\n",
              "       [2.56563275e-04],\n",
              "       [9.99607801e-01],\n",
              "       [1.07134141e-01],\n",
              "       [9.97459054e-01],\n",
              "       [9.99967456e-01],\n",
              "       [4.27912652e-01],\n",
              "       [2.77848523e-02],\n",
              "       [2.92988789e-05],\n",
              "       [6.06219247e-02],\n",
              "       [1.31402235e-03],\n",
              "       [9.99982834e-01],\n",
              "       [2.39470042e-03],\n",
              "       [1.28255750e-03],\n",
              "       [9.99957502e-01],\n",
              "       [3.64141643e-01],\n",
              "       [9.99934912e-01],\n",
              "       [3.64141643e-01],\n",
              "       [9.99977767e-01],\n",
              "       [9.76126830e-05],\n",
              "       [5.02396317e-04],\n",
              "       [5.01194409e-05],\n",
              "       [9.99984026e-01],\n",
              "       [7.82884716e-04],\n",
              "       [3.35406570e-04],\n",
              "       [6.39395876e-05],\n",
              "       [1.46411461e-04],\n",
              "       [2.38840759e-04],\n",
              "       [9.89234322e-05],\n",
              "       [2.17353855e-03],\n",
              "       [1.56014634e-04],\n",
              "       [3.26420239e-04],\n",
              "       [9.99564290e-01],\n",
              "       [4.88639460e-04],\n",
              "       [5.26799122e-04],\n",
              "       [1.65417587e-04],\n",
              "       [3.24904831e-05],\n",
              "       [8.65660142e-03],\n",
              "       [9.99004066e-01],\n",
              "       [9.93273919e-04],\n",
              "       [2.77136220e-04],\n",
              "       [9.76333162e-04],\n",
              "       [9.97830212e-01],\n",
              "       [9.99963343e-01],\n",
              "       [3.55573720e-05],\n",
              "       [7.41839031e-05],\n",
              "       [7.94371517e-05],\n",
              "       [2.70628243e-05],\n",
              "       [9.99893785e-01],\n",
              "       [3.24904831e-05],\n",
              "       [1.97682157e-03],\n",
              "       [9.99849916e-01],\n",
              "       [9.99968767e-01],\n",
              "       [9.99972939e-01],\n",
              "       [9.99977171e-01],\n",
              "       [9.99976516e-01],\n",
              "       [7.72751882e-05],\n",
              "       [1.31071909e-04],\n",
              "       [5.34022570e-01],\n",
              "       [9.94721651e-01],\n",
              "       [9.99983847e-01],\n",
              "       [9.65938687e-01],\n",
              "       [2.10426108e-04],\n",
              "       [9.95145738e-01],\n",
              "       [4.33887571e-01],\n",
              "       [3.43347310e-05],\n",
              "       [3.68618457e-05],\n",
              "       [6.21876679e-03],\n",
              "       [3.59074539e-03],\n",
              "       [4.47767052e-05],\n",
              "       [1.18681521e-03],\n",
              "       [9.98326778e-01],\n",
              "       [9.99980032e-01],\n",
              "       [7.74562213e-05],\n",
              "       [9.99972999e-01],\n",
              "       [9.98241246e-01],\n",
              "       [5.32445451e-03],\n",
              "       [2.13312730e-03],\n",
              "       [8.47819328e-01],\n",
              "       [5.23235977e-01],\n",
              "       [2.54226699e-02],\n",
              "       [7.37866940e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_preds = tf.squeeze(tf.round(model_4_pred))\n",
        "model_4_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3HVnOnhSBv2",
        "outputId": "1262438e-83d8-40de-b7ea-e1620051aaf2"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results = calculate_results(y_true = val_labels ,\n",
        "                                    y_pred = model_4_preds\n",
        "                                    )\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdAGqWxeSJa3",
        "outputId": "41bf3ece-c080-4b1f-b363-e32d1d88507a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7611548556430446,\n",
              " 'precision': 0.7627664723727715,\n",
              " 'recall': 0.7611548556430446,\n",
              " 'f1-score': 0.7588524417705016}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 5 : 1D Convolutional Neural Network\n",
        "\n",
        "We have used CNN's for images but images are typically 2D (height x width) however , our text data is 1D.\n",
        "\n",
        "Previously we used Conv2D for our image data but we are going to use Conv1D for our text data.\n",
        "\n",
        "The typical structure of a Conv1D model for sequences (in our case , text):\n",
        "\n",
        "Inputs(Text) -> Tokenization -> Embedding -> Layers (Conv1D + pooling) -> Outputs (class probabilities)\n",
        ""
      ],
      "metadata": {
        "id": "_mP03EHlSXzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out our embedding layer , Conv1D layer and max pooling\n",
        "\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"]))\n",
        "conv_1d = layers.Conv1D( filters = 32 ,\n",
        "                        kernel_size = 5 ,  # It looks at 5 words at a time (also referred as ngram because aynı anda 5 kelimeye bakıyor.)\n",
        "                         activation =   \"relu\" ,\n",
        "                         padding = \"valid\"   # Bu bizim conv_1d_output umuzun shapeinin 11 çıkmasına sebep oluyor. padding = same deseydik yine 15 olacaktı token outputumuz. valid atadıgımızda the output is smaller than the input shape.\n",
        "                         )  # padding valid atamazsak some of the tokens at the end of our sequences may get missed. Valid bunu engelliyor.\n",
        "\n",
        "conv_1d_output = conv_1d(embedding_test)  # Past test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)  # Equivalent to get the most important features or get the feature with highest value\n",
        "embedding_test.shape , conv_1d_output.shape , max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP2XOkvGcGCu",
        "outputId": "ca44597b-dd8a-4983-e31c-9d314d468695"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model\n",
        "\n",
        "inputs = layers.Input( shape = ( 1 ,) , dtype = tf.string)\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "\n",
        "x = embedding(x)\n",
        "\n",
        "x = layers.Conv1D( 64 , 5 , activation = \"relu\")(x)\n",
        "\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "\n",
        "outputs = layers.Dense( 1 , activation = \"sigmoid\")(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs , outputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "i8d9lmwIXYpr"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHyF3X4pZHZy",
        "outputId": "7e11df5f-f0ab-4300-b38c-638a7cd2f315"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile a model\n",
        "\n",
        "model_5.compile(loss = [\"binary_crossentropy\"] ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = [\"accuracy\"]\n",
        "                )"
      ],
      "metadata": {
        "id": "lpIlHoESY0yw"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_5 = model_5.fit( x = train_sentences ,\n",
        "                      y = train_labels ,\n",
        "                      epochs = 5 ,\n",
        "                      validation_data = (val_sentences , val_labels) ,\n",
        "                      callbacks = [create_tensorboard_callback(dir_name = save_dir , experiment_name = \"model_5_dense\")]\n",
        "                      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW3BP3OeZT36",
        "outputId": "717fda5f-53ff-43f8-b26c-618edfe4fcbc"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_dense/20230818-170416\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 26ms/step - loss: 0.0431 - accuracy: 0.9807 - val_loss: 1.3741 - val_accuracy: 0.7493\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0421 - accuracy: 0.9809 - val_loss: 1.3229 - val_accuracy: 0.7428\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0393 - accuracy: 0.9826 - val_loss: 1.3256 - val_accuracy: 0.7454\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0397 - accuracy: 0.9809 - val_loss: 1.3269 - val_accuracy: 0.7454\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0386 - accuracy: 0.9813 - val_loss: 1.3076 - val_accuracy: 0.7480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_preds = model_5.predict(val_sentences)\n",
        "model_5_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSuyl5OKZn0I",
        "outputId": "d9624f60-10e4-47f3-ae8e-0a5e57fb0075"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.32050598e-01],\n",
              "       [8.39550614e-01],\n",
              "       [9.99944866e-01],\n",
              "       [4.62954715e-02],\n",
              "       [6.16197440e-07],\n",
              "       [9.80061114e-01],\n",
              "       [9.85522389e-01],\n",
              "       [9.99966085e-01],\n",
              "       [9.99998331e-01],\n",
              "       [8.60878229e-01],\n",
              "       [3.16967544e-07],\n",
              "       [9.57833588e-01],\n",
              "       [6.28220550e-06],\n",
              "       [8.38966891e-02],\n",
              "       [3.82026919e-05],\n",
              "       [8.16079415e-03],\n",
              "       [3.29619972e-04],\n",
              "       [3.00956635e-05],\n",
              "       [2.38605756e-02],\n",
              "       [9.92576838e-01],\n",
              "       [5.30821145e-01],\n",
              "       [2.75959788e-08],\n",
              "       [9.99765635e-01],\n",
              "       [6.22869193e-05],\n",
              "       [9.99998629e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.36772333e-05],\n",
              "       [9.84845590e-03],\n",
              "       [1.03043008e-03],\n",
              "       [3.40016782e-01],\n",
              "       [9.54839349e-01],\n",
              "       [1.50516089e-05],\n",
              "       [4.63945508e-01],\n",
              "       [6.50518283e-04],\n",
              "       [3.50803398e-02],\n",
              "       [8.11906397e-01],\n",
              "       [9.99994636e-01],\n",
              "       [3.26676875e-01],\n",
              "       [3.84348212e-03],\n",
              "       [9.99958098e-01],\n",
              "       [2.45357707e-01],\n",
              "       [1.66736863e-04],\n",
              "       [2.08361726e-02],\n",
              "       [1.01403311e-04],\n",
              "       [9.93531883e-01],\n",
              "       [9.99991834e-01],\n",
              "       [9.99419570e-01],\n",
              "       [9.99007583e-01],\n",
              "       [8.39851424e-03],\n",
              "       [1.34725437e-01],\n",
              "       [1.09499808e-04],\n",
              "       [6.35618448e-01],\n",
              "       [5.67822077e-04],\n",
              "       [6.14797115e-01],\n",
              "       [9.92415845e-01],\n",
              "       [1.85374357e-02],\n",
              "       [1.10295219e-02],\n",
              "       [9.99996126e-01],\n",
              "       [8.53800339e-06],\n",
              "       [2.18412367e-07],\n",
              "       [3.72207910e-02],\n",
              "       [9.99999940e-01],\n",
              "       [9.76480186e-01],\n",
              "       [1.65641401e-03],\n",
              "       [9.94745970e-01],\n",
              "       [9.99995232e-01],\n",
              "       [9.91372943e-01],\n",
              "       [2.21553668e-02],\n",
              "       [9.90415275e-01],\n",
              "       [1.73999652e-01],\n",
              "       [1.34699992e-04],\n",
              "       [1.82307824e-01],\n",
              "       [9.99025702e-01],\n",
              "       [1.11663842e-03],\n",
              "       [9.99605238e-01],\n",
              "       [9.17924464e-01],\n",
              "       [4.04521776e-03],\n",
              "       [9.98863816e-01],\n",
              "       [1.72959715e-01],\n",
              "       [7.24219644e-05],\n",
              "       [8.64388198e-02],\n",
              "       [4.03878279e-02],\n",
              "       [1.00000000e+00],\n",
              "       [9.84619419e-06],\n",
              "       [4.73543449e-04],\n",
              "       [1.50816853e-03],\n",
              "       [2.84189045e-05],\n",
              "       [3.25980693e-01],\n",
              "       [1.11868575e-01],\n",
              "       [9.99999881e-01],\n",
              "       [9.99997258e-01],\n",
              "       [2.17869092e-05],\n",
              "       [9.65308666e-01],\n",
              "       [5.04233718e-01],\n",
              "       [9.99999940e-01],\n",
              "       [3.45616609e-01],\n",
              "       [9.82314646e-01],\n",
              "       [9.59922850e-01],\n",
              "       [9.98983026e-01],\n",
              "       [9.90957201e-01],\n",
              "       [9.99999642e-01],\n",
              "       [2.30008282e-05],\n",
              "       [1.10687461e-06],\n",
              "       [9.91761208e-01],\n",
              "       [9.93194401e-01],\n",
              "       [5.70547171e-02],\n",
              "       [9.93267179e-01],\n",
              "       [9.99983490e-01],\n",
              "       [8.92622722e-07],\n",
              "       [9.99724209e-01],\n",
              "       [7.13223279e-01],\n",
              "       [9.48851024e-08],\n",
              "       [4.05040056e-01],\n",
              "       [4.24136582e-04],\n",
              "       [2.09171281e-04],\n",
              "       [6.17082007e-02],\n",
              "       [6.55500054e-01],\n",
              "       [9.27961051e-01],\n",
              "       [2.22207338e-01],\n",
              "       [1.39988173e-04],\n",
              "       [1.00000000e+00],\n",
              "       [9.88128022e-07],\n",
              "       [3.56264110e-03],\n",
              "       [9.40860391e-01],\n",
              "       [1.84302196e-01],\n",
              "       [2.34844862e-03],\n",
              "       [9.84654725e-01],\n",
              "       [4.29510073e-05],\n",
              "       [8.31941701e-03],\n",
              "       [9.99582112e-01],\n",
              "       [7.84981239e-05],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [9.99948859e-01],\n",
              "       [2.36409623e-02],\n",
              "       [9.99898911e-01],\n",
              "       [9.41482127e-01],\n",
              "       [1.34570012e-03],\n",
              "       [9.19251994e-04],\n",
              "       [9.99999940e-01],\n",
              "       [8.28733981e-01],\n",
              "       [8.38966891e-02],\n",
              "       [9.95708466e-01],\n",
              "       [2.27243289e-01],\n",
              "       [4.47183894e-03],\n",
              "       [7.00122735e-04],\n",
              "       [5.31931210e-09],\n",
              "       [6.95126271e-03],\n",
              "       [1.38004422e-01],\n",
              "       [4.50406363e-03],\n",
              "       [7.24957958e-02],\n",
              "       [2.46888585e-02],\n",
              "       [2.26929053e-08],\n",
              "       [1.61094102e-03],\n",
              "       [9.99824107e-01],\n",
              "       [9.96550500e-01],\n",
              "       [8.29032809e-03],\n",
              "       [9.72741246e-01],\n",
              "       [5.98317627e-08],\n",
              "       [8.88621390e-01],\n",
              "       [6.24769405e-02],\n",
              "       [1.72073305e-01],\n",
              "       [9.99675870e-01],\n",
              "       [3.90698854e-03],\n",
              "       [1.05908490e-03],\n",
              "       [1.00000000e+00],\n",
              "       [1.30985543e-01],\n",
              "       [9.99999702e-01],\n",
              "       [7.15851545e-01],\n",
              "       [9.99995470e-01],\n",
              "       [9.99530971e-01],\n",
              "       [9.99990225e-01],\n",
              "       [2.05604752e-04],\n",
              "       [9.99973059e-01],\n",
              "       [8.87515023e-03],\n",
              "       [3.43353748e-01],\n",
              "       [1.49276659e-01],\n",
              "       [9.55035090e-02],\n",
              "       [9.99904454e-01],\n",
              "       [4.18650778e-03],\n",
              "       [8.36408496e-01],\n",
              "       [9.93782043e-01],\n",
              "       [9.99999762e-01],\n",
              "       [9.98588264e-01],\n",
              "       [1.26671954e-03],\n",
              "       [1.13505041e-06],\n",
              "       [1.00000000e+00],\n",
              "       [3.91975306e-07],\n",
              "       [7.76328619e-08],\n",
              "       [4.07643497e-01],\n",
              "       [4.63446230e-01],\n",
              "       [6.69891233e-05],\n",
              "       [8.94370442e-06],\n",
              "       [1.52347951e-07],\n",
              "       [1.78157086e-06],\n",
              "       [2.38763844e-03],\n",
              "       [3.09257247e-02],\n",
              "       [9.99715745e-01],\n",
              "       [2.44344148e-04],\n",
              "       [8.29574186e-04],\n",
              "       [9.99963641e-01],\n",
              "       [9.99857068e-01],\n",
              "       [1.77747607e-02],\n",
              "       [1.58642564e-04],\n",
              "       [1.00000000e+00],\n",
              "       [9.99982893e-01],\n",
              "       [9.99999166e-01],\n",
              "       [9.43435669e-01],\n",
              "       [9.97096896e-01],\n",
              "       [8.57172981e-02],\n",
              "       [9.99999881e-01],\n",
              "       [1.99475630e-06],\n",
              "       [3.51237657e-04],\n",
              "       [3.70671927e-07],\n",
              "       [6.47972609e-09],\n",
              "       [9.97768819e-01],\n",
              "       [9.78240788e-01],\n",
              "       [8.63442957e-01],\n",
              "       [9.99189079e-01],\n",
              "       [3.23291756e-02],\n",
              "       [4.27251856e-04],\n",
              "       [3.29849747e-04],\n",
              "       [4.42293276e-05],\n",
              "       [9.99985456e-01],\n",
              "       [1.67921707e-01],\n",
              "       [1.43442047e-03],\n",
              "       [1.00000000e+00],\n",
              "       [9.11987424e-01],\n",
              "       [9.78185475e-01],\n",
              "       [2.03228847e-04],\n",
              "       [5.23587514e-04],\n",
              "       [9.97957349e-01],\n",
              "       [9.82138664e-02],\n",
              "       [3.90527964e-01],\n",
              "       [8.44958762e-04],\n",
              "       [1.64665565e-01],\n",
              "       [2.29899790e-02],\n",
              "       [1.39511246e-02],\n",
              "       [1.65574776e-04],\n",
              "       [3.60639632e-01],\n",
              "       [5.86137455e-03],\n",
              "       [1.00000000e+00],\n",
              "       [9.99941766e-01],\n",
              "       [9.01351959e-05],\n",
              "       [1.12644358e-07],\n",
              "       [9.99943495e-01],\n",
              "       [1.74308498e-05],\n",
              "       [3.34744714e-03],\n",
              "       [1.69995964e-01],\n",
              "       [9.26066548e-07],\n",
              "       [9.98237431e-01],\n",
              "       [1.66763603e-09],\n",
              "       [1.84878104e-06],\n",
              "       [9.99992728e-01],\n",
              "       [2.21486703e-01],\n",
              "       [9.98737216e-01],\n",
              "       [9.99999881e-01],\n",
              "       [9.07344394e-04],\n",
              "       [1.06720871e-03],\n",
              "       [1.06755376e-01],\n",
              "       [7.95182306e-04],\n",
              "       [3.24181428e-07],\n",
              "       [9.99999464e-01],\n",
              "       [9.99969006e-01],\n",
              "       [6.03552938e-01],\n",
              "       [9.99986231e-01],\n",
              "       [6.07551367e-04],\n",
              "       [1.57934688e-02],\n",
              "       [3.49590600e-01],\n",
              "       [4.06187726e-03],\n",
              "       [2.25949567e-04],\n",
              "       [9.99993861e-01],\n",
              "       [2.17951904e-03],\n",
              "       [1.56521324e-07],\n",
              "       [9.99999762e-01],\n",
              "       [1.34602351e-05],\n",
              "       [4.50479565e-04],\n",
              "       [9.99960005e-01],\n",
              "       [7.60905823e-05],\n",
              "       [3.24508965e-01],\n",
              "       [5.47421572e-04],\n",
              "       [9.99999225e-01],\n",
              "       [9.98958468e-01],\n",
              "       [8.24180007e-01],\n",
              "       [3.91395032e-01],\n",
              "       [9.99990404e-01],\n",
              "       [1.24786638e-01],\n",
              "       [9.96004760e-01],\n",
              "       [5.28900744e-03],\n",
              "       [9.16876078e-01],\n",
              "       [9.99701381e-01],\n",
              "       [8.66809964e-01],\n",
              "       [9.09833834e-02],\n",
              "       [2.29254179e-03],\n",
              "       [9.29266334e-01],\n",
              "       [1.34423105e-02],\n",
              "       [1.74368881e-02],\n",
              "       [1.69167353e-04],\n",
              "       [8.71208906e-01],\n",
              "       [6.25101575e-06],\n",
              "       [1.28490536e-03],\n",
              "       [6.36580065e-02],\n",
              "       [9.99933779e-01],\n",
              "       [5.84087633e-02],\n",
              "       [2.06923112e-03],\n",
              "       [6.58839643e-01],\n",
              "       [4.34054881e-01],\n",
              "       [6.02289960e-02],\n",
              "       [1.39870426e-05],\n",
              "       [1.56935217e-04],\n",
              "       [9.99843419e-01],\n",
              "       [2.72987962e-01],\n",
              "       [1.72021493e-01],\n",
              "       [1.00000000e+00],\n",
              "       [2.88112933e-04],\n",
              "       [9.97987509e-01],\n",
              "       [4.97092605e-02],\n",
              "       [3.19694009e-05],\n",
              "       [2.23314628e-01],\n",
              "       [1.10404699e-05],\n",
              "       [1.47424182e-02],\n",
              "       [9.99959707e-01],\n",
              "       [3.10236998e-02],\n",
              "       [9.99996781e-01],\n",
              "       [3.79294425e-01],\n",
              "       [1.30720537e-05],\n",
              "       [9.99969602e-01],\n",
              "       [2.96216254e-04],\n",
              "       [9.99999464e-01],\n",
              "       [9.79489647e-04],\n",
              "       [1.50609858e-05],\n",
              "       [1.00000000e+00],\n",
              "       [5.57691310e-05],\n",
              "       [2.47574440e-06],\n",
              "       [9.99567747e-01],\n",
              "       [2.30594687e-05],\n",
              "       [2.33455580e-06],\n",
              "       [9.99796748e-01],\n",
              "       [9.99833763e-01],\n",
              "       [1.08840743e-06],\n",
              "       [6.26874669e-03],\n",
              "       [9.99970615e-01],\n",
              "       [9.36946869e-01],\n",
              "       [9.96874332e-01],\n",
              "       [3.98405083e-02],\n",
              "       [8.01676631e-01],\n",
              "       [9.99962509e-01],\n",
              "       [4.31914057e-04],\n",
              "       [3.81229875e-05],\n",
              "       [7.44075608e-03],\n",
              "       [6.19943254e-03],\n",
              "       [1.40506211e-06],\n",
              "       [2.30689555e-01],\n",
              "       [1.94552206e-02],\n",
              "       [1.14382294e-06],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [3.15897050e-04],\n",
              "       [2.42003277e-01],\n",
              "       [8.71715974e-03],\n",
              "       [2.17668489e-01],\n",
              "       [9.75008488e-01],\n",
              "       [3.89890045e-01],\n",
              "       [2.34243693e-04],\n",
              "       [7.08906100e-07],\n",
              "       [1.07423356e-02],\n",
              "       [9.64668334e-01],\n",
              "       [4.83640470e-03],\n",
              "       [5.70173701e-03],\n",
              "       [2.37948378e-04],\n",
              "       [1.77288777e-03],\n",
              "       [4.54935618e-03],\n",
              "       [9.93352532e-01],\n",
              "       [3.88675705e-02],\n",
              "       [7.42869452e-06],\n",
              "       [1.03591941e-03],\n",
              "       [1.19530763e-02],\n",
              "       [1.00000000e+00],\n",
              "       [9.99794722e-01],\n",
              "       [9.39727306e-01],\n",
              "       [9.74796295e-01],\n",
              "       [2.38181865e-08],\n",
              "       [8.70797276e-01],\n",
              "       [9.99999940e-01],\n",
              "       [5.77388644e-01],\n",
              "       [3.81491184e-01],\n",
              "       [9.99918997e-01],\n",
              "       [1.52762495e-02],\n",
              "       [9.99879420e-01],\n",
              "       [1.18928510e-04],\n",
              "       [6.59209713e-02],\n",
              "       [2.32604533e-01],\n",
              "       [4.55093861e-01],\n",
              "       [1.00000000e+00],\n",
              "       [8.69030580e-02],\n",
              "       [9.47139051e-06],\n",
              "       [3.30687297e-04],\n",
              "       [3.89890045e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.41651999e-05],\n",
              "       [9.65451151e-02],\n",
              "       [9.99828398e-01],\n",
              "       [1.40869932e-04],\n",
              "       [1.00000000e+00],\n",
              "       [9.11966804e-03],\n",
              "       [4.15354589e-05],\n",
              "       [1.70955788e-02],\n",
              "       [9.98715341e-01],\n",
              "       [9.89072740e-01],\n",
              "       [5.85007772e-04],\n",
              "       [1.39199153e-06],\n",
              "       [2.84567685e-03],\n",
              "       [9.99992609e-01],\n",
              "       [8.79088402e-01],\n",
              "       [1.90043089e-03],\n",
              "       [1.49795040e-01],\n",
              "       [7.18876021e-04],\n",
              "       [9.46423006e-06],\n",
              "       [9.99990642e-01],\n",
              "       [2.69226223e-01],\n",
              "       [9.99999881e-01],\n",
              "       [9.99961793e-01],\n",
              "       [3.04006115e-02],\n",
              "       [7.16970563e-01],\n",
              "       [1.22229016e-04],\n",
              "       [9.99432504e-01],\n",
              "       [9.98857260e-01],\n",
              "       [9.99554276e-01],\n",
              "       [1.45693216e-03],\n",
              "       [2.65818853e-02],\n",
              "       [6.93454494e-05],\n",
              "       [2.35849599e-04],\n",
              "       [3.32074778e-05],\n",
              "       [5.67024472e-05],\n",
              "       [9.46710825e-01],\n",
              "       [1.13347883e-03],\n",
              "       [1.00000000e+00],\n",
              "       [9.99933779e-01],\n",
              "       [2.75889635e-01],\n",
              "       [8.39550614e-01],\n",
              "       [3.81860475e-04],\n",
              "       [5.25557029e-04],\n",
              "       [4.06236470e-01],\n",
              "       [6.70142710e-01],\n",
              "       [8.73571694e-01],\n",
              "       [6.12293780e-02],\n",
              "       [1.50294054e-05],\n",
              "       [2.53489361e-05],\n",
              "       [6.45830312e-07],\n",
              "       [9.99688745e-01],\n",
              "       [9.99623716e-01],\n",
              "       [9.99962330e-01],\n",
              "       [1.36522248e-01],\n",
              "       [9.47689176e-01],\n",
              "       [6.66285157e-02],\n",
              "       [2.42264150e-06],\n",
              "       [5.00228584e-01],\n",
              "       [9.99699950e-01],\n",
              "       [1.00000000e+00],\n",
              "       [6.01987509e-08],\n",
              "       [9.55998778e-01],\n",
              "       [2.77059513e-07],\n",
              "       [9.99999523e-01],\n",
              "       [1.00000000e+00],\n",
              "       [5.40387742e-02],\n",
              "       [6.46763086e-01],\n",
              "       [9.99992490e-01],\n",
              "       [4.27363266e-04],\n",
              "       [8.60375760e-04],\n",
              "       [9.99999166e-01],\n",
              "       [2.76653668e-06],\n",
              "       [5.62139066e-05],\n",
              "       [9.99103665e-01],\n",
              "       [2.60145307e-01],\n",
              "       [9.61680830e-01],\n",
              "       [9.99997020e-01],\n",
              "       [5.10566133e-05],\n",
              "       [4.88535874e-03],\n",
              "       [3.26121044e-05],\n",
              "       [2.22968022e-09],\n",
              "       [9.88875836e-05],\n",
              "       [9.99743938e-01],\n",
              "       [4.86716090e-07],\n",
              "       [9.93733346e-01],\n",
              "       [4.72591221e-01],\n",
              "       [7.66898841e-02],\n",
              "       [1.98001415e-01],\n",
              "       [7.83828182e-06],\n",
              "       [4.03760896e-05],\n",
              "       [9.99861658e-01],\n",
              "       [9.99996364e-01],\n",
              "       [9.88840009e-04],\n",
              "       [6.05986221e-04],\n",
              "       [1.38159186e-01],\n",
              "       [2.75363745e-05],\n",
              "       [9.99957144e-01],\n",
              "       [1.58001421e-04],\n",
              "       [8.91448259e-01],\n",
              "       [9.70503926e-01],\n",
              "       [7.06708610e-01],\n",
              "       [9.93199825e-01],\n",
              "       [1.64630964e-01],\n",
              "       [1.13852858e-03],\n",
              "       [1.00423727e-04],\n",
              "       [1.03980638e-01],\n",
              "       [8.76515448e-01],\n",
              "       [9.18231606e-01],\n",
              "       [3.22164714e-01],\n",
              "       [6.83890015e-04],\n",
              "       [3.56607416e-07],\n",
              "       [3.00312945e-06],\n",
              "       [1.70467161e-02],\n",
              "       [5.69635332e-01],\n",
              "       [3.20199609e-01],\n",
              "       [9.99324083e-01],\n",
              "       [9.99975502e-01],\n",
              "       [3.45616609e-01],\n",
              "       [9.40830588e-01],\n",
              "       [7.57004786e-03],\n",
              "       [1.90235380e-06],\n",
              "       [9.98189151e-01],\n",
              "       [7.56641150e-01],\n",
              "       [3.58153787e-03],\n",
              "       [1.54834315e-01],\n",
              "       [9.88930762e-01],\n",
              "       [2.14071232e-08],\n",
              "       [8.50851536e-01],\n",
              "       [6.92363918e-01],\n",
              "       [8.86456370e-01],\n",
              "       [9.99995410e-01],\n",
              "       [1.35934129e-01],\n",
              "       [2.67863716e-03],\n",
              "       [9.40351367e-01],\n",
              "       [4.26800489e-06],\n",
              "       [7.55483508e-02],\n",
              "       [7.79543221e-01],\n",
              "       [9.73700941e-01],\n",
              "       [8.93942297e-01],\n",
              "       [7.57704431e-04],\n",
              "       [5.29255345e-03],\n",
              "       [8.54314327e-01],\n",
              "       [2.14344705e-03],\n",
              "       [4.78639231e-05],\n",
              "       [1.91213316e-04],\n",
              "       [3.42656612e-01],\n",
              "       [9.99999762e-01],\n",
              "       [9.98824775e-01],\n",
              "       [1.09744877e-01],\n",
              "       [9.99976575e-01],\n",
              "       [9.99891162e-01],\n",
              "       [1.64116031e-07],\n",
              "       [9.99995768e-01],\n",
              "       [6.16387837e-03],\n",
              "       [9.99974310e-01],\n",
              "       [4.48538959e-01],\n",
              "       [8.30428153e-02],\n",
              "       [2.73861573e-04],\n",
              "       [3.84450686e-05],\n",
              "       [5.90532683e-02],\n",
              "       [2.03355685e-05],\n",
              "       [2.59169370e-01],\n",
              "       [6.24312612e-04],\n",
              "       [9.99970198e-01],\n",
              "       [1.80552306e-03],\n",
              "       [9.56573784e-01],\n",
              "       [6.84831142e-01],\n",
              "       [9.58999270e-04],\n",
              "       [3.44640166e-02],\n",
              "       [9.99999344e-01],\n",
              "       [1.17581503e-05],\n",
              "       [9.99266028e-01],\n",
              "       [4.40993905e-01],\n",
              "       [4.34365030e-03],\n",
              "       [4.14856195e-01],\n",
              "       [6.91799360e-05],\n",
              "       [1.08126635e-02],\n",
              "       [9.99891162e-01],\n",
              "       [3.72556951e-06],\n",
              "       [2.66807852e-04],\n",
              "       [1.90087166e-02],\n",
              "       [1.00000000e+00],\n",
              "       [6.75837835e-03],\n",
              "       [6.58111530e-05],\n",
              "       [9.99760032e-01],\n",
              "       [5.80695207e-08],\n",
              "       [6.17331779e-03],\n",
              "       [1.20746419e-01],\n",
              "       [1.29923612e-01],\n",
              "       [5.50988407e-05],\n",
              "       [4.32404727e-01],\n",
              "       [6.21063635e-04],\n",
              "       [7.36750364e-02],\n",
              "       [3.54173258e-02],\n",
              "       [5.65128848e-02],\n",
              "       [3.87448748e-03],\n",
              "       [9.96013820e-01],\n",
              "       [9.98208165e-01],\n",
              "       [5.62203348e-01],\n",
              "       [6.01779675e-06],\n",
              "       [2.08769794e-04],\n",
              "       [9.99993324e-01],\n",
              "       [9.79749739e-01],\n",
              "       [9.99999940e-01],\n",
              "       [1.55339077e-01],\n",
              "       [9.97794509e-01],\n",
              "       [1.23133286e-04],\n",
              "       [9.98954654e-01],\n",
              "       [9.90465879e-01],\n",
              "       [6.66193933e-10],\n",
              "       [9.98836458e-01],\n",
              "       [2.69862893e-03],\n",
              "       [9.98818457e-01],\n",
              "       [9.99448001e-01],\n",
              "       [6.91961404e-03],\n",
              "       [6.60943042e-05],\n",
              "       [6.32980227e-01],\n",
              "       [2.84529506e-07],\n",
              "       [1.09592611e-02],\n",
              "       [1.00000000e+00],\n",
              "       [4.05725390e-01],\n",
              "       [9.99892533e-01],\n",
              "       [8.58573735e-01],\n",
              "       [9.99983013e-01],\n",
              "       [9.99566793e-01],\n",
              "       [5.18226949e-03],\n",
              "       [3.31037512e-07],\n",
              "       [9.47665930e-01],\n",
              "       [4.76206513e-03],\n",
              "       [1.99082106e-01],\n",
              "       [9.99993861e-01],\n",
              "       [9.99849677e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99942780e-01],\n",
              "       [9.88067269e-01],\n",
              "       [9.94908690e-01],\n",
              "       [9.93124786e-07],\n",
              "       [8.20838273e-01],\n",
              "       [9.99656320e-01],\n",
              "       [9.95134771e-01],\n",
              "       [1.31602297e-04],\n",
              "       [9.88269091e-01],\n",
              "       [9.91866648e-01],\n",
              "       [9.43422492e-04],\n",
              "       [8.86877254e-03],\n",
              "       [3.22164714e-01],\n",
              "       [1.64421368e-02],\n",
              "       [9.95341122e-01],\n",
              "       [9.92816329e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.70084575e-04],\n",
              "       [4.84196619e-07],\n",
              "       [4.11904057e-06],\n",
              "       [9.83676910e-01],\n",
              "       [2.35408940e-03],\n",
              "       [1.86003596e-02],\n",
              "       [9.92982984e-01],\n",
              "       [2.34251702e-03],\n",
              "       [8.48489285e-01],\n",
              "       [3.50242318e-03],\n",
              "       [7.95100331e-01],\n",
              "       [9.99984264e-01],\n",
              "       [1.31129073e-05],\n",
              "       [9.27760839e-01],\n",
              "       [6.00404525e-03],\n",
              "       [3.91870287e-07],\n",
              "       [1.14127186e-04],\n",
              "       [1.00000000e+00],\n",
              "       [9.65952575e-01],\n",
              "       [4.78232550e-06],\n",
              "       [1.75197236e-02],\n",
              "       [7.71964908e-01],\n",
              "       [1.24181301e-04],\n",
              "       [9.99998748e-01],\n",
              "       [1.08068408e-02],\n",
              "       [7.19353080e-01],\n",
              "       [3.72902811e-01],\n",
              "       [8.26713978e-04],\n",
              "       [7.26102442e-02],\n",
              "       [9.36030746e-01],\n",
              "       [1.18441088e-03],\n",
              "       [9.97169495e-01],\n",
              "       [2.56285489e-01],\n",
              "       [7.98575759e-01],\n",
              "       [9.98757362e-01],\n",
              "       [4.05382544e-01],\n",
              "       [1.81615129e-01],\n",
              "       [2.14071232e-08],\n",
              "       [7.96878278e-01],\n",
              "       [4.81023528e-02],\n",
              "       [1.00000000e+00],\n",
              "       [6.93272352e-01],\n",
              "       [9.23810899e-03],\n",
              "       [9.99999702e-01],\n",
              "       [8.40557516e-01],\n",
              "       [9.97443140e-01],\n",
              "       [8.40557516e-01],\n",
              "       [9.99981999e-01],\n",
              "       [2.39574583e-05],\n",
              "       [3.51867341e-02],\n",
              "       [2.99604110e-08],\n",
              "       [1.00000000e+00],\n",
              "       [4.76216823e-02],\n",
              "       [3.96774663e-03],\n",
              "       [3.12584689e-06],\n",
              "       [3.01529327e-03],\n",
              "       [7.77515173e-02],\n",
              "       [5.02060720e-05],\n",
              "       [1.70090646e-01],\n",
              "       [8.97154212e-03],\n",
              "       [7.39122683e-04],\n",
              "       [3.11283141e-01],\n",
              "       [2.59841583e-03],\n",
              "       [4.50612948e-04],\n",
              "       [6.93294161e-04],\n",
              "       [3.64293044e-07],\n",
              "       [4.03577268e-01],\n",
              "       [9.99564946e-01],\n",
              "       [6.05305308e-04],\n",
              "       [2.77994663e-01],\n",
              "       [1.40436820e-03],\n",
              "       [9.98246014e-01],\n",
              "       [1.00000000e+00],\n",
              "       [2.29743149e-04],\n",
              "       [3.70461130e-05],\n",
              "       [1.34045479e-07],\n",
              "       [1.39082443e-08],\n",
              "       [9.99998093e-01],\n",
              "       [3.64293044e-07],\n",
              "       [3.22141539e-04],\n",
              "       [9.98576760e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [9.99999821e-01],\n",
              "       [2.37146196e-06],\n",
              "       [5.21350245e-04],\n",
              "       [7.94773936e-01],\n",
              "       [7.97568023e-01],\n",
              "       [9.99966204e-01],\n",
              "       [4.67027515e-01],\n",
              "       [3.51858735e-01],\n",
              "       [9.96072710e-01],\n",
              "       [9.89372373e-01],\n",
              "       [2.24074824e-06],\n",
              "       [1.18641463e-09],\n",
              "       [3.50628141e-03],\n",
              "       [1.88470539e-02],\n",
              "       [1.23240650e-04],\n",
              "       [3.42972297e-03],\n",
              "       [9.99999762e-01],\n",
              "       [9.99999762e-01],\n",
              "       [2.62607718e-05],\n",
              "       [9.99970496e-01],\n",
              "       [8.70921552e-01],\n",
              "       [2.37959191e-01],\n",
              "       [5.13390871e-03],\n",
              "       [5.85451961e-01],\n",
              "       [9.49134901e-02],\n",
              "       [6.37025572e-03],\n",
              "       [1.13532144e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_pred = tf.squeeze(tf.round(model_5_preds))\n",
        "model_5_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elDpU4-xnkA9",
        "outputId": "09049d87-5385-4c24-8bb2-6a1b6c434b73"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_results = calculate_results(y_true = val_labels ,\n",
        "                                    y_pred = model_5_pred\n",
        "                                    )\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqbVNOC8nrGn",
        "outputId": "afa7d891-3b1a-441f-f995-851f41a24546"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7480314960629921,\n",
              " 'precision': 0.7480600429524334,\n",
              " 'recall': 0.7480314960629921,\n",
              " 'f1-score': 0.7465302222155744}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 6 : TensorFlow hub pre-trained sentence encoder\n",
        "\n",
        "Lets try and use transfer learning for NLP , universal sentence encoder from tensorflow hub"
      ],
      "metadata": {
        "id": "mavDoPmrn1Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "prFI7vM8u6sJ",
        "outputId": "80a9acd9-9dcc-4e88-ed3a-6fdaca3a9125"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"There's a flood in my street!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "embed_samples = embed([sample_sentence , \"When you can the universal sentence encoder on a sentence , it turns it into numbers\"])\n",
        "print(embed_samples[0][ : 50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxZgolTntkuP",
        "outputId": "b302d2fe-c088-476b-e3e4-c9c7b6310eb4"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157025  0.02485911  0.02878051 -0.012715    0.03971541  0.08827761\n",
            "  0.02680988  0.05589838 -0.01068731 -0.00597293  0.00639321 -0.01819516\n",
            "  0.00030816  0.09105889  0.05874645 -0.03180629  0.01512474 -0.05162925\n",
            "  0.00991366 -0.06865345 -0.04209306  0.0267898   0.03011009  0.00321065\n",
            " -0.00337968 -0.04787356  0.0226672  -0.00985927 -0.04063615 -0.01292093\n",
            " -0.04666382  0.05630299 -0.03949255  0.00517682  0.02495827 -0.07014439\n",
            "  0.0287151   0.0494768  -0.00633978 -0.08960193  0.02807119 -0.00808364\n",
            " -0.01360601  0.05998649 -0.10361788 -0.05195372  0.00232958 -0.02332531\n",
            " -0.03758106  0.03327729], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm9y3fud0PiH",
        "outputId": "bb39b61b-98b6-4ddc-97db-a90074045bd7"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Keras layer using the USE pre-trained layer from tensorflow hub\n",
        "\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\" ,\n",
        "                                        input_shape = [] , # We defined input shape as empty vector because the input to this layer can be a variable length. This pre-trained layer can take any variable length. Any variable length can go into this module but it will always output a 512 feature vector no matter what length sequence goes in. The output will always be 512.\n",
        "                                        dtype = tf.string ,\n",
        "                                        trainable = False ,\n",
        "                                        name = \"USE\"\n",
        "                                        )\n",
        "# Text vectorization layera ihtiyacımız yok cünkü bu modelin icinde zaten text vectorization yapıyor kendisi."
      ],
      "metadata": {
        "id": "kMUwSsb7uM9C"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model with using Sequential API\n",
        "\n",
        "model_6 = tf.keras.Sequential(\n",
        "    [\n",
        "        sentence_encoder_layer ,  # Bu modelde input layerımız direkt bu oluyor.\n",
        "        #layers.Dense(64 , activation = \"relu\")  yani istersek böyle lane stackleyebiliyoruz.\n",
        "        layers.Dense( 1 , activation = \"sigmoid\")\n",
        "\n",
        "\n",
        "    ] , name = \"model_6_USE\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "FuQsdbD5wee6"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt-kyQjh22H7",
        "outputId": "f7540fdf-6787-4026-d88f-d5eb2bdbba84"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile a model\n",
        "model_6.compile(loss = [\"binary_crossentropy\"] ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = [\"accuracy\"]\n",
        "                )"
      ],
      "metadata": {
        "id": "zNfF39Xj25TM"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "hist_6 = model_6.fit( x = train_sentences ,\n",
        "                     y = train_labels ,\n",
        "                     epochs = 5 ,\n",
        "                     validation_data = (val_sentences , val_labels) ,\n",
        "                     callbacks = [create_tensorboard_callback(dir_name = save_dir , experiment_name = \"model_6_dense\")]\n",
        "\n",
        "                      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2mgeRNg3PXQ",
        "outputId": "7a574395-8ba0-49e7-ec40-8a7bb6122a3b"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_6_dense/20230818-181802\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 12ms/step - loss: 0.6499 - accuracy: 0.7227 - val_loss: 0.6127 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.5829 - accuracy: 0.7835 - val_loss: 0.5629 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.5399 - accuracy: 0.7942 - val_loss: 0.5311 - val_accuracy: 0.7848\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.5111 - accuracy: 0.7977 - val_loss: 0.5099 - val_accuracy: 0.7848\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.4909 - accuracy: 0.7996 - val_loss: 0.4957 - val_accuracy: 0.7861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_preds = model_6.predict(val_sentences)\n",
        "model_6_preds\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZxhyQoD3l6Y",
        "outputId": "e9c680e2-aceb-4dcf-824c-04063b2cdc0d"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.36401966],\n",
              "       [0.68358135],\n",
              "       [0.85293466],\n",
              "       [0.35171145],\n",
              "       [0.6507671 ],\n",
              "       [0.7427859 ],\n",
              "       [0.8260346 ],\n",
              "       [0.8430263 ],\n",
              "       [0.7469515 ],\n",
              "       [0.19322678],\n",
              "       [0.5210855 ],\n",
              "       [0.48201615],\n",
              "       [0.40863255],\n",
              "       [0.4603998 ],\n",
              "       [0.4979054 ],\n",
              "       [0.18951929],\n",
              "       [0.36463842],\n",
              "       [0.4836935 ],\n",
              "       [0.5091783 ],\n",
              "       [0.5437844 ],\n",
              "       [0.635258  ],\n",
              "       [0.31116167],\n",
              "       [0.48851126],\n",
              "       [0.16743603],\n",
              "       [0.6126479 ],\n",
              "       [0.79695624],\n",
              "       [0.2315622 ],\n",
              "       [0.34017333],\n",
              "       [0.25505143],\n",
              "       [0.36914977],\n",
              "       [0.5562811 ],\n",
              "       [0.7497512 ],\n",
              "       [0.4490748 ],\n",
              "       [0.4923389 ],\n",
              "       [0.53538215],\n",
              "       [0.21106592],\n",
              "       [0.78324765],\n",
              "       [0.16556041],\n",
              "       [0.19536407],\n",
              "       [0.8122299 ],\n",
              "       [0.23541427],\n",
              "       [0.32110667],\n",
              "       [0.55149484],\n",
              "       [0.55582094],\n",
              "       [0.28161234],\n",
              "       [0.7409025 ],\n",
              "       [0.31845817],\n",
              "       [0.8307538 ],\n",
              "       [0.5249547 ],\n",
              "       [0.79535466],\n",
              "       [0.18362634],\n",
              "       [0.6089934 ],\n",
              "       [0.31651288],\n",
              "       [0.1437659 ],\n",
              "       [0.23594855],\n",
              "       [0.11649608],\n",
              "       [0.3066518 ],\n",
              "       [0.7280785 ],\n",
              "       [0.24223676],\n",
              "       [0.19921564],\n",
              "       [0.11214859],\n",
              "       [0.7784946 ],\n",
              "       [0.82331896],\n",
              "       [0.22970103],\n",
              "       [0.6657727 ],\n",
              "       [0.80014515],\n",
              "       [0.43468973],\n",
              "       [0.44974616],\n",
              "       [0.20014118],\n",
              "       [0.52116084],\n",
              "       [0.20627974],\n",
              "       [0.20558718],\n",
              "       [0.59875286],\n",
              "       [0.17259023],\n",
              "       [0.1380945 ],\n",
              "       [0.56934726],\n",
              "       [0.25605968],\n",
              "       [0.43722892],\n",
              "       [0.2153312 ],\n",
              "       [0.6735082 ],\n",
              "       [0.6817454 ],\n",
              "       [0.4828804 ],\n",
              "       [0.66224384],\n",
              "       [0.3110875 ],\n",
              "       [0.46041784],\n",
              "       [0.57135874],\n",
              "       [0.21400249],\n",
              "       [0.22992247],\n",
              "       [0.87059593],\n",
              "       [0.6172805 ],\n",
              "       [0.8782531 ],\n",
              "       [0.13563247],\n",
              "       [0.18035519],\n",
              "       [0.17439437],\n",
              "       [0.7660595 ],\n",
              "       [0.6539982 ],\n",
              "       [0.749599  ],\n",
              "       [0.68788457],\n",
              "       [0.78255934],\n",
              "       [0.7158966 ],\n",
              "       [0.7706288 ],\n",
              "       [0.26167893],\n",
              "       [0.15778053],\n",
              "       [0.8189578 ],\n",
              "       [0.7663083 ],\n",
              "       [0.15537594],\n",
              "       [0.6198335 ],\n",
              "       [0.6147744 ],\n",
              "       [0.26446334],\n",
              "       [0.6900779 ],\n",
              "       [0.49413028],\n",
              "       [0.26985356],\n",
              "       [0.35125652],\n",
              "       [0.3985353 ],\n",
              "       [0.4638044 ],\n",
              "       [0.49370557],\n",
              "       [0.53851783],\n",
              "       [0.67778057],\n",
              "       [0.57990867],\n",
              "       [0.6472628 ],\n",
              "       [0.763667  ],\n",
              "       [0.37251273],\n",
              "       [0.4871768 ],\n",
              "       [0.63307106],\n",
              "       [0.58314216],\n",
              "       [0.42192525],\n",
              "       [0.2598094 ],\n",
              "       [0.27278116],\n",
              "       [0.18660808],\n",
              "       [0.50360465],\n",
              "       [0.2618917 ],\n",
              "       [0.7699836 ],\n",
              "       [0.72953194],\n",
              "       [0.79940736],\n",
              "       [0.6312199 ],\n",
              "       [0.40881485],\n",
              "       [0.73082906],\n",
              "       [0.34500992],\n",
              "       [0.3798419 ],\n",
              "       [0.23475407],\n",
              "       [0.8145836 ],\n",
              "       [0.3432694 ],\n",
              "       [0.47126904],\n",
              "       [0.47433156],\n",
              "       [0.56314754],\n",
              "       [0.28484935],\n",
              "       [0.12113991],\n",
              "       [0.22213295],\n",
              "       [0.26971233],\n",
              "       [0.8112156 ],\n",
              "       [0.60333633],\n",
              "       [0.21708636],\n",
              "       [0.57775575],\n",
              "       [0.2583878 ],\n",
              "       [0.2978342 ],\n",
              "       [0.6584894 ],\n",
              "       [0.48580298],\n",
              "       [0.2149362 ],\n",
              "       [0.7513176 ],\n",
              "       [0.44101852],\n",
              "       [0.7313502 ],\n",
              "       [0.26296717],\n",
              "       [0.2071196 ],\n",
              "       [0.7889221 ],\n",
              "       [0.33339506],\n",
              "       [0.293007  ],\n",
              "       [0.9075827 ],\n",
              "       [0.3958558 ],\n",
              "       [0.7567147 ],\n",
              "       [0.20996693],\n",
              "       [0.811577  ],\n",
              "       [0.66252685],\n",
              "       [0.8332801 ],\n",
              "       [0.2618479 ],\n",
              "       [0.7449866 ],\n",
              "       [0.1195618 ],\n",
              "       [0.7806924 ],\n",
              "       [0.4710103 ],\n",
              "       [0.53143114],\n",
              "       [0.86427146],\n",
              "       [0.13118178],\n",
              "       [0.697088  ],\n",
              "       [0.5472651 ],\n",
              "       [0.69364065],\n",
              "       [0.67179507],\n",
              "       [0.3855845 ],\n",
              "       [0.29581615],\n",
              "       [0.77830863],\n",
              "       [0.54569745],\n",
              "       [0.30707806],\n",
              "       [0.36268204],\n",
              "       [0.75509924],\n",
              "       [0.4738067 ],\n",
              "       [0.4678318 ],\n",
              "       [0.2919693 ],\n",
              "       [0.34154987],\n",
              "       [0.24519117],\n",
              "       [0.3578339 ],\n",
              "       [0.42130274],\n",
              "       [0.23688745],\n",
              "       [0.28912184],\n",
              "       [0.7188215 ],\n",
              "       [0.6648454 ],\n",
              "       [0.25887525],\n",
              "       [0.3784128 ],\n",
              "       [0.8809552 ],\n",
              "       [0.38204157],\n",
              "       [0.71407974],\n",
              "       [0.7736109 ],\n",
              "       [0.66099995],\n",
              "       [0.15237804],\n",
              "       [0.765799  ],\n",
              "       [0.21340999],\n",
              "       [0.32616207],\n",
              "       [0.1904329 ],\n",
              "       [0.16730575],\n",
              "       [0.6647471 ],\n",
              "       [0.6891639 ],\n",
              "       [0.5012652 ],\n",
              "       [0.16452524],\n",
              "       [0.56718963],\n",
              "       [0.17747773],\n",
              "       [0.17054218],\n",
              "       [0.29414424],\n",
              "       [0.7755969 ],\n",
              "       [0.323677  ],\n",
              "       [0.3167114 ],\n",
              "       [0.7691512 ],\n",
              "       [0.5894496 ],\n",
              "       [0.45560622],\n",
              "       [0.671058  ],\n",
              "       [0.21517581],\n",
              "       [0.7781498 ],\n",
              "       [0.11998101],\n",
              "       [0.55251986],\n",
              "       [0.44134727],\n",
              "       [0.4551232 ],\n",
              "       [0.43277526],\n",
              "       [0.7695982 ],\n",
              "       [0.11897087],\n",
              "       [0.40042865],\n",
              "       [0.38395408],\n",
              "       [0.84120524],\n",
              "       [0.75688577],\n",
              "       [0.17290828],\n",
              "       [0.40383127],\n",
              "       [0.7115529 ],\n",
              "       [0.2544625 ],\n",
              "       [0.19112389],\n",
              "       [0.6078269 ],\n",
              "       [0.2848001 ],\n",
              "       [0.577359  ],\n",
              "       [0.16357619],\n",
              "       [0.5353652 ],\n",
              "       [0.6875236 ],\n",
              "       [0.2588119 ],\n",
              "       [0.7052535 ],\n",
              "       [0.88415873],\n",
              "       [0.21647996],\n",
              "       [0.33094653],\n",
              "       [0.75757957],\n",
              "       [0.2601421 ],\n",
              "       [0.30596337],\n",
              "       [0.7937693 ],\n",
              "       [0.5733456 ],\n",
              "       [0.6487419 ],\n",
              "       [0.69272494],\n",
              "       [0.23218092],\n",
              "       [0.33793342],\n",
              "       [0.14698105],\n",
              "       [0.40922993],\n",
              "       [0.44157562],\n",
              "       [0.77630246],\n",
              "       [0.22290008],\n",
              "       [0.440645  ],\n",
              "       [0.76112354],\n",
              "       [0.5406289 ],\n",
              "       [0.10317161],\n",
              "       [0.82154596],\n",
              "       [0.5689908 ],\n",
              "       [0.26945   ],\n",
              "       [0.3267562 ],\n",
              "       [0.8244844 ],\n",
              "       [0.44177458],\n",
              "       [0.28342703],\n",
              "       [0.65096104],\n",
              "       [0.46193656],\n",
              "       [0.26881588],\n",
              "       [0.5886269 ],\n",
              "       [0.22452208],\n",
              "       [0.5468034 ],\n",
              "       [0.4491611 ],\n",
              "       [0.52928907],\n",
              "       [0.6111898 ],\n",
              "       [0.27702358],\n",
              "       [0.70581824],\n",
              "       [0.42020276],\n",
              "       [0.8440835 ],\n",
              "       [0.10663017],\n",
              "       [0.63879377],\n",
              "       [0.54012984],\n",
              "       [0.27330196],\n",
              "       [0.31980872],\n",
              "       [0.64855736],\n",
              "       [0.39065164],\n",
              "       [0.32662064],\n",
              "       [0.25297177],\n",
              "       [0.527039  ],\n",
              "       [0.22958308],\n",
              "       [0.09480509],\n",
              "       [0.24735773],\n",
              "       [0.697858  ],\n",
              "       [0.51773465],\n",
              "       [0.35225776],\n",
              "       [0.8139157 ],\n",
              "       [0.20051293],\n",
              "       [0.72209895],\n",
              "       [0.60186094],\n",
              "       [0.18804687],\n",
              "       [0.39185077],\n",
              "       [0.24388947],\n",
              "       [0.22535925],\n",
              "       [0.78358287],\n",
              "       [0.14142552],\n",
              "       [0.5912188 ],\n",
              "       [0.30453277],\n",
              "       [0.27904624],\n",
              "       [0.702834  ],\n",
              "       [0.24783319],\n",
              "       [0.7679188 ],\n",
              "       [0.5485286 ],\n",
              "       [0.17200151],\n",
              "       [0.73798364],\n",
              "       [0.3669899 ],\n",
              "       [0.24235304],\n",
              "       [0.64120775],\n",
              "       [0.1722464 ],\n",
              "       [0.5064322 ],\n",
              "       [0.4918045 ],\n",
              "       [0.435396  ],\n",
              "       [0.22066651],\n",
              "       [0.255372  ],\n",
              "       [0.70225513],\n",
              "       [0.7610678 ],\n",
              "       [0.6153811 ],\n",
              "       [0.32158738],\n",
              "       [0.3494774 ],\n",
              "       [0.2775844 ],\n",
              "       [0.12716669],\n",
              "       [0.4191309 ],\n",
              "       [0.31276265],\n",
              "       [0.452587  ],\n",
              "       [0.15857673],\n",
              "       [0.35571352],\n",
              "       [0.3795628 ],\n",
              "       [0.18353593],\n",
              "       [0.7780297 ],\n",
              "       [0.7844289 ],\n",
              "       [0.7009765 ],\n",
              "       [0.40229574],\n",
              "       [0.5622216 ],\n",
              "       [0.27907076],\n",
              "       [0.64018565],\n",
              "       [0.4658295 ],\n",
              "       [0.6295016 ],\n",
              "       [0.18209311],\n",
              "       [0.28899488],\n",
              "       [0.26810545],\n",
              "       [0.33595046],\n",
              "       [0.13132033],\n",
              "       [0.53922516],\n",
              "       [0.1436905 ],\n",
              "       [0.15801315],\n",
              "       [0.39714482],\n",
              "       [0.17626895],\n",
              "       [0.22104369],\n",
              "       [0.2451849 ],\n",
              "       [0.5055494 ],\n",
              "       [0.214405  ],\n",
              "       [0.4840286 ],\n",
              "       [0.7789726 ],\n",
              "       [0.5563838 ],\n",
              "       [0.19261025],\n",
              "       [0.44946265],\n",
              "       [0.43842492],\n",
              "       [0.72214264],\n",
              "       [0.4929476 ],\n",
              "       [0.2792819 ],\n",
              "       [0.8778862 ],\n",
              "       [0.41082618],\n",
              "       [0.20846021],\n",
              "       [0.2964453 ],\n",
              "       [0.11041091],\n",
              "       [0.7282585 ],\n",
              "       [0.49328613],\n",
              "       [0.83155364],\n",
              "       [0.20979075],\n",
              "       [0.60299444],\n",
              "       [0.3887878 ],\n",
              "       [0.6281819 ],\n",
              "       [0.7553877 ],\n",
              "       [0.2082485 ],\n",
              "       [0.61354536],\n",
              "       [0.6803274 ],\n",
              "       [0.39789984],\n",
              "       [0.76680046],\n",
              "       [0.48587638],\n",
              "       [0.42290264],\n",
              "       [0.18489873],\n",
              "       [0.39536595],\n",
              "       [0.67070746],\n",
              "       [0.13051932],\n",
              "       [0.22728424],\n",
              "       [0.32099313],\n",
              "       [0.7595782 ],\n",
              "       [0.62083393],\n",
              "       [0.47776273],\n",
              "       [0.80930144],\n",
              "       [0.3334371 ],\n",
              "       [0.25217426],\n",
              "       [0.7640789 ],\n",
              "       [0.6794515 ],\n",
              "       [0.67655414],\n",
              "       [0.7453219 ],\n",
              "       [0.18430057],\n",
              "       [0.6567523 ],\n",
              "       [0.19612586],\n",
              "       [0.620045  ],\n",
              "       [0.2714576 ],\n",
              "       [0.7400997 ],\n",
              "       [0.17463937],\n",
              "       [0.22585227],\n",
              "       [0.18390766],\n",
              "       [0.6188711 ],\n",
              "       [0.3303797 ],\n",
              "       [0.34078175],\n",
              "       [0.29915604],\n",
              "       [0.56786776],\n",
              "       [0.77549607],\n",
              "       [0.62717193],\n",
              "       [0.6437671 ],\n",
              "       [0.66992605],\n",
              "       [0.45411354],\n",
              "       [0.27072206],\n",
              "       [0.24190596],\n",
              "       [0.67626613],\n",
              "       [0.23617247],\n",
              "       [0.12464358],\n",
              "       [0.42983246],\n",
              "       [0.28180543],\n",
              "       [0.19297016],\n",
              "       [0.68008024],\n",
              "       [0.7207839 ],\n",
              "       [0.6352918 ],\n",
              "       [0.8766384 ],\n",
              "       [0.8064285 ],\n",
              "       [0.23901042],\n",
              "       [0.40023652],\n",
              "       [0.57890195],\n",
              "       [0.7835653 ],\n",
              "       [0.79869086],\n",
              "       [0.14773431],\n",
              "       [0.29880714],\n",
              "       [0.48407966],\n",
              "       [0.866234  ],\n",
              "       [0.82437074],\n",
              "       [0.34214938],\n",
              "       [0.26412857],\n",
              "       [0.7532964 ],\n",
              "       [0.11826357],\n",
              "       [0.19797575],\n",
              "       [0.7969251 ],\n",
              "       [0.6041649 ],\n",
              "       [0.44362932],\n",
              "       [0.46401504],\n",
              "       [0.66783184],\n",
              "       [0.77934176],\n",
              "       [0.8384714 ],\n",
              "       [0.15806255],\n",
              "       [0.18245238],\n",
              "       [0.51801723],\n",
              "       [0.26488566],\n",
              "       [0.2965253 ],\n",
              "       [0.7128246 ],\n",
              "       [0.09878214],\n",
              "       [0.4849195 ],\n",
              "       [0.32736966],\n",
              "       [0.16822797],\n",
              "       [0.41377044],\n",
              "       [0.5046552 ],\n",
              "       [0.45643377],\n",
              "       [0.7680112 ],\n",
              "       [0.36420196],\n",
              "       [0.38532326],\n",
              "       [0.30481067],\n",
              "       [0.30762273],\n",
              "       [0.43295392],\n",
              "       [0.6963007 ],\n",
              "       [0.23686466],\n",
              "       [0.54067093],\n",
              "       [0.79810673],\n",
              "       [0.11704107],\n",
              "       [0.33715078],\n",
              "       [0.7523477 ],\n",
              "       [0.22040726],\n",
              "       [0.6309702 ],\n",
              "       [0.29229867],\n",
              "       [0.7954279 ],\n",
              "       [0.31361774],\n",
              "       [0.24259625],\n",
              "       [0.15864633],\n",
              "       [0.21233319],\n",
              "       [0.3920602 ],\n",
              "       [0.4436072 ],\n",
              "       [0.7523008 ],\n",
              "       [0.23760854],\n",
              "       [0.8259113 ],\n",
              "       [0.52051723],\n",
              "       [0.6398276 ],\n",
              "       [0.76554316],\n",
              "       [0.47754192],\n",
              "       [0.38744107],\n",
              "       [0.5714907 ],\n",
              "       [0.7700753 ],\n",
              "       [0.12900813],\n",
              "       [0.47541472],\n",
              "       [0.24980095],\n",
              "       [0.35941228],\n",
              "       [0.5887161 ],\n",
              "       [0.73177105],\n",
              "       [0.6251044 ],\n",
              "       [0.6869413 ],\n",
              "       [0.20355532],\n",
              "       [0.18955395],\n",
              "       [0.5711581 ],\n",
              "       [0.26458853],\n",
              "       [0.17503351],\n",
              "       [0.22492705],\n",
              "       [0.29976934],\n",
              "       [0.5698139 ],\n",
              "       [0.32954416],\n",
              "       [0.46477374],\n",
              "       [0.36474556],\n",
              "       [0.4023773 ],\n",
              "       [0.33954838],\n",
              "       [0.41830355],\n",
              "       [0.58057904],\n",
              "       [0.817138  ],\n",
              "       [0.72405547],\n",
              "       [0.65839183],\n",
              "       [0.63862854],\n",
              "       [0.6281421 ],\n",
              "       [0.33012852],\n",
              "       [0.6439557 ],\n",
              "       [0.16854121],\n",
              "       [0.8083187 ],\n",
              "       [0.16758406],\n",
              "       [0.4121578 ],\n",
              "       [0.601428  ],\n",
              "       [0.15066501],\n",
              "       [0.20531143],\n",
              "       [0.47310138],\n",
              "       [0.80228955],\n",
              "       [0.79513764],\n",
              "       [0.63126636],\n",
              "       [0.28209886],\n",
              "       [0.6195081 ],\n",
              "       [0.6142688 ],\n",
              "       [0.21600437],\n",
              "       [0.3299902 ],\n",
              "       [0.6673642 ],\n",
              "       [0.60925925],\n",
              "       [0.8202366 ],\n",
              "       [0.46005377],\n",
              "       [0.4128103 ],\n",
              "       [0.41028723],\n",
              "       [0.38604113],\n",
              "       [0.59466404],\n",
              "       [0.5859107 ],\n",
              "       [0.512564  ],\n",
              "       [0.2194727 ],\n",
              "       [0.2118799 ],\n",
              "       [0.76604444],\n",
              "       [0.17723344],\n",
              "       [0.16128144],\n",
              "       [0.82584214],\n",
              "       [0.4232829 ],\n",
              "       [0.18716396],\n",
              "       [0.56783825],\n",
              "       [0.16823812],\n",
              "       [0.3901051 ],\n",
              "       [0.43693638],\n",
              "       [0.5863398 ],\n",
              "       [0.13515334],\n",
              "       [0.4125924 ],\n",
              "       [0.76923597],\n",
              "       [0.33385068],\n",
              "       [0.7459031 ],\n",
              "       [0.7631244 ],\n",
              "       [0.15543035],\n",
              "       [0.20886081],\n",
              "       [0.22219425],\n",
              "       [0.74304575],\n",
              "       [0.44154978],\n",
              "       [0.7915692 ],\n",
              "       [0.31899798],\n",
              "       [0.4667213 ],\n",
              "       [0.29478332],\n",
              "       [0.19532932],\n",
              "       [0.5925385 ],\n",
              "       [0.253419  ],\n",
              "       [0.7606646 ],\n",
              "       [0.21081196],\n",
              "       [0.29426235],\n",
              "       [0.8274051 ],\n",
              "       [0.38926372],\n",
              "       [0.21422525],\n",
              "       [0.5179553 ],\n",
              "       [0.1783802 ],\n",
              "       [0.6283589 ],\n",
              "       [0.8761927 ],\n",
              "       [0.3403238 ],\n",
              "       [0.8770261 ],\n",
              "       [0.28824675],\n",
              "       [0.5973263 ],\n",
              "       [0.29657245],\n",
              "       [0.63709575],\n",
              "       [0.5305613 ],\n",
              "       [0.4829585 ],\n",
              "       [0.13757545],\n",
              "       [0.68103856],\n",
              "       [0.7095615 ],\n",
              "       [0.47878304],\n",
              "       [0.6223309 ],\n",
              "       [0.77710116],\n",
              "       [0.12892047],\n",
              "       [0.54979897],\n",
              "       [0.4230957 ],\n",
              "       [0.5682475 ],\n",
              "       [0.24277252],\n",
              "       [0.60460967],\n",
              "       [0.38694632],\n",
              "       [0.54664516],\n",
              "       [0.3369058 ],\n",
              "       [0.33361512],\n",
              "       [0.42584974],\n",
              "       [0.18730462],\n",
              "       [0.4832038 ],\n",
              "       [0.3577826 ],\n",
              "       [0.7051655 ],\n",
              "       [0.85719186],\n",
              "       [0.16447619],\n",
              "       [0.3148653 ],\n",
              "       [0.20732297],\n",
              "       [0.32462648],\n",
              "       [0.33941296],\n",
              "       [0.17618595],\n",
              "       [0.7306328 ],\n",
              "       [0.23271123],\n",
              "       [0.35304746],\n",
              "       [0.23671381],\n",
              "       [0.2517251 ],\n",
              "       [0.6823864 ],\n",
              "       [0.29626417],\n",
              "       [0.21926464],\n",
              "       [0.29953662],\n",
              "       [0.31252876],\n",
              "       [0.4092303 ],\n",
              "       [0.81342727],\n",
              "       [0.47175163],\n",
              "       [0.25205436],\n",
              "       [0.35523137],\n",
              "       [0.25676027],\n",
              "       [0.10185435],\n",
              "       [0.77359205],\n",
              "       [0.47091562],\n",
              "       [0.5743013 ],\n",
              "       [0.59945667],\n",
              "       [0.29443824],\n",
              "       [0.47907946],\n",
              "       [0.42849496],\n",
              "       [0.1476406 ],\n",
              "       [0.51641566],\n",
              "       [0.6277701 ],\n",
              "       [0.31902108],\n",
              "       [0.7487866 ],\n",
              "       [0.13768913],\n",
              "       [0.42703745],\n",
              "       [0.35941228],\n",
              "       [0.16341329],\n",
              "       [0.8002775 ],\n",
              "       [0.7776117 ],\n",
              "       [0.35632274],\n",
              "       [0.24901512],\n",
              "       [0.82246214],\n",
              "       [0.64153916],\n",
              "       [0.63394856],\n",
              "       [0.58809584],\n",
              "       [0.61798716],\n",
              "       [0.3993504 ],\n",
              "       [0.34153453],\n",
              "       [0.5132036 ],\n",
              "       [0.7091838 ],\n",
              "       [0.27852547],\n",
              "       [0.4592155 ],\n",
              "       [0.43540087],\n",
              "       [0.49349445],\n",
              "       [0.21148205],\n",
              "       [0.2546839 ],\n",
              "       [0.33390072],\n",
              "       [0.23588963],\n",
              "       [0.3133004 ],\n",
              "       [0.6346745 ],\n",
              "       [0.12608585],\n",
              "       [0.19326293],\n",
              "       [0.27227268],\n",
              "       [0.42728764],\n",
              "       [0.15716043],\n",
              "       [0.5822414 ],\n",
              "       [0.18070532],\n",
              "       [0.5124024 ],\n",
              "       [0.23908734],\n",
              "       [0.18020456],\n",
              "       [0.65815777],\n",
              "       [0.29083684],\n",
              "       [0.32598922],\n",
              "       [0.25992504],\n",
              "       [0.21813187],\n",
              "       [0.7855077 ],\n",
              "       [0.4077031 ],\n",
              "       [0.26249078],\n",
              "       [0.7513994 ],\n",
              "       [0.66839015],\n",
              "       [0.7009571 ],\n",
              "       [0.87012327],\n",
              "       [0.8435444 ],\n",
              "       [0.2668789 ],\n",
              "       [0.3083637 ],\n",
              "       [0.12479295],\n",
              "       [0.508352  ],\n",
              "       [0.68126565],\n",
              "       [0.5089215 ],\n",
              "       [0.40632406],\n",
              "       [0.2731561 ],\n",
              "       [0.51596737],\n",
              "       [0.46282846],\n",
              "       [0.45327038],\n",
              "       [0.2996424 ],\n",
              "       [0.32617223],\n",
              "       [0.24467611],\n",
              "       [0.22254188],\n",
              "       [0.5402344 ],\n",
              "       [0.75446475],\n",
              "       [0.21412237],\n",
              "       [0.7743152 ],\n",
              "       [0.627446  ],\n",
              "       [0.24214697],\n",
              "       [0.2728395 ],\n",
              "       [0.2073209 ],\n",
              "       [0.7102016 ],\n",
              "       [0.578918  ],\n",
              "       [0.35912257]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pred = tf.squeeze(tf.round(model_6_preds))\n",
        "model_6_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Z4Xsd34kNj",
        "outputId": "da0067c5-84e2-4d04-adb6-eba8c7169f92"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results = calculate_results(y_true = val_labels ,\n",
        "                                    y_pred = model_6_pred\n",
        "                                    )\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeQyo-jD4xDh",
        "outputId": "65b756c2-e884-43e1-f816-bac0572d6ab1"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7860892388451444,\n",
              " 'precision': 0.7863431959164349,\n",
              " 'recall': 0.7860892388451444,\n",
              " 'f1-score': 0.7850582651599072}"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to improve our model_6\n",
        "\n",
        "model_6_improve = tf.keras.Sequential(\n",
        "    [\n",
        "        sentence_encoder_layer ,\n",
        "        layers.Dense( 64 , activation =  \"relu\") ,\n",
        "        layers.Dense( 1 , activation = \"sigmoid\" , name = \"output_layer\")\n",
        "\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "QyhhlUhD449d"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_6_improve.compile(loss = [\"binary_crossentropy\"] ,\n",
        "                optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = [\"accuracy\"]\n",
        "                )"
      ],
      "metadata": {
        "id": "YZdjr3kZ6Hhk"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "hist_6_improve = model_6_improve.fit( x = train_sentences ,\n",
        "                     y = train_labels ,\n",
        "                     epochs = 5 ,\n",
        "                     validation_data = (val_sentences , val_labels) ,\n",
        "                     callbacks = [create_tensorboard_callback(dir_name = save_dir , experiment_name = \"model_6_improve_dense\")]\n",
        "\n",
        "                      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5oRsP1Y6NrF",
        "outputId": "f0fec776-45e8-48aa-a53e-99f587a4a93e"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_6_improve_dense/20230818-183008\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 11ms/step - loss: 0.5028 - accuracy: 0.7854 - val_loss: 0.4480 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.4141 - accuracy: 0.8146 - val_loss: 0.4375 - val_accuracy: 0.8071\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3996 - accuracy: 0.8208 - val_loss: 0.4339 - val_accuracy: 0.8123\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3927 - accuracy: 0.8241 - val_loss: 0.4301 - val_accuracy: 0.8097\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3859 - accuracy: 0.8304 - val_loss: 0.4275 - val_accuracy: 0.8084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_improve_preds = model_6_improve.predict(val_sentences)\n",
        "model_6_improve_preds\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsRpkwz6XL7",
        "outputId": "b47dbf6f-f4c9-4bc3-9eba-6005fe47fc89"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16276628],\n",
              "       [0.79003876],\n",
              "       [0.98984116],\n",
              "       [0.21169765],\n",
              "       [0.6732754 ],\n",
              "       [0.75170535],\n",
              "       [0.97835785],\n",
              "       [0.9790968 ],\n",
              "       [0.9541548 ],\n",
              "       [0.09700762],\n",
              "       [0.6214952 ],\n",
              "       [0.44272122],\n",
              "       [0.16536315],\n",
              "       [0.53145486],\n",
              "       [0.24104969],\n",
              "       [0.0315002 ],\n",
              "       [0.32123494],\n",
              "       [0.59869957],\n",
              "       [0.3495958 ],\n",
              "       [0.3073196 ],\n",
              "       [0.9147935 ],\n",
              "       [0.10915114],\n",
              "       [0.36180648],\n",
              "       [0.03740163],\n",
              "       [0.8765997 ],\n",
              "       [0.97064894],\n",
              "       [0.06189346],\n",
              "       [0.12721719],\n",
              "       [0.10696267],\n",
              "       [0.28704932],\n",
              "       [0.48814392],\n",
              "       [0.91863847],\n",
              "       [0.329686  ],\n",
              "       [0.28129384],\n",
              "       [0.44719774],\n",
              "       [0.08466875],\n",
              "       [0.9821984 ],\n",
              "       [0.06073403],\n",
              "       [0.03722097],\n",
              "       [0.98584557],\n",
              "       [0.08391458],\n",
              "       [0.25869554],\n",
              "       [0.49620867],\n",
              "       [0.53998363],\n",
              "       [0.26848435],\n",
              "       [0.96621764],\n",
              "       [0.3619913 ],\n",
              "       [0.9535243 ],\n",
              "       [0.6192057 ],\n",
              "       [0.8597589 ],\n",
              "       [0.06749013],\n",
              "       [0.63343334],\n",
              "       [0.1872363 ],\n",
              "       [0.06633187],\n",
              "       [0.11071014],\n",
              "       [0.03754566],\n",
              "       [0.13399826],\n",
              "       [0.90381944],\n",
              "       [0.12220469],\n",
              "       [0.05992127],\n",
              "       [0.07739422],\n",
              "       [0.9727394 ],\n",
              "       [0.9729357 ],\n",
              "       [0.0870491 ],\n",
              "       [0.8969791 ],\n",
              "       [0.95124483],\n",
              "       [0.72061193],\n",
              "       [0.15707085],\n",
              "       [0.06583881],\n",
              "       [0.4946538 ],\n",
              "       [0.12005302],\n",
              "       [0.07926408],\n",
              "       [0.7269156 ],\n",
              "       [0.06027471],\n",
              "       [0.03728413],\n",
              "       [0.45039237],\n",
              "       [0.19378363],\n",
              "       [0.27103397],\n",
              "       [0.06276045],\n",
              "       [0.7453056 ],\n",
              "       [0.7515732 ],\n",
              "       [0.430611  ],\n",
              "       [0.9150079 ],\n",
              "       [0.09544405],\n",
              "       [0.6961845 ],\n",
              "       [0.5794467 ],\n",
              "       [0.08003521],\n",
              "       [0.14408413],\n",
              "       [0.98867106],\n",
              "       [0.8887516 ],\n",
              "       [0.9958838 ],\n",
              "       [0.04220913],\n",
              "       [0.09117994],\n",
              "       [0.02514003],\n",
              "       [0.9665461 ],\n",
              "       [0.7666785 ],\n",
              "       [0.9747794 ],\n",
              "       [0.8628847 ],\n",
              "       [0.9799928 ],\n",
              "       [0.9365669 ],\n",
              "       [0.95002925],\n",
              "       [0.16947867],\n",
              "       [0.17046049],\n",
              "       [0.98961544],\n",
              "       [0.9793095 ],\n",
              "       [0.03526891],\n",
              "       [0.8404101 ],\n",
              "       [0.795423  ],\n",
              "       [0.1247725 ],\n",
              "       [0.80515206],\n",
              "       [0.12515284],\n",
              "       [0.05956236],\n",
              "       [0.18569244],\n",
              "       [0.28873724],\n",
              "       [0.14759265],\n",
              "       [0.21146883],\n",
              "       [0.39941895],\n",
              "       [0.5753361 ],\n",
              "       [0.75472283],\n",
              "       [0.738976  ],\n",
              "       [0.91540194],\n",
              "       [0.14282465],\n",
              "       [0.53870195],\n",
              "       [0.7856869 ],\n",
              "       [0.58784944],\n",
              "       [0.36525306],\n",
              "       [0.13843384],\n",
              "       [0.10675233],\n",
              "       [0.12629838],\n",
              "       [0.30843854],\n",
              "       [0.11376095],\n",
              "       [0.93720335],\n",
              "       [0.973963  ],\n",
              "       [0.97052646],\n",
              "       [0.7725814 ],\n",
              "       [0.19546723],\n",
              "       [0.95103115],\n",
              "       [0.39010474],\n",
              "       [0.43457428],\n",
              "       [0.11659727],\n",
              "       [0.9763052 ],\n",
              "       [0.17207047],\n",
              "       [0.5037995 ],\n",
              "       [0.47809908],\n",
              "       [0.79392534],\n",
              "       [0.36336508],\n",
              "       [0.04375953],\n",
              "       [0.08900195],\n",
              "       [0.1368192 ],\n",
              "       [0.8995589 ],\n",
              "       [0.3231754 ],\n",
              "       [0.05688847],\n",
              "       [0.4874126 ],\n",
              "       [0.06882682],\n",
              "       [0.41660666],\n",
              "       [0.8074884 ],\n",
              "       [0.64340377],\n",
              "       [0.08481549],\n",
              "       [0.943717  ],\n",
              "       [0.15823184],\n",
              "       [0.88666224],\n",
              "       [0.08196356],\n",
              "       [0.16041231],\n",
              "       [0.95492214],\n",
              "       [0.07181324],\n",
              "       [0.05585263],\n",
              "       [0.9931093 ],\n",
              "       [0.18783243],\n",
              "       [0.9082514 ],\n",
              "       [0.14976063],\n",
              "       [0.98377675],\n",
              "       [0.36881673],\n",
              "       [0.9654857 ],\n",
              "       [0.0552741 ],\n",
              "       [0.9484935 ],\n",
              "       [0.036933  ],\n",
              "       [0.8582401 ],\n",
              "       [0.4635736 ],\n",
              "       [0.5839375 ],\n",
              "       [0.99490017],\n",
              "       [0.05432389],\n",
              "       [0.66219926],\n",
              "       [0.37210357],\n",
              "       [0.8821061 ],\n",
              "       [0.9266246 ],\n",
              "       [0.30046058],\n",
              "       [0.17062998],\n",
              "       [0.9793711 ],\n",
              "       [0.31661803],\n",
              "       [0.09036217],\n",
              "       [0.36284882],\n",
              "       [0.95690256],\n",
              "       [0.10193788],\n",
              "       [0.17739722],\n",
              "       [0.09988505],\n",
              "       [0.11175805],\n",
              "       [0.12150499],\n",
              "       [0.22936621],\n",
              "       [0.11561127],\n",
              "       [0.07418924],\n",
              "       [0.14233625],\n",
              "       [0.9525986 ],\n",
              "       [0.84068245],\n",
              "       [0.20206814],\n",
              "       [0.1344505 ],\n",
              "       [0.98746246],\n",
              "       [0.24172199],\n",
              "       [0.8444564 ],\n",
              "       [0.9208163 ],\n",
              "       [0.80834377],\n",
              "       [0.03426148],\n",
              "       [0.96852434],\n",
              "       [0.06280535],\n",
              "       [0.11078338],\n",
              "       [0.03298636],\n",
              "       [0.04610949],\n",
              "       [0.90231746],\n",
              "       [0.91374874],\n",
              "       [0.6536666 ],\n",
              "       [0.05160937],\n",
              "       [0.52563685],\n",
              "       [0.0572281 ],\n",
              "       [0.09841391],\n",
              "       [0.18967119],\n",
              "       [0.9859724 ],\n",
              "       [0.14661664],\n",
              "       [0.19547777],\n",
              "       [0.9701141 ],\n",
              "       [0.6530695 ],\n",
              "       [0.25552282],\n",
              "       [0.76774323],\n",
              "       [0.1747705 ],\n",
              "       [0.93492913],\n",
              "       [0.04634114],\n",
              "       [0.37721497],\n",
              "       [0.47290578],\n",
              "       [0.33245388],\n",
              "       [0.57595074],\n",
              "       [0.98121226],\n",
              "       [0.03850169],\n",
              "       [0.57924885],\n",
              "       [0.23946351],\n",
              "       [0.9782546 ],\n",
              "       [0.92218924],\n",
              "       [0.04258393],\n",
              "       [0.17806043],\n",
              "       [0.906962  ],\n",
              "       [0.18396465],\n",
              "       [0.10620507],\n",
              "       [0.6937808 ],\n",
              "       [0.12055942],\n",
              "       [0.7948756 ],\n",
              "       [0.03055345],\n",
              "       [0.53213924],\n",
              "       [0.89408344],\n",
              "       [0.17052498],\n",
              "       [0.795208  ],\n",
              "       [0.9933968 ],\n",
              "       [0.29160187],\n",
              "       [0.11866578],\n",
              "       [0.9446026 ],\n",
              "       [0.0948567 ],\n",
              "       [0.14248854],\n",
              "       [0.95233387],\n",
              "       [0.86914206],\n",
              "       [0.71742123],\n",
              "       [0.9089488 ],\n",
              "       [0.08253343],\n",
              "       [0.12783837],\n",
              "       [0.07271384],\n",
              "       [0.11146478],\n",
              "       [0.36557123],\n",
              "       [0.9226233 ],\n",
              "       [0.09380283],\n",
              "       [0.33489633],\n",
              "       [0.94549865],\n",
              "       [0.15962459],\n",
              "       [0.06551349],\n",
              "       [0.97765714],\n",
              "       [0.41747424],\n",
              "       [0.09804469],\n",
              "       [0.13505623],\n",
              "       [0.97083527],\n",
              "       [0.4268244 ],\n",
              "       [0.19700155],\n",
              "       [0.5886287 ],\n",
              "       [0.75715774],\n",
              "       [0.16263194],\n",
              "       [0.7978069 ],\n",
              "       [0.05859343],\n",
              "       [0.83903426],\n",
              "       [0.53463703],\n",
              "       [0.23348722],\n",
              "       [0.7445483 ],\n",
              "       [0.07249472],\n",
              "       [0.85738236],\n",
              "       [0.28012082],\n",
              "       [0.9811723 ],\n",
              "       [0.08669598],\n",
              "       [0.56004554],\n",
              "       [0.29547313],\n",
              "       [0.10321108],\n",
              "       [0.07223495],\n",
              "       [0.82752055],\n",
              "       [0.2377666 ],\n",
              "       [0.15407445],\n",
              "       [0.10478668],\n",
              "       [0.7134191 ],\n",
              "       [0.06518456],\n",
              "       [0.02863265],\n",
              "       [0.11843975],\n",
              "       [0.96608615],\n",
              "       [0.67023796],\n",
              "       [0.23208493],\n",
              "       [0.97294694],\n",
              "       [0.07229958],\n",
              "       [0.9095319 ],\n",
              "       [0.67145264],\n",
              "       [0.02353763],\n",
              "       [0.21341024],\n",
              "       [0.09567018],\n",
              "       [0.14233953],\n",
              "       [0.97767186],\n",
              "       [0.06034381],\n",
              "       [0.71323013],\n",
              "       [0.06832007],\n",
              "       [0.17668033],\n",
              "       [0.8692854 ],\n",
              "       [0.0689875 ],\n",
              "       [0.8563359 ],\n",
              "       [0.8441892 ],\n",
              "       [0.09891625],\n",
              "       [0.94034564],\n",
              "       [0.24511036],\n",
              "       [0.20644258],\n",
              "       [0.54449147],\n",
              "       [0.05362681],\n",
              "       [0.38088423],\n",
              "       [0.4846963 ],\n",
              "       [0.5213653 ],\n",
              "       [0.10347176],\n",
              "       [0.19996084],\n",
              "       [0.92504615],\n",
              "       [0.9606149 ],\n",
              "       [0.6985444 ],\n",
              "       [0.17077053],\n",
              "       [0.26585686],\n",
              "       [0.09034738],\n",
              "       [0.06503067],\n",
              "       [0.16194327],\n",
              "       [0.25024784],\n",
              "       [0.32104033],\n",
              "       [0.08860207],\n",
              "       [0.0879295 ],\n",
              "       [0.46166766],\n",
              "       [0.04743915],\n",
              "       [0.964123  ],\n",
              "       [0.961014  ],\n",
              "       [0.8146774 ],\n",
              "       [0.63609207],\n",
              "       [0.43026298],\n",
              "       [0.06786428],\n",
              "       [0.95746267],\n",
              "       [0.501418  ],\n",
              "       [0.39180925],\n",
              "       [0.05343267],\n",
              "       [0.16088468],\n",
              "       [0.07592165],\n",
              "       [0.16888651],\n",
              "       [0.03238396],\n",
              "       [0.71012723],\n",
              "       [0.03653329],\n",
              "       [0.16161582],\n",
              "       [0.19657059],\n",
              "       [0.07760424],\n",
              "       [0.07664202],\n",
              "       [0.11587035],\n",
              "       [0.14137028],\n",
              "       [0.14045107],\n",
              "       [0.43099168],\n",
              "       [0.94317824],\n",
              "       [0.8096127 ],\n",
              "       [0.11993285],\n",
              "       [0.19099677],\n",
              "       [0.5385298 ],\n",
              "       [0.9497973 ],\n",
              "       [0.41338447],\n",
              "       [0.28614354],\n",
              "       [0.9921573 ],\n",
              "       [0.2572303 ],\n",
              "       [0.11326354],\n",
              "       [0.37052667],\n",
              "       [0.04203478],\n",
              "       [0.8419373 ],\n",
              "       [0.6244215 ],\n",
              "       [0.99067837],\n",
              "       [0.10114951],\n",
              "       [0.71109134],\n",
              "       [0.23116583],\n",
              "       [0.38342997],\n",
              "       [0.969546  ],\n",
              "       [0.14069726],\n",
              "       [0.6290897 ],\n",
              "       [0.8995656 ],\n",
              "       [0.09698151],\n",
              "       [0.94349134],\n",
              "       [0.29546896],\n",
              "       [0.71482027],\n",
              "       [0.05746639],\n",
              "       [0.27317744],\n",
              "       [0.8473914 ],\n",
              "       [0.04133364],\n",
              "       [0.08978396],\n",
              "       [0.41327387],\n",
              "       [0.94889957],\n",
              "       [0.75953126],\n",
              "       [0.24416548],\n",
              "       [0.9520551 ],\n",
              "       [0.17697033],\n",
              "       [0.08452846],\n",
              "       [0.96532875],\n",
              "       [0.874395  ],\n",
              "       [0.78933686],\n",
              "       [0.7956309 ],\n",
              "       [0.03354553],\n",
              "       [0.5903244 ],\n",
              "       [0.14381658],\n",
              "       [0.8447862 ],\n",
              "       [0.39270762],\n",
              "       [0.91975516],\n",
              "       [0.08156429],\n",
              "       [0.06480417],\n",
              "       [0.09836408],\n",
              "       [0.6451217 ],\n",
              "       [0.24809417],\n",
              "       [0.275055  ],\n",
              "       [0.42968178],\n",
              "       [0.39803672],\n",
              "       [0.9874097 ],\n",
              "       [0.8164915 ],\n",
              "       [0.6920933 ],\n",
              "       [0.7664011 ],\n",
              "       [0.32021037],\n",
              "       [0.10962909],\n",
              "       [0.18947022],\n",
              "       [0.74890095],\n",
              "       [0.05862698],\n",
              "       [0.05315894],\n",
              "       [0.2267237 ],\n",
              "       [0.16223305],\n",
              "       [0.04303095],\n",
              "       [0.8657652 ],\n",
              "       [0.9255425 ],\n",
              "       [0.8652587 ],\n",
              "       [0.96571815],\n",
              "       [0.98301744],\n",
              "       [0.07138458],\n",
              "       [0.18285988],\n",
              "       [0.38615158],\n",
              "       [0.83868   ],\n",
              "       [0.9879634 ],\n",
              "       [0.07372455],\n",
              "       [0.14280675],\n",
              "       [0.47373834],\n",
              "       [0.990818  ],\n",
              "       [0.9466828 ],\n",
              "       [0.15221722],\n",
              "       [0.20093767],\n",
              "       [0.94327754],\n",
              "       [0.0348172 ],\n",
              "       [0.1804604 ],\n",
              "       [0.9114907 ],\n",
              "       [0.60455793],\n",
              "       [0.22425945],\n",
              "       [0.7472382 ],\n",
              "       [0.53257406],\n",
              "       [0.82406735],\n",
              "       [0.97987396],\n",
              "       [0.1047552 ],\n",
              "       [0.04999248],\n",
              "       [0.16921753],\n",
              "       [0.06013463],\n",
              "       [0.36586505],\n",
              "       [0.88766426],\n",
              "       [0.03790195],\n",
              "       [0.61927545],\n",
              "       [0.08371162],\n",
              "       [0.08245081],\n",
              "       [0.29373425],\n",
              "       [0.45412955],\n",
              "       [0.3337402 ],\n",
              "       [0.971277  ],\n",
              "       [0.21543823],\n",
              "       [0.07449438],\n",
              "       [0.11340765],\n",
              "       [0.12729207],\n",
              "       [0.53966236],\n",
              "       [0.8248716 ],\n",
              "       [0.10923751],\n",
              "       [0.8648635 ],\n",
              "       [0.9647598 ],\n",
              "       [0.05164393],\n",
              "       [0.3646832 ],\n",
              "       [0.81278944],\n",
              "       [0.1863968 ],\n",
              "       [0.6582716 ],\n",
              "       [0.08956632],\n",
              "       [0.9416857 ],\n",
              "       [0.1790593 ],\n",
              "       [0.16279148],\n",
              "       [0.10533801],\n",
              "       [0.06770123],\n",
              "       [0.17982858],\n",
              "       [0.6128408 ],\n",
              "       [0.9518144 ],\n",
              "       [0.15949996],\n",
              "       [0.97143435],\n",
              "       [0.6699054 ],\n",
              "       [0.66695035],\n",
              "       [0.9832463 ],\n",
              "       [0.44283432],\n",
              "       [0.37051654],\n",
              "       [0.85715604],\n",
              "       [0.9538237 ],\n",
              "       [0.05385134],\n",
              "       [0.19043471],\n",
              "       [0.08031597],\n",
              "       [0.2365404 ],\n",
              "       [0.38556206],\n",
              "       [0.924876  ],\n",
              "       [0.74342734],\n",
              "       [0.9662349 ],\n",
              "       [0.08525264],\n",
              "       [0.03858236],\n",
              "       [0.8663635 ],\n",
              "       [0.11197548],\n",
              "       [0.07192838],\n",
              "       [0.06265908],\n",
              "       [0.11476546],\n",
              "       [0.4261696 ],\n",
              "       [0.23601218],\n",
              "       [0.4799146 ],\n",
              "       [0.20891881],\n",
              "       [0.14789209],\n",
              "       [0.09456672],\n",
              "       [0.19345777],\n",
              "       [0.3694251 ],\n",
              "       [0.9537457 ],\n",
              "       [0.80989176],\n",
              "       [0.719495  ],\n",
              "       [0.9084851 ],\n",
              "       [0.9428508 ],\n",
              "       [0.07374376],\n",
              "       [0.8336354 ],\n",
              "       [0.07035597],\n",
              "       [0.9801676 ],\n",
              "       [0.06194441],\n",
              "       [0.23300934],\n",
              "       [0.25670704],\n",
              "       [0.05289472],\n",
              "       [0.16387706],\n",
              "       [0.2811757 ],\n",
              "       [0.95582104],\n",
              "       [0.86328024],\n",
              "       [0.83516324],\n",
              "       [0.07704004],\n",
              "       [0.7194107 ],\n",
              "       [0.7311177 ],\n",
              "       [0.078803  ],\n",
              "       [0.253338  ],\n",
              "       [0.8402786 ],\n",
              "       [0.7159935 ],\n",
              "       [0.98620033],\n",
              "       [0.2420863 ],\n",
              "       [0.153326  ],\n",
              "       [0.5834255 ],\n",
              "       [0.11335931],\n",
              "       [0.7424528 ],\n",
              "       [0.90843385],\n",
              "       [0.21041578],\n",
              "       [0.06235623],\n",
              "       [0.07892752],\n",
              "       [0.93796617],\n",
              "       [0.15977757],\n",
              "       [0.07110916],\n",
              "       [0.96882045],\n",
              "       [0.17646967],\n",
              "       [0.10741267],\n",
              "       [0.697173  ],\n",
              "       [0.0284266 ],\n",
              "       [0.23872261],\n",
              "       [0.36651856],\n",
              "       [0.6100951 ],\n",
              "       [0.01273851],\n",
              "       [0.27974215],\n",
              "       [0.94906515],\n",
              "       [0.12079044],\n",
              "       [0.94219613],\n",
              "       [0.9843228 ],\n",
              "       [0.05570922],\n",
              "       [0.06243605],\n",
              "       [0.04211169],\n",
              "       [0.9323988 ],\n",
              "       [0.50624347],\n",
              "       [0.9833139 ],\n",
              "       [0.11206869],\n",
              "       [0.30999237],\n",
              "       [0.09761209],\n",
              "       [0.05167345],\n",
              "       [0.765603  ],\n",
              "       [0.12718381],\n",
              "       [0.9273196 ],\n",
              "       [0.08575321],\n",
              "       [0.17417495],\n",
              "       [0.98188686],\n",
              "       [0.30225328],\n",
              "       [0.06249996],\n",
              "       [0.45153046],\n",
              "       [0.03815911],\n",
              "       [0.6048466 ],\n",
              "       [0.98687226],\n",
              "       [0.08351889],\n",
              "       [0.98686165],\n",
              "       [0.20441866],\n",
              "       [0.80271614],\n",
              "       [0.12069507],\n",
              "       [0.49147838],\n",
              "       [0.31824267],\n",
              "       [0.8691168 ],\n",
              "       [0.03285624],\n",
              "       [0.47563487],\n",
              "       [0.93632966],\n",
              "       [0.68107903],\n",
              "       [0.6525077 ],\n",
              "       [0.89421463],\n",
              "       [0.06185642],\n",
              "       [0.7045783 ],\n",
              "       [0.11748675],\n",
              "       [0.72175485],\n",
              "       [0.14994138],\n",
              "       [0.92191124],\n",
              "       [0.36927462],\n",
              "       [0.56813014],\n",
              "       [0.168191  ],\n",
              "       [0.07039407],\n",
              "       [0.6408355 ],\n",
              "       [0.12716317],\n",
              "       [0.18629478],\n",
              "       [0.5679377 ],\n",
              "       [0.963616  ],\n",
              "       [0.99141103],\n",
              "       [0.07853395],\n",
              "       [0.06040619],\n",
              "       [0.07085253],\n",
              "       [0.13534237],\n",
              "       [0.30617478],\n",
              "       [0.06174416],\n",
              "       [0.974353  ],\n",
              "       [0.13454312],\n",
              "       [0.42649835],\n",
              "       [0.09595051],\n",
              "       [0.1169242 ],\n",
              "       [0.85426736],\n",
              "       [0.11134979],\n",
              "       [0.10697169],\n",
              "       [0.24146318],\n",
              "       [0.0974713 ],\n",
              "       [0.38767385],\n",
              "       [0.9845725 ],\n",
              "       [0.4596901 ],\n",
              "       [0.04336052],\n",
              "       [0.1814126 ],\n",
              "       [0.11122671],\n",
              "       [0.03861511],\n",
              "       [0.933887  ],\n",
              "       [0.19243716],\n",
              "       [0.7019152 ],\n",
              "       [0.44502944],\n",
              "       [0.11200808],\n",
              "       [0.2926132 ],\n",
              "       [0.26969784],\n",
              "       [0.05518183],\n",
              "       [0.15161447],\n",
              "       [0.8592552 ],\n",
              "       [0.14198346],\n",
              "       [0.9325309 ],\n",
              "       [0.05740338],\n",
              "       [0.18603577],\n",
              "       [0.2365404 ],\n",
              "       [0.03759633],\n",
              "       [0.8148888 ],\n",
              "       [0.9520548 ],\n",
              "       [0.25075004],\n",
              "       [0.07069221],\n",
              "       [0.975885  ],\n",
              "       [0.74885404],\n",
              "       [0.829015  ],\n",
              "       [0.6368884 ],\n",
              "       [0.78457195],\n",
              "       [0.10230815],\n",
              "       [0.1763651 ],\n",
              "       [0.24949116],\n",
              "       [0.7944613 ],\n",
              "       [0.0809961 ],\n",
              "       [0.4207147 ],\n",
              "       [0.19251175],\n",
              "       [0.32084692],\n",
              "       [0.07096328],\n",
              "       [0.08306449],\n",
              "       [0.12516385],\n",
              "       [0.18664138],\n",
              "       [0.21695404],\n",
              "       [0.518472  ],\n",
              "       [0.01953545],\n",
              "       [0.09333538],\n",
              "       [0.17291634],\n",
              "       [0.25208417],\n",
              "       [0.02496229],\n",
              "       [0.676841  ],\n",
              "       [0.03438708],\n",
              "       [0.6356129 ],\n",
              "       [0.11984135],\n",
              "       [0.20018284],\n",
              "       [0.87976736],\n",
              "       [0.06521128],\n",
              "       [0.32229984],\n",
              "       [0.12159494],\n",
              "       [0.06980083],\n",
              "       [0.94611317],\n",
              "       [0.23488674],\n",
              "       [0.17316198],\n",
              "       [0.888179  ],\n",
              "       [0.93743443],\n",
              "       [0.9025984 ],\n",
              "       [0.99146163],\n",
              "       [0.9629068 ],\n",
              "       [0.1653919 ],\n",
              "       [0.18431515],\n",
              "       [0.05376124],\n",
              "       [0.7015198 ],\n",
              "       [0.88767153],\n",
              "       [0.5858505 ],\n",
              "       [0.36609524],\n",
              "       [0.05957122],\n",
              "       [0.3999126 ],\n",
              "       [0.37418848],\n",
              "       [0.14393878],\n",
              "       [0.22700094],\n",
              "       [0.10798816],\n",
              "       [0.08705343],\n",
              "       [0.14694336],\n",
              "       [0.33605504],\n",
              "       [0.9181739 ],\n",
              "       [0.11464958],\n",
              "       [0.9333881 ],\n",
              "       [0.6907928 ],\n",
              "       [0.07279716],\n",
              "       [0.12337017],\n",
              "       [0.11874006],\n",
              "       [0.88279027],\n",
              "       [0.6478452 ],\n",
              "       [0.12274527]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_improve_pred = tf.squeeze(tf.round(model_6_improve_preds))\n",
        "model_6_improve_pred\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U9KZY4G6hZs",
        "outputId": "ed21bfa0-a8da-497d-bd74-ee3bb5d077bc"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_improve_results = calculate_results(y_true = val_labels ,\n",
        "                                    y_pred = model_6_improve_pred\n",
        "                                    )\n",
        "model_6_improve_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuygWcus6orh",
        "outputId": "2b9b4679-57a0-4d4e-8665-438c9873f242"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8083989501312336,\n",
              " 'precision': 0.8106890532903106,\n",
              " 'recall': 0.8083989501312336,\n",
              " 'f1-score': 0.8067678554730104}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-hNg9ucp6wUU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}